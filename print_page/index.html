
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="canonical" href="https://mmondics.github.io/ocp-cloudpak-workshop/print_page/">
      
      <link rel="icon" href="../images/openshift-logo.png">
      <meta name="generator" content="mkdocs-1.2.2, mkdocs-material-7.3.0">
    
    
      
        <title>Print Site - Red Hat OpenShift and IBM Cloud Paks on IBM Z and LinuxONE Workshop</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.8b42a75e.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.3f5d1f46.min.css">
        
          
          
          <meta name="theme-color" content="#000000">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style>
      
    
    
    
      <link rel="stylesheet" href="../css/print-site.css">
    
      <link rel="stylesheet" href="../css/print-site-material.css">
    
      <link rel="stylesheet" href="../stylesheets/extra.css">
    
    
      


    
    
  
        <script type="text/javascript">
        document.addEventListener('DOMContentLoaded', function () {
            remove_material_navigation();remove_mkdocs_theme_navigation();generate_toc();
        })
        </script>
        </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="">
  
    
    <script>function __prefix(e){return new URL("../..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Red Hat OpenShift and IBM Cloud Paks on IBM Z and LinuxONE Workshop" class="md-header__button md-logo" aria-label="Red Hat OpenShift and IBM Cloud Paks on IBM Z and LinuxONE Workshop" data-md-component="logo">
      
  <img src="../images/openshift-logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Red Hat OpenShift and IBM Cloud Paks on IBM Z and LinuxONE Workshop
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Print Site
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        
<a href="https://github.com/mmondics/ocp-cloudpak-workshop/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Red Hat OpenShift and IBM Cloud Paks on IBM Z and LinuxONE Workshop" class="md-nav__button md-logo" aria-label="Red Hat OpenShift and IBM Cloud Paks on IBM Z and LinuxONE Workshop" data-md-component="logo">
      
  <img src="../images/openshift-logo.png" alt="logo">

    </a>
    Red Hat OpenShift and IBM Cloud Paks on IBM Z and LinuxONE Workshop
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/mmondics/ocp-cloudpak-workshop/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../prerequisites/" class="md-nav__link">
        Prerequisites
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../lab-assignments/" class="md-nav__link">
        Lab Assignments
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../workshop-architecture/" class="md-nav__link">
        Lab Architecture
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5">
          Presentations
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Presentations" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Presentations
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../presentations/presentation1.pdf" class="md-nav__link">
        Presentation 1 - Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../presentations/presentation2.pdf" class="md-nav__link">
        Presentation 2 - Technical Deep Dive
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6" type="checkbox" id="__nav_6" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6">
          Labs
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Labs" data-md-level="1">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          Labs
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_1" type="checkbox" id="__nav_6_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_1">
          Exploring the OpenShift Console
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Exploring the OpenShift Console" data-md-level="2">
        <label class="md-nav__title" for="__nav_6_1">
          <span class="md-nav__icon md-icon"></span>
          Exploring the OpenShift Console
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab001/lab001-1/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab001/lab001-2/" class="md-nav__link">
        Connect to OCP
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab001/lab001-3/" class="md-nav__link">
        The Administrator Persepctive
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab001/lab001-4/" class="md-nav__link">
        The Developer Perspective
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab001/lab001-5/" class="md-nav__link">
        Deploy from the Developer Catalog
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab001/lab001-6/" class="md-nav__link">
        View Workload from the Administrator Perspective
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab001/lab001-7/" class="md-nav__link">
        Cleaning Up
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_2" type="checkbox" id="__nav_6_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_2">
          Using the OpenShift Command Line (oc)
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Using the OpenShift Command Line (oc)" data-md-level="2">
        <label class="md-nav__title" for="__nav_6_2">
          <span class="md-nav__icon md-icon"></span>
          Using the OpenShift Command Line (oc)
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab002/lab002-1/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab002/lab002-2/" class="md-nav__link">
        Log into OpenShift Using the CLI
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab002/lab002-3/" class="md-nav__link">
        Overview of the OpenShift CLI
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab002/lab002-4/" class="md-nav__link">
        Deploy Container Image from the CLI
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab002/lab002-5/" class="md-nav__link">
        Open a Remote Shell Session into the MongoDB Pod
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab002/lab002-6/" class="md-nav__link">
        Working with Pods
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab002/lab002-7/" class="md-nav__link">
        Administrative CLI Commands
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab002/lab002-8/" class="md-nav__link">
        Cleaning Up
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_3" type="checkbox" id="__nav_6_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_3">
          Deploying an Application from Source Code
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Deploying an Application from Source Code" data-md-level="2">
        <label class="md-nav__title" for="__nav_6_3">
          <span class="md-nav__icon md-icon"></span>
          Deploying an Application from Source Code
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab004/lab004-1/" class="md-nav__link">
        Source-to-Image (S2I) Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab004/lab004-2/" class="md-nav__link">
        Exploring GitHub and the Example Health Source Code
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab004/lab004-3/" class="md-nav__link">
        Connect to OCP and Authenticate
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab004/lab004-4/" class="md-nav__link">
        Edit the Source Code and Push an Update
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab004/lab004-5/" class="md-nav__link">
        Cleaning Up
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_4" type="checkbox" id="__nav_6_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_4">
          OpenShift Pipelines
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="OpenShift Pipelines" data-md-level="2">
        <label class="md-nav__title" for="__nav_6_4">
          <span class="md-nav__icon md-icon"></span>
          OpenShift Pipelines
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab009/lab009-0/" class="md-nav__link">
        Introduction to OpenShift Pipelines
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab009/lab009-1/" class="md-nav__link">
        Log into OpenShift Using the CLI
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab009/lab009-2/" class="md-nav__link">
        Cloning the GitHub Repository and Viewing its Contents
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab009/lab009-3/" class="md-nav__link">
        Understanding and Deploying Tasks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab009/lab009-4/" class="md-nav__link">
        Understanding and Deploying Pipelines
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab009/lab009-5/" class="md-nav__link">
        Running the Pipeline
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab009/lab009-6/" class="md-nav__link">
        Access the Application in a Browser
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab009/lab009-7/" class="md-nav__link">
        Cleaning Up
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_5" type="checkbox" id="__nav_6_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_5">
          Monitoring, Metering, and Metrics
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Monitoring, Metering, and Metrics" data-md-level="2">
        <label class="md-nav__title" for="__nav_6_5">
          <span class="md-nav__icon md-icon"></span>
          Monitoring, Metering, and Metrics
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab005/lab005-1/" class="md-nav__link">
        Overview of OpenShift Monitoring
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab005/lab005-2/" class="md-nav__link">
        Connect to OCP and Authenticate
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab005/lab005-3/" class="md-nav__link">
        Using OpenShift Metrics (Prometheus)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab005/lab005-4/" class="md-nav__link">
        Using the In-Browser Grafana Dashboards
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab005/lab005-5/" class="md-nav__link">
        Connect to Grafana
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab005/lab005-6/" class="md-nav__link">
        Using Grafana Dashboards
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab005/lab005-7/" class="md-nav__link">
        Using OpenShift Alerts (Alertmanager)
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_6" type="checkbox" id="__nav_6_6" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_6">
          Using Persistent Storage with MongoDB and NodeJS
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Using Persistent Storage with MongoDB and NodeJS" data-md-level="2">
        <label class="md-nav__title" for="__nav_6_6">
          <span class="md-nav__icon md-icon"></span>
          Using Persistent Storage with MongoDB and NodeJS
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab006/lab006-1/" class="md-nav__link">
        Overview of Persistent Storage and Application Architecture
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab006/lab006-2/" class="md-nav__link">
        Connect to OCP and Authenticate
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab006/lab006-3/" class="md-nav__link">
        Create a PersistentVolumeClaim
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab006/lab006-4/" class="md-nav__link">
        Deploy MongoDB from Container Image
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab006/lab006-5/" class="md-nav__link">
        Deploy Node.js Application from Dockerfile
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab006/lab006-6/" class="md-nav__link">
        Interacting with MongoDB from Node.js Application
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab006/lab006-7/" class="md-nav__link">
        Cleaning Up
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_7" type="checkbox" id="__nav_6_7" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_7">
          Deploying an Application with the Open Liberty Operator
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Deploying an Application with the Open Liberty Operator" data-md-level="2">
        <label class="md-nav__title" for="__nav_6_7">
          <span class="md-nav__icon md-icon"></span>
          Deploying an Application with the Open Liberty Operator
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab007/lab007-1/" class="md-nav__link">
        Overview of the Open Liberty Operator and Sample Application
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab007/lab007-2/" class="md-nav__link">
        Log into OpenShift Using the CLI
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab007/lab007-3/" class="md-nav__link">
        Cloning the GitHub Repository and Reviewing its Contents
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab007/lab007-4/" class="md-nav__link">
        Using the Open Liberty Operator to Install an Application
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab007/lab007-5/" class="md-nav__link">
        Access the Application in a Browser
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab007/lab007-6/" class="md-nav__link">
        Cleaning Up
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_8" type="checkbox" id="__nav_6_8" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_8">
          Deploying an Application with Quarkus Red Hat Runtime
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Deploying an Application with Quarkus Red Hat Runtime" data-md-level="2">
        <label class="md-nav__title" for="__nav_6_8">
          <span class="md-nav__icon md-icon"></span>
          Deploying an Application with Quarkus Red Hat Runtime
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab008/lab008-1/" class="md-nav__link">
        Overview of the Quarkus Red Hat Runtime
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab008/lab008-2/" class="md-nav__link">
        Log into OpenShift Using the CLI
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab008/lab008-3/" class="md-nav__link">
        Creating and Reviewing the Quarkus Project
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab008/lab008-4/" class="md-nav__link">
        Configure the Application for OpenShift
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab008/lab008-5/" class="md-nav__link">
        Deploy the Application onto OpenShift
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lab008/lab008-6/" class="md-nav__link">
        Cleaning Up
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Print Site
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Print Site
      </a>
      
        
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#" class="md-nav__link">
    Home
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#prerequisites" class="md-nav__link">
    Prerequisites
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lab-assignments" class="md-nav__link">
    Lab Assignments
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#workshop-architecture" class="md-nav__link">
    Lab Architecture
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#section-presentations" class="md-nav__link">
    Presentations
  </a>
  
    <nav class="md-nav" aria-label="Presentations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#presentations-presentation1.pdf" class="md-nav__link">
    Presentation 1 - Overview
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#presentations-presentation2.pdf" class="md-nav__link">
    Presentation 2 - Technical Deep Dive
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#section-labs" class="md-nav__link">
    Labs
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#" class="md-nav__link">
    Home
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#prerequisites" class="md-nav__link">
    Prerequisites
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lab-assignments" class="md-nav__link">
    Lab Assignments
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#workshop-architecture" class="md-nav__link">
    Lab Architecture
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#section-presentations" class="md-nav__link">
    Presentations
  </a>
  
    <nav class="md-nav" aria-label="Presentations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#presentations-presentation1.pdf" class="md-nav__link">
    Presentation 1 - Overview
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#presentations-presentation2.pdf" class="md-nav__link">
    Presentation 2 - Technical Deep Dive
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#section-labs" class="md-nav__link">
    Labs
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                
                <div id="print-site-page" class="print-site-enumerate-headings print-site-enumerate-figures">
        <section class="print-page">
            <div id="print-page-toc" data-toc-depth="3">
                <nav role='navigation' class='print-page-toc-nav'>
                <h1 class='print-page-toc-title'>Table of Contents</h1>
                </nav>
            </div>
        </section>
        <section class="print-page" id="index"><h1 id="index-red-hat-openshift-and-ibm-cloud-paks-on-ibm-z-and-linuxone-workshop">Red Hat OpenShift and IBM Cloud Paks on IBM Z and LinuxONE Workshop<a class="headerlink" href="#index-red-hat-openshift-and-ibm-cloud-paks-on-ibm-z-and-linuxone-workshop" title="Permanent link">&para;</a></h1>
<p>Welcome to the Red Hat OpenShift and IBM Cloud Paks on IBM Z and LinuxONE workshop. Below you can find the workshop agenda, presentations, and lab documentation.</p>
<h2 id="index-agenda">Agenda<a class="headerlink" href="#index-agenda" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th>Activity</th>
<th>Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="../presentations/presentation1.pdf"><strong>Presentation 1 - High level overview of OpenShift, Cloud Paks, and running them on IBM Z</strong></a></td>
<td>30-45 minutes</td>
</tr>
<tr>
<td><a href="../presentations/presentation2.pdf"><strong>Presentation 2 - Technical Deep Dive</strong></a></td>
<td>~ 1 hour</td>
</tr>
<tr>
<td>Connect to environment as a group</td>
<td>5-10 minutes</td>
</tr>
<tr>
<td><a href="#index-labs"><strong>Hands-on, self-paced labs</strong></a></td>
<td>Remainder of day</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The lab environments will be available the day following the workshop.</p>
<p>For example, If the workshop is on a Thursday, the environments will be available until 5PM EST Friday.</p>
</div>
<h2 id="index-presentations">Presentations<a class="headerlink" href="#index-presentations" title="Permanent link">&para;</a></h2>
<ul>
<li><a href="../presentations/presentation1.pdf">Presentation 1 - High Level Overview of Red Hat OpenShift &amp; IBM Cloud Paks on IBM Z</a></li>
<li><a href="../presentations/presentation2.pdf">Presentation 2 - Technical Deep Dive, Installation &amp; Configuration, Lessons Learned</a></li>
</ul>
<h2 id="index-labs">Labs<a class="headerlink" href="#index-labs" title="Permanent link">&para;</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The labs are designed so that you can pick and choose which you would like to complete. The labs <em>are not</em> designed for you to get through them all in one day.</p>
<p>Labs are non-sequential and have no dependencies on one another.</p>
</div>
<h3 id="index-introductory-labs">Introductory Labs<a class="headerlink" href="#index-introductory-labs" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="#lab001-lab001-1">Exploring the OpenShift Console</a></li>
<li><a href="#lab002-lab002-1">Using the OpenShift Command Line (oc)</a></li>
</ul>
<h3 id="index-openshift-capability-labs">OpenShift Capability Labs<a class="headerlink" href="#index-openshift-capability-labs" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="#lab004-lab004-1">Deploying an Application from Source Code</a></li>
<li><a href="#lab009-lab009-0">OpenShift Pipelines</a></li>
</ul>
<!--- * [OpenShift Service Mesh](lab010/lab010-1.md) --->
<ul>
<li><a href="#lab005-lab005-1">Monitoring, Metering, and Metrics</a></li>
<li><a href="#lab006-lab006-1">Using Persistent Storage - MongoDB and NodeJS</a></li>
</ul>
<h3 id="index-extended-capability-labs">Extended Capability Labs<a class="headerlink" href="#index-extended-capability-labs" title="Permanent link">&para;</a></h3>
<!--- * [Using the z/OS Cloud Broker](lab003/lab003-1.md) --->
<ul>
<li><a href="#lab007-lab007-1">Deploying an Application with the Open Liberty Operator</a></li>
<li><a href="#lab008-lab008-1">Deploying an Application with Quarkus Red Hat Runtime</a></li>
</ul>
<h2 id="index-workshop-environment-architecture">Workshop Environment Architecture<a class="headerlink" href="#index-workshop-environment-architecture" title="Permanent link">&para;</a></h2>
<p>Please visit <a href="#workshop-architecture">this page</a> to see the architecture of the workshop's lab environment.</p>
<h2 id="index-workshop-owners">Workshop Owners<a class="headerlink" href="#index-workshop-owners" title="Permanent link">&para;</a></h2>
<ul>
<li><a href="mailto:matt.mondics@ibm.com">Matt Mondics</a></li>
<li><a href="mailto:pwnovak@us.ibm.com">Paul Novak</a></li>
</ul></section><section class="print-page" id="prerequisites"><h1 id="prerequisites-prerequisites">Prerequisites<a class="headerlink" href="#prerequisites-prerequisites" title="Permanent link">&para;</a></h1>
<h2 id="prerequisites-github-account">GitHub Account<a class="headerlink" href="#prerequisites-github-account" title="Permanent link">&para;</a></h2>
<p>If you wish to complete <a href="#lab004-lab004-1">Deploying an Application from Source Code</a>, you must have your own GitHub account. You can create one create one by clicking the <em>Sign Up</em> button on the <a href="https://github.com/">GitHub homepage</a>.</p></section><section class="print-page" id="lab-assignments"><h1 id="lab-assignments-lab-assignments">Lab Assignments<a class="headerlink" href="#lab-assignments-lab-assignments" title="Permanent link">&para;</a></h1>
<p><strong>There are connection instructions below the table on this page.</strong></p>
<h2 id="lab-assignments-virtual-machine-openshift-logins">Virtual Machine &amp; OpenShift Logins<a class="headerlink" href="#lab-assignments-virtual-machine-openshift-logins" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th>Name</th>
<th>Virtual Machine Password</th>
<th>workshop-user Password</th>
<th>User Number</th>
<th>OpenShift Username</th>
<th>OpenShift Password</th>
</tr>
</thead>
<tbody>
<tr>
<td><a class="md-button" href="https://cloud.skytap.com/vms/d54ffbb2cfe58f5640a0f77eaf947043/desktops">Andrews</a></td>
<td><strong>fdt39vua</strong></td>
<td>p@ssw0rd</td>
<td>01</td>
<td>user01</td>
<td>p@ssw0rd</td>
</tr>
<tr>
<td><a class="md-button md-button--primary" href="https://cloud.skytap.com/vms/2ad95a9d5184975f133f4c51d4e14cb9/desktops">Archambault</a></td>
<td><strong>ymsp2ung</strong></td>
<td>p@ssw0rd</td>
<td>02</td>
<td>user02</td>
<td>p@ssw0rd</td>
</tr>
<tr>
<td><a class="md-button" href="https://cloud.skytap.com/vms/833ec8e8eac15ca2f957fa5cded2c33a/desktops">Balasubramanian</a></td>
<td><strong>j8gfteho</strong></td>
<td>p@ssw0rd</td>
<td>03</td>
<td>user03</td>
<td>p@ssw0rd</td>
</tr>
<tr>
<td><a class="md-button md-button--primary" href="https://cloud.skytap.com/vms/471f459d17cfa08b451d89349162572e/desktops">Balasubramanian</a></td>
<td><strong>d2wr771r</strong></td>
<td>p@ssw0rd</td>
<td>04</td>
<td>user04</td>
<td>p@ssw0rd</td>
</tr>
<tr>
<td><a class="md-button" href="https://cloud.skytap.com/vms/f728e7092ad79711ab07ef09f143b31b/desktops">Craven</a></td>
<td><strong>ja8kpjv9</strong></td>
<td>p@ssw0rd</td>
<td>05</td>
<td>user05</td>
<td>p@ssw0rd</td>
</tr>
<tr>
<td><a class="md-button md-button--primary" href="https://cloud.skytap.com/vms/0b86d5d9a86be00f0229ee458eb4569f/desktops">Deodhar</a></td>
<td><strong>wv08oels</strong></td>
<td>p@ssw0rd</td>
<td>06</td>
<td>user06</td>
<td>p@ssw0rd</td>
</tr>
<tr>
<td><a class="md-button" href="https://cloud.skytap.com/vms/0b212273b0ac10f7a68ef642a3ba9c55/desktops">Higgins</a></td>
<td><strong>rtd2z62t</strong></td>
<td>p@ssw0rd</td>
<td>07</td>
<td>user07</td>
<td>p@ssw0rd</td>
</tr>
<tr>
<td><a class="md-button md-button--primary" href="https://cloud.skytap.com/vms/8c8fcf6a596ab867f76fc2231b98c840/desktops">Michalik</a></td>
<td><strong>4hvg03wm</strong></td>
<td>p@ssw0rd</td>
<td>08</td>
<td>user08</td>
<td>p@ssw0rd</td>
</tr>
<tr>
<td><a class="md-button" href="https://cloud.skytap.com/vms/fa85f5fed0a881057b3c0a2b975611f4/desktops">Regan</a></td>
<td><strong>2ryxzqjt</strong></td>
<td>p@ssw0rd</td>
<td>09</td>
<td>user09</td>
<td>p@ssw0rd</td>
</tr>
<tr>
<td><a class="md-button md-button--primary" href="https://cloud.skytap.com/vms/bdac7a99040d0777c444bf015890c4ec/desktops">Srikakolapu</a></td>
<td><strong>91qrjq88</strong></td>
<td>p@ssw0rd</td>
<td>10</td>
<td>user10</td>
<td>p@ssw0rd</td>
</tr>
<tr>
<td><a class="md-button" href="https://cloud.skytap.com/vms/2f0eda821b3f458a621dc3f0d1ae2fcd/desktops">Subbanna</a></td>
<td><strong>w3893bo3</strong></td>
<td>p@ssw0rd</td>
<td>11</td>
<td>user11</td>
<td>p@ssw0rd</td>
</tr>
</tbody>
</table>
<!--- | [TBD](https://google.com){ .md-button .md-button--primary } | **TBD** | p@ssw0rd | 12 | user12 | p@ssw0rd |
| [TBD](https://google.com){ .md-button } |  **TBD**| p@ssw0rd | 13 | user13 | p@ssw0rd |
| [TBD](https://google.com){ .md-button .md-button--primary } | **TBD** | p@ssw0rd | 14 | user14 | p@ssw0rd |
| [TBD](https://google.com){ .md-button } | **TBD** | p@ssw0rd | 15 | user15 | p@ssw0rd |
| [TBD](https://google.com){ .md-button .md-button--primary } | **TBD** | p@ssw0rd | 16 | user16 | p@ssw0rd |
| [TBD](https://google.com){ .md-button } | **TBD** | p@ssw0rd | 17 | user17 | p@ssw0rd |
| [TBD](https://google.com){ .md-button .md-button--primary } | **TBD** | p@ssw0rd | 18 | user18 | p@ssw0rd |
| [TBD](https://google.com){ .md-button } | **TBD** | p@ssw0rd | 19 | user19 | p@ssw0rd |
| [TBD](https://google.com){ .md-button .md-button--primary } | **TBD** | p@ssw0rd | 20 | user20 | p@ssw0rd |
| [TBD](https://google.com){ .md-button } | **TBD** | p@ssw0rd | 21 | user21 | p@ssw0rd |
| [TBD](https://google.com){ .md-button .md-button--primary } | **TBD** | p@ssw0rd | 22 | user22 | p@ssw0rd |
| [TBD](https://google.com){ .md-button } | **TBD** | p@ssw0rd | 23 | user23 | p@ssw0rd |
| [TBD](https://google.com){ .md-button .md-button--primary } | **TBD** | p@ssw0rd | 24 | user24 | p@ssw0rd |
| [TBD](https://google.com){ .md-button } | **TBD** | p@ssw0rd | 25 | user25 | p@ssw0rd |
| [TBD](https://google.com){ .md-button .md-button--primary } | **TBD** | p@ssw0rd | 26 | user26 | p@ssw0rd |
| [TBD](https://google.com){ .md-button } | **TBD** | p@ssw0rd | 27 | user27 | p@ssw0rd |
| [TBD](https://google.com){ .md-button .md-button--primary } | **TBD** | p@ssw0rd | 28 | user28 | p@ssw0rd |
| [TBD](https://google.com){ .md-button } | **TBD** | p@ssw0rd | 29 | user29 | p@ssw0rd |
| [TBD](https://google.com){ .md-button .md-button--primary } | **TBD** | p@ssw0rd | 30 | user30 | p@ssw0rd |--->

<h2 id="lab-assignments-connecting-to-your-rhel-virtual-desktop">Connecting to your RHEL Virtual Desktop<a class="headerlink" href="#lab-assignments-connecting-to-your-rhel-virtual-desktop" title="Permanent link">&para;</a></h2>
<ol>
<li>
<p><strong>Click the link to your personal virtual machine</strong> and <strong>enter the Virtual Machine Password provided on the table</strong>.</p>
</li>
<li>
<p><strong>Click the box for the RHEL desktop</strong> that should be green and running.</p>
<p><img alt="rhel-running" src="../images/rhel-running.png" /></p>
</li>
<li>
<p><strong>Log into the RHEL desktop</strong> with the password: <code>p@ssw0rd</code>.</p>
<p><img alt="rhel-login" src="../images/rhel-login.png" /></p>
<div class="admonition note">
<p class="admonition-title"><img alt="⚠" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/26a0.svg" title=":warning:" /> Important <img alt="⚠" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/26a0.svg" title=":warning:" /></p>
<p>Each virtual machine has a 3 hour inactivity timer. If you exceed this timeout, you can restart the virtual machine, but this will log you off of the VPN. If this happens, reach out to an instructor and they will log back into the VPN for you.</p>
</div>
</li>
</ol></section><section class="print-page" id="workshop-architecture"><h1 id="workshop-architecture-workshop-architecture-diagram">Workshop Architecture Diagram<a class="headerlink" href="#workshop-architecture-workshop-architecture-diagram" title="Permanent link">&para;</a></h1>
<p><img alt="workshop-arch" src="../ocpz-workshop-arch.drawio.svg" /></p>
<p>The OpenShift (OCP) on IBM Z environment used in this workshop is detailed in the diagram above.</p>
<p>Note that this <em>is not</em> the recommended OpenShift architecture for high availablity or production. For OCP on Z reference architectures <a href="https://www.ibm.com/docs/en/linux-on-systems?topic=openshift-reference-architecture">navigate to this link</a>.</p>
<p>The entire lab environment is behing the Washington Systems Center VPN. You are given a RHEL virtual machine with the Cisco AnyConnect VPN client installed and running which provides access to the WSC environment.</p>
<p>There are 3 OpenShift clusters you access during the labs. Because of the wide variety of lab material that requires different <a href="https://cloud.redhat.com/learn/topics/operators">operators</a>, each with their own resource and version requirements, it is simpler to divide labs on to multiple clusters.</p>
<p>Each OCP cluster is made up of 3 Control Planes and 3 Compute Nodes as shown in OCP Cluster 1 in the diagram. The Control Planes and Compute Nodes have a minimum of the resources shown for OCP cluster 1, although some clusters have more than the resources listed because of some more intensive applications running on them (IBM Cloud Paks &amp; Foundational Services).</p>
<p>All clusters are running on a single z/VM 7.1 instance on a single LPAR of an IBM z14 (again, not recommended outside of POC/demo).</p>
<p>There are various other support servers running as Linux guests that you use during these labs. These are outside of the OCP cluster itself, but take care of tasks such as LDAP, NFS storage, and a server with the <code>oc</code> command line <a href="https://docs.openshift.com/container-platform/4.9/cli_reference/openshift_cli/getting-started-cli.html">installed</a> that will let you connect to the three OpenShift clusters.</p></section>
                        <h1 class='nav-section-title' id='section-presentations'>
                            Presentations <a class='headerlink' href='#section-presentations' title='Permanent link'>↵</a>
                        </h1>
                        <h1 class='nav-section-title-end'>Ended: Presentations</h1>
                        <h1 class='nav-section-title' id='section-labs'>
                            Labs <a class='headerlink' href='#section-labs' title='Permanent link'>↵</a>
                        </h1>
                        
                        <h2 class='nav-section-title' id='section-exploring-the-openshift-console'>
                            Exploring the OpenShift Console <a class='headerlink' href='#section-exploring-the-openshift-console' title='Permanent link'>↵</a>
                        </h2>
                        <section class="print-page" id="lab001-lab001-1"><h1 id="lab001-lab001-1-exploring-the-openshift-console">Exploring the OpenShift Console<a class="headerlink" href="#lab001-lab001-1-exploring-the-openshift-console" title="Permanent link">&para;</a></h1>
<p>The OpenShift Container Platform web console is a user interface accessible from a web browser.</p>
<p>Developers can use the web console to <a href="https://docs.openshift.com/container-platform/4.8/web_console/odc-about-developer-perspective.html">visualize, browse, and manage the contents of projects</a>.</p>
<p><img alt="openshift-console" src="../images/openshift-console.png" /></p>
<p>Administrators can use the web console to monitor the status of the applications running on the cluster, <a href="https://docs.openshift.com/container-platform/4.8/web_console/using-dashboard-to-get-cluster-information.html">along with the cluster itself</a>.</p>
<p><img alt="openshift-console-admin" src="../images/openshift-console-admin.png" /></p>
<p><a href="https://docs.openshift.com/container-platform/4.8/web_console/configuring-web-console.html">The web console can be customized</a> to suit an organization's needs, and when you log into the web console, you will only see the cluster resources that are available to you as allowed by the OpenShift Role Based Access Control (RBAC).</p>
<p>The web console runs as a group of pods on the control plane nodes in the <code>openshift-console</code> project, along with a service exposed as a route.</p></section><section class="print-page" id="lab001-lab001-2"><h1 id="lab001-lab001-2-connect-to-ocp-and-authenticate">Connect to OCP and Authenticate<a class="headerlink" href="#lab001-lab001-2-connect-to-ocp-and-authenticate" title="Permanent link">&para;</a></h1>
<ol>
<li>
<p>In your virtual machine desktop, <strong>open a Firefox web browser</strong>.</p>
</li>
<li>
<p>In the browser, <strong>navigate to the OpenShift on IBM Z console</strong> at the following address: <a href="https://console-openshift-console.apps.atsocppa.dmz/">https://console-openshift-console.apps.atsocppa.dmz/</a></p>
<details class="note" open="open"><summary>Note</summary><p>You will receive a security challenge if the cluster has not yet been accessed from your browser. This is due to the default SSL certificate being “self-signed” and not yet recognized.</p>
<p>Accept the challenge to continue by <strong>clicking Advanced</strong> and then <strong>clicking Proceed to console-openshift-console.apps.atsocppa.dmz (unsafe)</strong>.</p>
<p>You will likely need to do this twice due to how OpenShift reroutes Oauth requests. </p>
</details>
<details><summary>Expand for screenshot</summary><p><img alt="security-accept.png" src="../images/security-accept.png" />
<img alt="security-accept-2.png" src="../images/security-accept-2.png" /></p>
</details>
<p>You will now see the OpenShift console login page.</p>
<p><img alt="openshift-console-login" src="../images/openshift-console-login.png" /></p>
</li>
<li>
<p><strong>Log in with the OpenShift credentials</strong> provided to you on the <a href="#lab-assignments">Lab Assignments</a> page.</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>Your OpenShift credentials will be something like the following:</p>
<ul>
<li>
<p>Username: userNN (where NN is your user number)</p>
</li>
<li>
<p>Password: p@ssw0rd</p>
</li>
</ul>
</div>
</li>
</ol></section><section class="print-page" id="lab001-lab001-3"><h1 id="lab001-lab001-3-the-administrator-perspective">The Administrator Perspective<a class="headerlink" href="#lab001-lab001-3-the-administrator-perspective" title="Permanent link">&para;</a></h1>
<p>Take a moment to notice the following elements in the navigation bar:</p>
<p><img alt="navigation-bar.png" src="../images/navigation-bar.png" /></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>These buttons display on each page of the OpenShift console. Note that the Applications button might be missing from your screen, depending on your credentials.</p>
</div>
<p>By default, the menu on the left side of the page should be activated and displaying the cluster menu.</p>
<ol>
<li>
<p>In the left-side menu, <strong>select the Administrator perspective</strong> if it isn't already showing.</p>
<p><img alt="administrator-perspective.png" src="../images/administrator-perspective.png" /></p>
<p>With the administrator menu showing, you are provided with a broad range of options to manage the OpenShift cluster and the applications running on it.</p>
<p><img alt="administrator-menu.png" src="../images/administrator-menu.png" /></p>
<details class="information"><summary>Expand to Learn More About the Different Views</summary><ul>
<li>
<p><em>Developer / Administrator toggle</em>.  This lets you flip between which of the two perspectives you want to use.</p>
</li>
<li>
<p><em>Home</em>: Provides overview of projects, resources, and events in the scope of your credentials.</p>
</li>
<li>
<p><em>Operators</em>: Provides access to the OperatorHub to install new operators and also lets you view operators that are already installed.</p>
</li>
<li>
<p><em>Workloads</em>: Expands to provide access to many Kubernetes and OpenShift objects, such as pods, deployments, secrets, jobs and more.</p>
</li>
<li>
<p><em>Networking</em>: Provides access to services, routes, and ingresses required for external access to the cluster.</p>
</li>
<li>
<p><em>Storage</em>: Provides access to storage objects in the OpenShift cluster, such as PersistentVolumeClaims.</p>
</li>
<li>
<p><em>Builds</em>: View and create Build objects – use to transform input parameters into resulting objects.</p>
</li>
<li>
<p><em>Pipelines</em>: View and create Pipelines – Tekton-based CI/CD processes and objects. This will be missing if not installed in your OpenShift cluster.</p>
</li>
<li>
<p><em>Monitoring</em>: Access cluster resource Monitoring, Metrics, and Alerting.</p>
</li>
<li>
<p><em>Compute</em>: Access cluster infrastructure – Control &amp; Compute Nodes, Machines, and more.</p>
</li>
<li>
<p><em>User Management</em>: Access and manage Users, Groups, Roles, RoleBindings, Service Accounts, and more.</p>
</li>
<li>
<p><em>Administration</em>: View and edit cluster settings.</p>
</li>
</ul>
</details>
<p>The <em>Administrator</em> perspective is the default view for the OpenShift console for users who have an administrative access level. This perspective provides visibility into options related to cluster administration, as well as a broader view of the projects associated with the currently logged-in user.</p>
</li>
<li>
<p>In the Menu, <strong>click Home -&gt; Projects</strong>.</p>
<p><img alt="home-projects.png" src="../images/home-projects.png" /></p>
<p>The rest of the page is populated by projects. A project has been created for you to work in named userNN-project (where NN is your user number).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Any project starting with <em>openshift-</em> or <em>kube-</em> contain the workloads running the OpenShift platform itself.</p>
</div>
</li>
<li>
<p><strong>Click the userNN-project hyperlink</strong> (where NN is your user number).</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>With so many Projects displayed, you can use the search bar to find yours more easily.</p>
</div>
<p>You will now see the Dashboard for your project.</p>
<p><img alt="empty-openshift-project.png" src="../images/empty-openshift-project.png" /></p>
</li>
<li>
<p><strong>Scroll down the Overview tab of your project</strong>.</p>
<p>This displays information about what’s going on in your project, such as CPU and memory usage, any alerts or crashlooping pods, an inventory of all the Kubernetes resources deployed in the project, and more. You won’t see much information yet, as no workloads should be running in this project.</p>
</li>
<li>
<p><strong>Click the Workloads tab</strong> to the right of YAML.</p>
<p>This page displays all of the workloads in your project, so it’s empty for now.</p>
<details class="note" open="open"><summary>Note</summary><p>All objects in OpenShift are generated using YAML files. YAML (standing for Yet Another Markup Language) is meant to be a human-readable language for configuration files. Any OpenShift object such as Deployments, Services, Routes, and nearly everything else can be modified by directly editing their YAML file in either the console or command line.</p>
</details>
<p>Workloads are typically created by developers, so in the next section, you will swap to the developer perspective to deploy a an application. You will return to the administrator perspective later in this lab.</p>
</li>
</ol></section><section class="print-page" id="lab001-lab001-4"><h1 id="lab001-lab001-4-the-developer-perspective">The Developer Perspective<a class="headerlink" href="#lab001-lab001-4-the-developer-perspective" title="Permanent link">&para;</a></h1>
<ol>
<li>
<p>In the left-side Menu, <strong>click the Administrator dropdown, and select Developer</strong>.</p>
<p><img alt="developer-perspective.png" src="../images/developer-perspective.png" /></p>
<p>The <em>Developer</em> perspective provides views and workflows specific to developer use cases, while hiding many of the cluster management options typically used by administrators. This perspective provides developers with a streamlined view of the options they typically use.</p>
<p><img alt="developer-menu.png" src="../images/developer-menu.png" /></p>
<details class="information"><summary>Expand to Learn More About the Different Views</summary><ul>
<li>
<p><em>+Add</em>: Clicking on this will open a prompt letting you add a workload to your current project.</p>
</li>
<li>
<p><em>Topology</em>: Displays all of the deployed workloads in the currently selected project.</p>
</li>
<li>
<p><em>Monitoring</em>: Lets you view the monitoring dashboard for just this project.</p>
</li>
<li>
<p><em>Search</em>: Used to search for any type of API resource present in this project, provided you have access to that resource type.</p>
</li>
<li>
<p><em>Builds</em>: This will let you view or create Build Configurations in the currently selected project.</p>
</li>
<li>
<p><em>Pipelines</em>: View and create Pipelines – Tekton-based CI/CD processes and objects.</p>
</li>
<li>
<p><em>Helm</em>: Displays the Helm releases in this project, or prompts you to install one from the catalog if none are present.</p>
</li>
<li>
<p><em>Project</em>: Takes you to your project overview page, the project inventory, events, utilization, and more.</p>
</li>
<li>
<p><em>Config Maps</em>: Displays Config Maps for your project, which store non-confidential data in key-value pairs.</p>
</li>
<li>
<p><em>Secrets</em>: Displays Secrets for your project. Used to store sensitive, confidential data in key-value pairs, tokens, or passwords.</p>
</li>
</ul>
</details>
</li>
</ol>
<p>Switching to the Developer perspective takes you to the <em>Topology</em> view. If no workloads are deployed in the selected project, options to start building an application or visit the +Add page or are displayed.</p>
<p>If you ended up on a page other than Topology, continue with step 1 below anyways.</p>
<ol>
<li>
<p><strong>Click the +Add button in the menu</strong>.</p>
<p><img alt="add-workload-notes.png" src="../images/add-workload-notes.png" /></p>
<details class="information"><summary>Expand to learn about Deployment Methods</summary><p>There are multiple methods of deploying workloads from the OpenShift web browser.</p>
<ul>
<li><em>Samples</em>: Red Hat provides sample applications in various languages. Use these to see what a pre-made application running in OpenShift can look like.</li>
<li><em>From Git</em>: Use this option to import an existing codebase in a Git repository to create, build, and deploy an application.</li>
<li><em>From Devfile</em>: Similar to From Git, use this option to import a Devfile from your Git repository to build and deploy an application.</li>
<li><em>Container Image</em>: Use existing images from an image stream or registry to deploy it.</li>
<li><em>From Catalog</em>: Explore the Developer Catalog to select the required applications, services, or source to image builders and add it to your project.</li>
<li><em>From Dockerfile</em>: Import a dockerfile from your Git repository to build and deploy an application.</li>
<li><em>YAML</em>: Use the editor to add YAML or JSON definitions to create and modify resources.</li>
<li><em>Database</em>: Filters the Developer Catalog to display only the databases it contains.</li>
<li><em>Operator Backed</em>: Deploy applications that are managed by Operators. Many of these will come from the OperatorHub.</li>
<li><em>Helm Chart</em>: Deploy applications defined by Helm Charts, which provide simple installations, upgrades, rollbacks, and generally reduced complexity.</li>
<li><em>Pipeline</em>: Create a Tekton-based Pipeline to automate application creation and delivery using OpenShift’s built-in CI/CD capabilities.</li>
</ul>
</details>
<p>In the next section, you will deploy an application from the OpenShift Developer Catalog.</p>
</li>
</ol></section><section class="print-page" id="lab001-lab001-5"><h1 id="lab001-lab001-5-deploy-from-the-developer-catalog">Deploy from the Developer Catalog<a class="headerlink" href="#lab001-lab001-5-deploy-from-the-developer-catalog" title="Permanent link">&para;</a></h1>
<p>In this section, you will be building a sample application from a template. The template will create two pods:</p>
<ul>
<li>
<p>A Ruby on Rails blogging application from source code in GitHub</p>
</li>
<li>
<p>A PostgreSQL database from a container image</p>
</li>
</ul>
<details class="info" open="open"><summary>Info</summary><p>A <em>container image</em> holds a set of software that is ready to run, while a <em>container</em> is a running instance of a container image. Images can be hosted in registries, such as the OpenShift internal registry, the Red Hat registry, Docker Hub, or a private registry of your own.</p>
</details>
<ol>
<li>
<p><strong>Click the All Services option in the Developer Catalog section</strong> on the +Add page.</p>
<p>This brings up the OpenShift Developer catalog containing all types of applications you can deploy including Operators, Helm Charts, Templates, and more.</p>
</li>
<li>
<p><strong>Find and click the Rails + PostgreSQL (Ephemeral) tile</strong>.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>You can search for <em>Rails + PostgreSQL (Ephemeral</em>) in the search bar.</p>
</div>
<p><img alt="rails-tile.png" src="../images/rails-tile.png" /></p>
</li>
<li>
<p><strong>Click Instantiate Template</strong> on the next screen that appears.</p>
<p>You are brought to a page full of configurable parameters that you can edit if so desired. Notice that all of the required fields on this page automatically populate. You can read through all of the options, but there is no need to edit any of them.</p>
</li>
<li>
<p><strong>Click the Create button</strong> at the bottom of the page.</p>
<p>You will now be taken to the topology view, where you will see two icons – one for each of the two workload pods that the template will create. If you don’t see the icons right away, you may need to refresh your browser window.</p>
<details class="info" open="open"><summary>Info</summary><p>The Ruby on Rails application will take a few minutes to fully deploy, while the PostgreSQL application will deploy in just a few seconds. The reason for this difference is that the Ruby application is being built (containerized) from Ruby source code located in the GitHub repository located here: <a href="https://github.com/sclorg/rails-ex.git">https://github.com/sclorg/rails-ex.git</a> into a container image, and then deployed. If you would like to watch the steps that OpenShift is taking to build the containerized application, <strong>click the circle labeled rails-postgresql-example, click the Resources tab, and click View Logs in the Builds section</strong>.</p>
<p>The PostgreSQL application, on the other hand, is deployed from a pre-built container image hosted in quay.io, so it takes much less time to start up.</p>
</details>
<p>You will know that both applications are successfully deployed and running when each icon has a solid blue circle.</p>
<p><img alt="running-pods.png" src="../images/running-pods.png" /></p>
</li>
<li>
<p><strong>Click the icon for the rails-postgresql-example application</strong>. This will bring up a window on the right side of the screen with information about your DeploymentConfig.</p>
</li>
<li>
<p><strong>Click the Details tab</strong> if it is not already selected.</p>
<p><img alt="rails-details.png" src="../images/rails-details.png" /></p>
<p>Here you’ll see information about your DeploymentConfig. Notice that many of the fields such as Labels, Update Strategy, and more have been populated with default values. These can be modified.</p>
</li>
<li>
<p><strong>Click the Actions dropdown</strong>.</p>
<p><img alt="actions-dropdown.png" src="../images/actions-dropdown.png" /></p>
<p>Many application configurations can be modified from this menu, along with other tasks such as starting or pausing a rollout, or deleting the deployment configuration.</p>
</li>
<li>
<p><strong>Click the up arrow</strong> next to the blue circle.</p>
<p><img alt="scaling-up.png" src="../images/scaling-up.png" /></p>
<p>This scales your application from one pod to two pods.</p>
<p><img alt="scaled-up.png" src="../images/scaled-up.png" /></p>
<details class="note" open="open"><summary>Note</summary><p>This is a simple demonstration of horizontal scaling with Kubernetes. You now have two instances of your pod running in the OpenShift cluster. Traffic to the Rails application will now be distributed to each pod, and if for some reason a pod is lost, that traffic will be redistributed to the remaining pods until a Kubernetes starts another. If a whole compute node is lost, Kubernetes will move the pods to different compute nodes.</p>
<p>OpenShift and Kubernetes also support autoscaling of pods based on CPU or memory consumption, but that is outside the scope of this lab.  </p>
</details>
</li>
<li>
<p><strong>Click the Resources tab</strong>.</p>
<p><img alt="resources-tab.png" src="../images/resources-tab.png" /></p>
<p>Notice the two pods associated with your Rails application. On this page, you’ll see more information about your pods, any build configurations currently running or completed, and the services/ports associated with the pod.</p>
</li>
<li>
<p><strong>Click the route address at the bottom of the resources tab</strong>.</p>
<details><summary>Expand for a Tip</summary><p>You could also access this route by clicking on the external link icon associated with your Rails pod on the Topology view.</p>
<p><img alt="external-link.png" src="../images/external-link.png" /></p>
</details>
<p><img alt="rails-dashboard.png" src="../images/rails-dashboard.png" /></p>
<p>If you see the page above, your Rails application is up and running. You just deployed a Ruby on Rails application from source code residing in GitHub, and connected it to a PostgreSQL container deployed from a container image pulled from quay.io into OpenShift running on an IBM Z server.</p>
<p>Feel free to read through the Rails application homepage to learn more about what this application can do.</p>
</li>
<li>
<p><strong>Add</strong> <code>/articles</code> <strong>to the end of the Rails homepage URL</strong>.</p>
<p>This will result in a URL like the following:</p>
<p><a href="http://rails-postgresql-example-userNN-project.apps.atsocppa.dmz/articles">http://rails-postgresql-example-userNN-project.apps.atsocppa.dmz/articles</a></p>
<p>Where <code>NN</code> is your user number.</p>
<p><img alt="listing-articles.png" src="../images/listing-articles.png" /></p>
<p>You are now interacting with the blogging application that’s shipped with the Rails source code. If you create a new article, the contents for the Title and Body are stored in the PostgreSQL database in the other pod that makes up this application.</p>
<p>In the next section you will navigate back to the Administrator perspective to see the overview of your project with a workload running.</p>
</li>
</ol></section><section class="print-page" id="lab001-lab001-6"><h1 id="lab001-lab001-6-view-workload-from-the-administrator-perspective">View Workload from the Administrator Perspective<a class="headerlink" href="#lab001-lab001-6-view-workload-from-the-administrator-perspective" title="Permanent link">&para;</a></h1>
<ol>
<li>
<p>In the left-side menu, <strong>select the Administrator perspective</strong>.</p>
<p><img alt="administrator-perspective.png" src="../images/administrator-perspective.png" /></p>
</li>
<li>
<p><strong>Navigate back to your project by clicking Menu -&gt; Home -&gt; Projects -&gt; userNN-project</strong>.</p>
<p>The overview page now displays data about the CPU and Memory Usage, new objects in your project inventory, and new activity in the events panel.</p>
<p><img alt="populated-project.png" src="../images/populated-project.png" /></p>
</li>
<li>
<p><strong>Click View Events</strong> under the right-side panel.</p>
<p><img alt="project-events.png" src="../images/project-events.png" /></p>
<p>This page is populated with all of the events associated with your project, including errors, container creation messages, pod scaling and deletion, and much more. You can filter by type, category, or by searching for keywords.</p>
<details class="note" open="open"><summary>Note</summary><p>Feel free to click through a few more pages from the left-side main menu. You’ll notice a few of them have objects created as a part of the Rails-PostgreSQL application, such as Workloads  Pods, Networking  Services and Routes, Builds  Image Streams. These were all created as part of the template package.</p>
</details>
</li>
<li>
<p><strong>Navigate back your project</strong> as in the previous step (or by clicking your browser’s back button).</p>
</li>
<li>
<p><strong>Find the Inventory on the project page</strong> which lists all of the objects created as part of your application</p>
</li>
</ol></section><section class="print-page" id="lab001-lab001-7"><h1 id="lab001-lab001-7-cleaning-up">Cleaning Up<a class="headerlink" href="#lab001-lab001-7-cleaning-up" title="Permanent link">&para;</a></h1>
<ol>
<li>
<p><strong>Navigate back your project</strong> as in the previous section (or by clicking your browser’s back button).</p>
</li>
<li>
<p><strong>Find the Inventory on the project page</strong> which lists all of the objects created as part of your application</p>
</li>
<li>
<p><strong>Click the Deployment Configs hyperlink</strong>.</p>
<p><img alt="project-inventory.png" src="../images/project-inventory.png" /></p>
</li>
<li>
<p>For both of the 2 Deployment Configs that appear <strong>click the three dots on the right side of the screen, and then click Delete Deployment Config.</strong></p>
<p><img alt="delete-dc.png" src="../images/delete-dc.png" /></p>
<p>This will delete some, but not all of the resources created by the application template. The running pods will be stopped and deleted, but some other components will remain. This is not a problem in the case of these labs.</p>
</li>
</ol></section><h1 class='nav-section-title-end'>Ended: Exploring the OpenShift Console</h1>
                        <h2 class='nav-section-title' id='section-using-the-openshift-command-line-oc-'>
                            Using the OpenShift Command Line (oc) <a class='headerlink' href='#section-using-the-openshift-command-line-oc-' title='Permanent link'>↵</a>
                        </h2>
                        <section class="print-page" id="lab002-lab002-1"><h1 id="lab002-lab002-1-the-openshift-command-line-oc">The OpenShift Command Line (oc)<a class="headerlink" href="#lab002-lab002-1-the-openshift-command-line-oc" title="Permanent link">&para;</a></h1>
<p>The OpenShift command line <code>oc</code> is a command line tool that can be used to create applications and manage OpenShift projects. <code>oc</code> is ideal in situations where you:</p>
<ul>
<li>Work directly with project source code.</li>
<li>Script OpenShift Container Platform operations.</li>
<li>Are restricted by bandwidth resources and cannot use the web console.</li>
</ul>
<p>Furthermore, many people familiar with Linux and/or Kubernetes tend to find the <code>oc</code> command line an easier and more efficient method of performing tasks, rather than the web-based console.</p>
<p>Like with the OpenShift web console, the OpenShift command line includes functions both <a href="https://docs.openshift.com/container-platform/4.9/cli_reference/openshift_cli/developer-cli-commands.html">for developers</a> and for <a href="https://docs.openshift.com/container-platform/4.9/cli_reference/openshift_cli/administrator-cli-commands.html">administrators</a>.</p></section><section class="print-page" id="lab002-lab002-2"><h1 id="lab002-lab002-2-log-into-openshift-using-the-cli">Log into OpenShift Using the CLI<a class="headerlink" href="#lab002-lab002-2-log-into-openshift-using-the-cli" title="Permanent link">&para;</a></h1>
<p>In this section, you will be connecting to a “Linux Guest” server which has a few things set up to make your life a little easier. Most notably, it has the OpenShift command line <code>oc</code> installed, so you don’t have to install it on your RHEL VM terminal.</p>
<ol>
<li>
<p><strong>Open a Terminal session</strong></p>
</li>
<li>
<p><strong>ssh into the Linux Guest server</strong>: <code>ssh userNN@192.168.176.61</code> (where NN is your user number).</p>
</li>
<li>
<p>When prompted, <strong>enter your password</strong>: <code>p@ssw0rd</code> and <strong>hit enter</strong>.</p>
<details class="example" open="open"><summary>Example Output</summary><p><img alt="ascii-wsc.png" src="../images/ascii-wsc.png" /></p>
</details>
</li>
<li>
<p>In Firefox, <strong>navigate to the following URL</strong> to request an API token:</p>
<p><a href="https://oauth-openshift.apps.atsocppa.dmz/oauth/token/request">https://oauth-openshift.apps.atsocppa.dmz/oauth/token/request</a></p>
</li>
<li>
<p><strong>Enter your OpenShift credentials when prompted</strong>.</p>
<ul>
<li>
<p>Username: userNN</p>
</li>
<li>
<p>Password: p@ssw0rd</p>
</li>
</ul>
</li>
<li>
<p><strong>Click the “Display Token” hyperlink</strong>.</p>
<p><img alt="display-token.png" src="../images/display-token.png" /></p>
</li>
<li>
<p><strong>Copy the contents of the first text box</strong> beginning with “oc login” and ending with “6443”.</p>
<p><img alt="oc-login-token.png" src="../images/oc-login-token.png" /></p>
</li>
<li>
<p><strong>Paste this command back in your terminal session and press enter</strong>.</p>
<div class="highlight"><pre><span></span><code>oc login --token=&lt;YOUR_TOKEN_HERE&gt; --server=https://api.atsocppa.dmz:6443
</code></pre></div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>If you’re prompted to use an insecure connection, type Y and hit enter.</p>
</div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ oc login --token=uL3fHEPSGH3io0htdGRfAMAPIIY44BhwnGxCMA3dei4 --server=https://api.atsocppa.dmz:6443
Logged into &quot;https://api.atsocppa.dmz:6443&quot; as &quot;user01&quot; using the token provided.

You have access to 161 projects, the list has been suppressed. You can list all projects with &#39;oc projects&#39;

Using project &quot;user01-project&quot;.
</code></pre></div>
</details>
<p>You are now logged into the cluster via the command line, and you are told which project you are using.</p>
<p>If you’re in a project other than userNN-project, use the following command to move into it: <code>oc project userNN-project</code>, where NN is your user number.</p>
</li>
</ol></section><section class="print-page" id="lab002-lab002-3"><h1 id="lab002-lab002-3-overview-of-the-openshift-cli">Overview of the OpenShift CLI<a class="headerlink" href="#lab002-lab002-3-overview-of-the-openshift-cli" title="Permanent link">&para;</a></h1>
<ol>
<li>
<p>In your terminal, <strong>enter the command</strong>:</p>
<div class="highlight"><pre><span></span><code>oc --help
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ oc --help
OpenShift Client

This client helps you develop, build, deploy, and run your applications on any
OpenShift or Kubernetes cluster. It also includes the administrative
commands for managing a cluster under the &#39;adm&#39; subcommand.

Usage:
oc [flags]

Basic Commands:
login           Log in to a server
new-project     Request a new project
new-app         Create a new application
status          Show an overview of the current project
project         Switch to another project
projects        Display existing projects
explain         Documentation of resources

Build and Deploy Commands:
rollout         Manage a Kubernetes deployment or OpenShift deployment config
rollback        Revert part of an application back to a previous deployment
new-build       Create a new build configuration
start-build     Start a new build
</code></pre></div>
</details>
<p>The <code>--help</code> flag will display all of the available options the oc CLI.</p>
</li>
<li>
<p><strong>Enter the following command</strong></p>
<div class="highlight"><pre><span></span><code>oc new-app --help
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ oc new-app --help
Create a new application by specifying source code, templates, and/or images

This command will try to build up the components of an application using images, templates, or code
that has a public repository. It will lookup the images on the local Docker installation (if
available), a container image registry, an integrated image stream, or stored templates.

If you specify a source code URL, it will set up a build that takes your source code and converts
it into an image that can run inside of a pod. Local source must be in a git repository that has a
remote repository that the server can see. The images will be deployed via a deployment
configuration, and a service will be connected to the first public port of the app. You may either
specify components using the various existing flags or let new-app autodetect what kind of
components you have provided.

If you provide source code, a new build will be automatically triggered. You can use &#39;oc status&#39; to
check the progress.

Usage:
oc new-app (IMAGE | IMAGESTREAM | TEMPLATE | PATH | URL ...) [flags]

Examples:
# List all local templates and image streams that can be used to create an app
oc new-app --list

# Create an application based on the source code in the current git repository (with a public
remote) and a Docker image
oc new-app . --docker-image=repo/langimage
</code></pre></div>
</details>
<p>The <code>--help</code> flag now displays all of the available options for the oc new-app command. If you get confused about any of the commands we use in this workshop, or just want more information, using this flag is a good first step.</p>
</li>
</ol></section><section class="print-page" id="lab002-lab002-4"><h1 id="lab002-lab002-4-deploy-container-image-from-the-cli">Deploy Container Image from the CLI<a class="headerlink" href="#lab002-lab002-4-deploy-container-image-from-the-cli" title="Permanent link">&para;</a></h1>
<p><code>oc new-app</code> is a powerful and commonly used command in the OpenShift CLI. It has the ability to deploy applications from components that include:</p>
<ul>
<li>Source or binary code</li>
<li>Container images</li>
<li>Templates</li>
</ul>
<p>The set of objects created by <code>oc new-app</code> depends on the artifacts passed as an input.</p>
<ol>
<li>
<p><strong>Run the following command to start a MongoDB deployment from a template</strong>:</p>
<div class="highlight"><pre><span></span><code>oc new-app --template=mongodb-ephemeral
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ oc new-app --template=mongodb-ephemeral
--&gt; Deploying template &quot;openshift/mongodb-ephemeral&quot; to project user01-project

MongoDB (Ephemeral)
---------
MongoDB database service, without persistent storage. For more information about using this template, including OpenShift considerations, see documentation in the upstream repository: https://github.com/sclorg/mongodb-container.

WARNING: Any data stored will be lost upon pod destruction. Only use this template for testing

The following service(s) have been created in your project: mongodb.

        Username: userFUX
        Password: AXGgm5dnKY44Byuk
Database Name: sampledb
Connection URL: mongodb://userFUX:AXGgm5dnKY44Byuk@mongodb/sampledb

For more information about using this template, including OpenShift considerations, see documentation in the upstream repository: https://github.com/sclorg/mongodb-container.

* With parameters:
    * Memory Limit=512Mi
    * Namespace=openshift
    * Database Service Name=mongodb
    * MongoDB Connection Username=userFUX # generated
    * MongoDB Connection Password=AXGgm5dnKY44Byuk # generated
    * MongoDB Database Name=sampledb
    * MongoDB Admin Password=JibwnlSwiow18owJ # generated
    * Version of MongoDB Image=3.6

--&gt; Creating resources ...
    secret &quot;mongodb&quot; created
    service &quot;mongodb&quot; created
    deploymentconfig.apps.openshift.io &quot;mongodb&quot; created
--&gt; Success
    Application is not exposed. You can expose services to the outside world by executing one or more of the commands below:
    &#39;oc expose svc/mongodb&#39; 
    Run &#39;oc status&#39; to view your app.
</code></pre></div>
</details>
<details class="note" open="open"><summary>Note</summary><p>Notice a few things:</p>
<ul>
<li>
<p>OpenShift went out and found a template that matches your desired deployment – MongoDB-ephemeral.</p>
</li>
<li>
<p>You’re told what exactly is going to be created and what it will be named.</p>
</li>
<li>
<p>Those objects are then created within your project space.</p>
</li>
<li>
<p>You’re told that the application was successfully deployed, but it is not yet exposed. This means that it’s running, but it’s not accessible from outside the cluster.</p>
</li>
</ul>
</details>
</li>
<li>
<p><strong>Run the following command</strong> to view the app in your project space:</p>
<div class="highlight"><pre><span></span><code>oc status
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ oc status
In project user01-project on server https://api.atsocppa.dmz:6443

svc/mongodb - 172.30.94.118:27017
dc/mongodb deploys istag/mongodb:latest 
    deployment #1 deployed 3 minutes ago - 1 pod

View details with &#39;oc describe &lt;resource&gt;/&lt;name&gt;&#39; or list everything with &#39;oc get all&#39;.
</code></pre></div>
</details>
<ol>
<li>Now <strong>run the following command</strong> to see all of the objects that were built:</li>
</ol>
<div class="highlight"><pre><span></span><code>oc get all
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ oc get all
NAME                 READY   STATUS      RESTARTS   AGE
pod/mongodb-1-deploy   0/1     Completed   0          5m30s
pod/mongodb-1-sj6mk    1/1     Running     0          5m22s

NAME                            DESIRED   CURRENT   READY   AGE
replicationcontroller/mongodb-1   1         1         1       5m30s

NAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)     AGE
service/mongodb   ClusterIP   172.30.94.118   &lt;none&gt;        27017/TCP   5m32s

NAME                                       REVISION   DESIRED   CURRENT   TRIGGERED BY
deploymentconfig.apps.openshift.io/mongodb   1          1         1       config,image(mongodb:3.6)
</code></pre></div>
</details>
<p>These are the objects that OpenShift told us would be created, and they all work together to run the application. While they’re all important pieces of this puzzle, <em>pods</em> are where the application code is actually running. Let’s narrow down on our pods.</p>
<details class="note" open="open"><summary>Note</summary><p>You might also have objects left over from other labs if they were not completely cleaned out. This is okay and the objects for different applications will not interfere with one another due to their use of <em>labels</em>.</p>
</details>
</li>
<li>
<p><strong>Run the command</strong>:</p>
<div class="highlight"><pre><span></span><code>oc get pods
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ oc get pods
NAME             READY   STATUS      RESTARTS   AGE
mongodb-1-deploy   0/1     Completed   0          28s
mongodb-1-r8dpw    1/1     Running     0          19s
</code></pre></div>
</details>
<p>The <code>oc new-app</code> command created two pods. One ending with “deploy”, and the other ending with a randomly-generated string of 5 characters (r8dpw in the screenshot above). They are both associated with your mongo deployment, but one is in a <em>Completed</em> status, and one is <em>Running</em>. The <em>Completed</em> pod had one simple job – scale the other pod to its desired count of 1.</p>
</li>
<li>
<p><strong>Run the following command</strong> to see the logs for the deploy pod</p>
<div class="highlight"><pre><span></span><code>oc logs pod/mongodb-1-deploy
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ oc logs pod/mongodb-1-deploy
--&gt; Scaling mongodb-1 to 1
--&gt; Success
</code></pre></div>
</details>
<p>That’s a pretty simple responsibility. The second pod, ending in the randomly generated string of characters, has a much more complicated job. This is the pod where the MongoDB application code is actually running.</p>
</li>
<li>
<p><strong>Run the following command</strong> to see the logs for the MongoDB deployment:</p>
<div class="highlight"><pre><span></span><code>oc logs pod/mongodb-1-XXXXX
</code></pre></div>
<p>Where <code>XXXXX</code> is your unique string of characters that you saw in the <code>oc get pods</code> output.</p>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ oc logs pod/mongodb-1-r8dpw
2020-04-15T16:56:12.344+0000 I  CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols &#39;none&#39;
2020-04-15T16:56:12.346+0000 W  ASIO     [main] No TransportLayer configured during NetworkInterface startup
2020-04-15T16:56:12.351+0000 I  CONTROL  [initandlisten] MongoDB starting : pid=1 port=27017 dbpath=/data/db 64-bit host=mongo-1-r8dpw
2020-04-15T16:56:12.351+0000 I  CONTROL  [initandlisten] db version v4.2.5
2020-04-15T16:56:12.351+0000 I  CONTROL  [initandlisten] git version: 2261279b51ea13df08ae708ff278f0679c59dc32
2020-04-15T16:56:12.351+0000 I  CONTROL  [initandlisten] OpenSSL version: OpenSSL 1.1.1  11 Sep 2018
2020-04-15T16:56:12.351+0000 I  CONTROL  [initandlisten] allocator: tcmalloc
2020-04-15T16:56:12.351+0000 I  CONTROL  [initandlisten] modules: none
2020-04-15T16:56:12.351+0000 I  CONTROL  [initandlisten] build environment:
2020-04-15T16:56:12.351+0000 I  CONTROL  [initandlisten]     distmod: ubuntu1804
2020-04-15T16:56:12.351+0000 I  CONTROL  [initandlisten]     distarch: s390x
2020-04-15T16:56:12.351+0000 I  CONTROL  [initandlisten]     target_arch: s390x
</code></pre></div>
</details>
<p>This is obviously a much busier pod. One of the first lines in its log tells you which version of MongoDB is running.</p>
</li>
</ol>
<p>In the next section, you will connect to the pod and see that it is actually running MongoDB.</p></section><section class="print-page" id="lab002-lab002-5"><h1 id="lab002-lab002-5-open-a-remote-shell-session-into-the-mongodb-pod">Open a Remote Shell Session into the MongoDB Pod<a class="headerlink" href="#lab002-lab002-5-open-a-remote-shell-session-into-the-mongodb-pod" title="Permanent link">&para;</a></h1>
<p>OpenShift provides <em>Remote Shell</em> capabilities from both the command line and from the web console.</p>
<p>With the <code>oc rsh</code> command, you can issue commands as if you are inside the container and perform local operations like monitoring, debugging, and using CLI commands specific to what is running in the container.</p>
<details class="information" open="open"><summary>Information</summary><p>For example, if you open a remote shell session into a MySQL container, you can count the number of records in the database by invoking the mysql command, then using the prompt to type in the SELECT command. You can also use commands like ps(1) and ls(1) for validation.</p>
</details>
<p>With the MongoDB application you deployed, you can <code>rsh</code> into the MongoDB pod to run <code>mongo</code> CLI commands.</p>
<ol>
<li>
<p><strong>Enter the following command</strong> to rsh into the container:</p>
<div class="highlight"><pre><span></span><code>oc rsh mongo-XXXXX
</code></pre></div>
<p>Where <code>XXXXX</code> is your unique string of 5 characters</p>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ oc rsh mongodb-1-r8dpw
$ 
</code></pre></div>
</details>
<p>This new line that <em>does not</em> start with <code>userNN@lab061</code> indicates that you are now in the remote shell session for the pod</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>If you wait too long to interact with the remote shell (about a minute), it will automatically time-out and you will have to re-connect. You can tell that this happened if the prompt reappears.</p>
</div>
</li>
<li>
<p>In the remote session, <strong>issue the command</strong>:</p>
<div class="highlight"><pre><span></span><code>mongo
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>$ mongo
MongoDB shell version v4.2.5
connecting to: mongodb://127.0.0.1:27017/?compressors=disabled&amp;gssapiServiceName=mongodb
Implicit session: session { &quot;id&quot; : UUID(&quot;2320e01b-168e-41d0-a132-af0c9243d29c&quot;) }
MongoDB server version: 4.2.5
Welcome to the MongoDB shell.
For interactive help, type &quot;help&quot;.
For more comprehensive documentation, see
    http://docs.mongodb.org/
Questions? Try the support group
    http://groups.google.com/group/mongodb-user
</code></pre></div>
</details>
<p><code>mongo</code> is the shell command for MongoDB. Issuing the <code>mongo</code> command without any options or flags connects you to a MongoDB instance running on your localhost with port 27017. If you see this message, MongoDB is up and running in the container.</p>
</li>
<li>
<p><strong>Exit the MongoDB shell by entering the command</strong>:</p>
<div class="highlight"><pre><span></span><code>exit
</code></pre></div>
</li>
<li>
<p><strong>Exit the remote shell session by entering, once again</strong>:</p>
<div class="highlight"><pre><span></span><code>exit
</code></pre></div>
<p>You should be back in the <code>userNN@lab061</code> command line.</p>
</li>
</ol></section><section class="print-page" id="lab002-lab002-6"><h1 id="lab002-lab002-6-working-with-pods">Working with Pods<a class="headerlink" href="#lab002-lab002-6-working-with-pods" title="Permanent link">&para;</a></h1>
<p>One of the main benefits of using containers and Kubernetes-based cloud platforms like OpenShift is the ability to <em>scale horizontally</em> – rapidly duplicating or deleting pods to meet a desired state.</p>
<details class="information" open="open"><summary>Information</summary><p>One of the core concepts of Kubernetes is the <em>Declarative State</em>. Users <em>declare</em> what resources they want, and Kubernetes does whatever it can to make that happen. Scaling is one example of this.</p>
</details>
<p>Scaling essentially creates copies of the application in order to distribute traffic to multiple instances and/or compute nodes for high availability and load balancing.</p>
<ol>
<li>
<p><strong>Enter the following command</strong> to get the name of your MongoDB deploymentconfig (dc)</p>
<div class="highlight"><pre><span></span><code>oc get dc
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ oc get dc
NAME    REVISION   DESIRED   CURRENT   TRIGGERED BY
mongodb   1          1         1         config,image(mongodb:3.6)
</code></pre></div>
</details>
<p>Your deploymentconfig named <code>mongo</code> has a count desired = current = 1.</p>
</li>
<li>
<p><strong>Scale the mongo deployment to 3 replicas</strong>:</p>
<div class="highlight"><pre><span></span><code>oc scale dc/mongodb --replicas=3
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ oc scale dc/mongodb --replicas=3
deploymentconfig.apps.openshift.io/mongodb scaled
</code></pre></div>
</details>
</li>
<li>
<p><strong>Enter the following command again</strong> to see the scaled application.</p>
<div class="highlight"><pre><span></span><code>oc get dc
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ oc get dc
NAME    REVISION   DESIRED   CURRENT   TRIGGERED BY
mongodb   1          3         3         config,image(mongodb:3.6)
</code></pre></div>
</details>
<p>This output is telling you that OpenShift knows that you want three copies (pods) of MongoDB, and it is successfully meeting that declared state.</p>
</li>
<li>
<p><strong>Enter the following command again to see your three pods</strong>:</p>
<div class="highlight"><pre><span></span><code>oc get pods
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ oc get pods
NAME             READY   STATUS      RESTARTS   AGE
mongodb-1-5nmjn    1/1     Running     0          2m6s
mongodb-1-deploy   0/1     Completed   0          20m
mongodb-1-dh49x    1/1     Running     0          2m6s
mongodb-1-r8dpw    1/1     Running     0          19m
</code></pre></div>
</details>
<p>Two of the pods will have a shorter age than the original one – these are the two new pods that were just created when you scaled the application.</p>
</li>
<li>
<p><strong>Dig into the pods a little bit further by entering the following command</strong>:</p>
<div class="highlight"><pre><span></span><code>oc describe pod/mongodb-1-XXXXX
</code></pre></div>
<p>Where <code>XXXXX</code> is one of your unique strings of characters.</p>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ oc describe pod/mongodb-1-5nmjn
Name:               mongodb-1-5nmjn
Namespace:          user01-project
Priority:           0
PriorityClassName:  &lt;none&gt;
Node:               worker-0.atsocppa.dmz/192.168.176.175
Start Time:         Wed, 15 Apr 2020 13:13:53 -0400
Labels:             app=mongodb
                    deployment=mongodb-1
                    deploymentconfig=mongodb
</code></pre></div>
</details>
<p>This command gives you all kinds of information about your pod. Notice the <code>Node:</code> field that begins with <code>worker-#</code>.</p>
</li>
<li>
<p><strong>Run the same command again, but on a different pod this time</strong>:</p>
<div class="highlight"><pre><span></span><code>oc describe pod/mongodb-1-YYYYY
</code></pre></div>
<p>Where <code>YYYYY</code> is one of your other unique strings of characters. Pick one different than the previous step.</p>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ oc describe pod/mongodb-1-r8dpw
Name:               mongodb-1-r8dpw
Namespace:          user01-project
Priority:           0
PriorityClassName:  &lt;none&gt;
Node:               worker-2.atsocppa.dmz/192.168.176.177
Start Time:         Wed, 15 Apr 2020 12:56:03 -0400
Labels:             app=mongodb
                    deployment=mongodb-1
                    deploymentconfig=mongodb
</code></pre></div>
</details>
<p>It is likely (but not guaranteed) that this pod has been placed on a <em>different</em> compute node than the first pod you described. The reason for this is that you have three compute nodes in this OpenShift cluster, and Kubernetes balances the load for this application across multiple nodes.</p>
</li>
</ol></section><section class="print-page" id="lab002-lab002-7"><h1 id="lab002-lab002-7-administrative-cli-commands">Administrative CLI Commands<a class="headerlink" href="#lab002-lab002-7-administrative-cli-commands" title="Permanent link">&para;</a></h1>
<p>If you’ve already completed <a href="#lab001-lab001-1">Exploring the OpenShift Console</a>, you’ll remember that there are both developer and administrator perspectives. The same is true in the OpenShift CLI. </p>
<p>The <code>oc adm</code> command gives cluster administrators the ability to check logs, manage users, groups, policies, certificates, and many other tasks usually associated with administrative roles.</p>
<ol>
<li>
<p><strong>Issue the following command to see all of the OpenShift administrator commands</strong>.</p>
<div class="highlight"><pre><span></span><code>oc adm --help
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ oc adm --help
Administrative Commands

Actions for administering an OpenShift cluster are exposed here.

Usage:
oc adm [flags]

Cluster Management:
upgrade                            Upgrade a cluster
top                                Show usage statistics of resources on the server
must-gather                        Launch a new instance of a pod for gathering debug information

Node Management:
drain                              Drain node in preparation for maintenance
cordon                             Mark node as unschedulable
uncordon                           Mark node as schedulable
taint                              Update the taints on one or more nodes
node-logs                          Display and filter node logs

Security and Policy:
new-project                        Create a new project
policy                             Manage cluster authorization and security policy
groups                             Manage groups
certificate                        Approve or reject certificate requests
pod-network                        Manage pod network

Maintenance:
prune                              Remove older versions of resources from the server
migrate                            Migrate data in the cluster

Configuration:
create-kubeconfig                  Create a basic .kubeconfig file from client certs
create-bootstrap-project-template  Create a bootstrap project template
create-login-template              Create a login template
create-provider-selection-template Create a provider selection template
create-error-template              Create an error page template

Other Commands:
build-chain                        Output the inputs and dependencies of your builds
completion                         Output shell completion code for the specified shell (text or zsh)
config                             Change configuration files for the client
verify-image-signature             Verify the image identity contained in the image signature
</code></pre></div>
</details>
<details class="note" open="open"><summary>Note</summary><p>Your userNN credential has the privileges required to run some, but not all of these commands.</p>
</details>
</li>
<li>
<p><strong>Run the following administrative command to show see usage statistics for pods in your project</strong>.</p>
<div class="highlight"><pre><span></span><code>oc adm top pods
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ oc adm top pods
NAME            CPU(cores)   MEMORY(bytes)   
mongodb-1-5nmjn   3m           83Mi            
mongodb-1-dh49x   3m           83Mi            
mongodb-1-r8dpw   3m           85Mi
</code></pre></div>
</details>
<p>As OpenShift clusters grow in production, administrative commands like this one become more and more essential to keep everything running smoothly.</p>
</li>
</ol></section><section class="print-page" id="lab002-lab002-8"><h1 id="lab002-lab002-8-cleaning-up">Cleaning Up<a class="headerlink" href="#lab002-lab002-8-cleaning-up" title="Permanent link">&para;</a></h1>
<ol>
<li>
<p><strong>Double check that you are in your own userNN-project by issuing the command</strong>:</p>
<div class="highlight"><pre><span></span><code>oc project
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ oc project
Using project &quot;user01-project&quot; on server &quot;https://api.atsocppa.dmz:6443&quot;.
</code></pre></div>
</details>
</li>
<li>
<p><strong>Once you’re sure you’re in your own project, issue the following command to delete all objects associated with your application labeled mongodb-ephemeral</strong>.  </p>
<div class="highlight"><pre><span></span><code>oc delete all --selector app=mongodb-ephemeral -o name
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ oc delete all --selector app=mongodb-ephemeral -o name
replicationcontroller/mongodb-1
service/mongodb
deploymentconfig.apps.openshift.io/mongodb
</code></pre></div>
</details>
</li>
<li>
<p><strong>Run the following command to check that all of your mongo application resources were deleted</strong>:</p>
<div class="highlight"><pre><span></span><code>oc get all
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ oc get all
No resources found.
user00@lab061:~$
</code></pre></div>
</details>
</li>
<li>
<p>(<strong><em>Optional</em></strong>) <strong>If there are leftover resources from other labs that you would like to delete, run the command</strong>:</p>
<div class="highlight"><pre><span></span><code>oc delete all --all
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ oc delete all --all
pod &quot;rails-postgresql-example-1-build&quot; deleted
service &quot;postgresql&quot; deleted
service &quot;rails-postgresql-example&quot; deleted
buildconfig.build.openshift.io &quot;rails-postgresql-example&quot; deleted
build.build.openshift.io &quot;rails-postgresql-example-1&quot; deleted
imagestream.image.openshift.io &quot;rails-postgresql-example&quot; deleted
route.route.openshift.io &quot;rails-postgresql-example&quot; deleted
</code></pre></div>
</details>
</li>
</ol></section><h1 class='nav-section-title-end'>Ended: Using the OpenShift Command Line (oc)</h1>
                        <h2 class='nav-section-title' id='section-deploying-an-application-from-source-code'>
                            Deploying an Application from Source Code <a class='headerlink' href='#section-deploying-an-application-from-source-code' title='Permanent link'>↵</a>
                        </h2>
                        <section class="print-page" id="lab004-lab004-1"><h1 id="lab004-lab004-1-deploying-an-application-from-source-code">Deploying an Application from Source Code<a class="headerlink" href="#lab004-lab004-1-deploying-an-application-from-source-code" title="Permanent link">&para;</a></h1>
<p>OpenShift is designed for users with various responsibilities, backgrounds and skillsets. Most broadly, OpenShift is designed for two main groups – <em>administrators</em> and <em>developers</em>. Furthermore, there are different types of administrators, and different types of developers.</p>
<p>As much of the Information Technology world moves toward cloud technology as the consumption model for enterprise computing, developers are required to make a shift in the tools they use to perform their work. At the heart of almost every cloud platform there are two of these new, core technologies – <em>containers</em> and <em>container orchestrators</em>.</p>
<details class="note" open="open"><summary>Note</summary><p>We won’t be specifically covering these technologies in this lab, but you’ve probably heard of them. Docker is the most popular container runtime, and Kubernetes is the most popular container orchestrator. For the curious, OpenShift replaced Docker containers with CRI-O containers when moving from v3.11 to v4.1 (although Docker containers will still work in OpenShift 4.x).</p>
</details>
<p>However, not every developer wants (or needs) to learn these new technologies in order to take advantage of them. In fact, OpenShift enables developers with no container experience at all to simply provide their source code (written in Javascript, Python, Go, etc.) and let OpenShift build the container for them using its <strong><em>Source-to-Image (S2I) capability</em></strong>.</p>
<p><img alt="s2i-diagram" src="../images/s2i-diagram.png" /></p>
<p>OpenShift's S2I capability allows developers to focus on developing their application and leaves the containerization process to OpenShift. Using the S2I tooling and Builder Images loaded into the OpenShift image registry, the developer does not need to create a Dockerfile, use any podman or docker commands, or do anything else that is usually required to make a container image out of application source code.</p></section><section class="print-page" id="lab004-lab004-2"><h1 id="lab004-lab004-2-exploring-github-and-the-example-health-source-code">Exploring GitHub and the Example Health Source Code<a class="headerlink" href="#lab004-lab004-2-exploring-github-and-the-example-health-source-code" title="Permanent link">&para;</a></h1>
<p>In this lab, you will be deploying a sample healthcare application called <em>Example Health</em>. The application is written in JavaScript, and it’s loaded into IBM’s GitHub repository.</p>
<ol>
<li>
<p>In Firefox, <strong>navigate to <a href="https://github.com/IBM/node-s2i-openshift">https://github.com/IBM/node-s2i-openshift</a></strong></p>
<p><img alt="ibm-repo" src="../images/ibm-repo.png" /></p>
<p>This is an IBM repository that contains everything you need in order to deploy the application – including a <code>README.md</code> file with information and instructions, additional files required for the source code to work, and the source code itself. Let’s look at the source code now.</p>
</li>
<li>
<p><strong>Open the site folder</strong>.</p>
<p><img alt="site-dir" src="../images/site-dir.png" /></p>
</li>
<li>
<p><strong>Open the app.js file</strong>.</p>
<p><img alt="app-js" src="../images/app-js.png" /></p>
<p>This is the source code for the frontend application that OpenShift will build into a container. Notice that it is NOT any sort of container image, Dockerfile, or YAML file itself – rather, it is <em>written in Javascript</em>. Feel free to look through the code.</p>
</li>
<li>
<p><strong>Click on the node-s2i-openshift hyperlink</strong> to get back to the main repository page.</p>
<p>Your URL should again be <a href="https://github.com/IBM/node-s2i-openshift">https://github.com/IBM/node-s2i-openshift</a></p>
<p>You’ll need to make a fork of this repository so you have your own copy to work with. To do so, you’ll first need to sign into GitHub.</p>
</li>
<li>
<p><strong>Click the Sign In button in the top right</strong>.</p>
<p><img alt="gh-sign-in" src="../images/gh-sign-in.png" /></p>
</li>
<li>
<p><strong>Log in with YOUR OWN GitHub credentials</strong>.</p>
<details class="note" open="open"><summary>Note</summary><p>If you don’t have a GitHub account already, please create one and then sign in with it.</p>
</details>
<p>After a successful login, you will be taken back to the main repository page. Now you can create your own fork of the repository.</p>
</li>
<li>
<p><strong>Click the Fork button on the left side of the page</strong>.</p>
<p><img alt="gh-fork" src="../images/gh-fork.png" /></p>
<p>When complete, you will be taken to your forked repository page</p>
<p>Notice that while everything else looks basically  the same, the URL has changed from <a href="https://github.com/IBM/node-s2i-openshift">https://github.com/IBM/node-s2i-openshift</a></p>
<p>to:</p>
<p><a href="https://github.com/YOUR_GITHUB_USERNAME/node-s2i-openshift">https://github.com/YOUR_GITHUB_USERNAME/node-s2i-openshift</a></p>
</li>
<li>
<p><strong>Leave this browser tab open, and open another</strong>.</p>
</li>
</ol></section><section class="print-page" id="lab004-lab004-3"><h1 id="lab004-lab004-3-connect-to-ocp-and-authenticate">Connect to OCP and Authenticate<a class="headerlink" href="#lab004-lab004-3-connect-to-ocp-and-authenticate" title="Permanent link">&para;</a></h1>
<ol>
<li>
<p>In your virtual machine desktop, <strong>open a Firefox web browser</strong>.</p>
</li>
<li>
<p>In the browser, <strong>navigate to the OpenShift on IBM Z console</strong> at the following address: <a href="https://console-openshift-console.apps.atsocppa.dmz/">https://console-openshift-console.apps.atsocppa.dmz/</a>.</p>
<details class="note" open="open"><summary>Note</summary><p>You will receive a security challenge if the cluster has not yet been accessed from your browser. This is due to the default SSL certificate being “self-signed” and not yet recognized.</p>
<p>Accept the challenge to continue by <strong>clicking Advanced</strong> and then <strong>clicking Proceed to console-openshift-console.apps.atsocppa.dmz (unsafe)</strong>.</p>
<p>You will likely need to do this twice due to how OpenShift reroutes Oauth requests. </p>
</details>
<details><summary>Expand for screenshot</summary><p><img alt="security-accept.png" src="../images/security-accept.png" />
<img alt="security-accept-2.png" src="../images/security-accept-2.png" /></p>
</details>
<p>You will now see the OpenShift console login page.</p>
<p><img alt="openshift-console-login" src="../images/openshift-console-login.png" /></p>
</li>
<li>
<p>Log in with the OpenShift credentials provided to you on the <a href="#lab-assignments">Lab Assignments</a> page.</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>Your OpenShift credentials will be something like the following:</p>
<ul>
<li>
<p>Username: userNN (where NN is your user number)</p>
</li>
<li>
<p>Password: p@ssw0rd</p>
</li>
</ul>
</div>
</li>
</ol></section><section class="print-page" id="lab004-lab004-4"><h1 id="lab004-lab004-4-edit-the-source-code-and-push-an-update">Edit the Source Code and Push an Update<a class="headerlink" href="#lab004-lab004-4-edit-the-source-code-and-push-an-update" title="Permanent link">&para;</a></h1>
<ol>
<li>
<p><strong>Switch to the Developer Perspective</strong>, if not already on it.</p>
<p><img alt="developer-perspective" src="../images/developer-perspective.png" /></p>
</li>
<li>
<p><strong>Change into your userNN-project</strong> if not already in it.</p>
<p><img alt="userNN-project" src="../images/userNN-project.png" /></p>
</li>
<li>
<p><strong>Click the +Add button from the left-side menu</strong>.</p>
<p><img alt="add-workload" src="../images/add-workload.png" /></p>
</li>
<li>
<p><strong>Click the From Git option in the Git Repository section</strong> of the +Add page.</p>
<p><img alt="from-git" src="../images/from-git.png" /></p>
</li>
<li>
<p><strong>In the Git Repo URL field, enter the URL of your forked repository</strong>.</p>
<p>It will look something like: <a href="https://github.com/YOUR_GITHUB_USERNAME/node-s2i-openshift">https://github.com/YOUR_GITHUB_USERNAME/node-s2i-openshift</a></p>
<p><img alt="import-from-git" src="../images/import-from-git.png" /></p>
</li>
<li>
<p><strong>Click the Show Advanced Git Options hyperlink</strong>.</p>
</li>
<li>
<p><strong>In the Context Dir field, enter <code>/site</code></strong>.</p>
<p><img alt="show-advanced" src="../images/show-advanced.png" /></p>
<details class="note" open="open"><summary>Recall</summary><p>This is the folder in the GitHub repository that you dug into to view the source code.</p>
</details>
</li>
<li>
<p><strong>For Builder Image, select the Node.js tile</strong>. It is likely that OpenShift will detect the programming language in the GitHub repository and automatically select the Node.js builder image.</p>
<p><img alt="node-tile" src="../images/node-tile.png" /></p>
</li>
<li>
<p><strong>Scroll to the bottom of this page and click the Create button</strong>.</p>
<p>You will be taken to the Topology page, which will show your new application along with three smaller circular buttons that can be used to perform different actions against the application.</p>
</li>
<li>
<p><strong>Click the circular Node.js application icon</strong>.</p>
<p><img alt="node-icon" src="../images/node-icon.png" /></p>
<p>At first, the icon will be all white and you will see “Build #1 is running” in the righthand panel. If you wish, you can watch the logs for the running Build to see everything it’s doing. After a minute or two, the icon will have a green check mark next to it, indicating the Build is complete. Once the Build is complete, your Pod will be created. You can also watch the logs for this, if you wish. About 10 seconds later, a solid blue ring will appear around the edge of the circular icon, indicating that the pod is up and running.</p>
<p><img alt="node-panel" src="../images/node-panel.png" /></p>
<details class="note" open="open"><summary>Note</summary><p>Feel free to click on the <em>View Logs</em> hyperlink to watch everything that the build is creating. When complete, the log will display <code>Push Successful</code>, and you can return to the Topology page by clicking the link on the left side of the page.</p>
</details>
<p>If you clicked off of the Node.js application Resources tab, click on the circular icon again, then click on the Resources tab.</p>
</li>
<li>
<p><strong>Click the Route URL</strong> – beginning with http://</p>
<p><img alt="route-url" src="../images/route-url.png" /></p>
<p>You will be taken to the Example Health application.</p>
<p><img alt="example-health-login" src="../images/example-health-login.png" /></p>
</li>
<li>
<p><strong>Log into the Example Health application using the following credentials</strong>:</p>
<ul>
<li>
<p>Username: <code>test</code></p>
</li>
<li>
<p>Password: <code>test</code></p>
</li>
</ul>
<p><img alt="example-health-patient" src="../images/example-health-patient.png" /></p>
<p>All of the data in this application is simulated to look similar to the health records of an insurance company. Feel free to explore the application and notice the multiple tabs it contains.</p>
<p>The JavaScript code you looked at in your forked GitHub repository was containerized by OpenShift’s S2I function and deployed onto the OpenShift cluster.</p>
<p>Now that your application is running in a container in OpenShift, let’s see how an application developer can make a change to the source code, and then push the update to the running application.</p>
<p>We’ll make a simple change in a few lines of text to demonstrate. As we see in the Example Health application, there is a section with Personal Information.</p>
<p><img alt="personal-info" src="../images/personal-info.png" /></p>
</li>
<li>
<p><strong>In your forked GitHub repository, navigate to the source code again</strong>:</p>
</li>
<li>
<p><strong>Make sure you are in your own fork of the repository</strong>.</p>
</li>
<li>
<p>From <https://github.com/\<YOUR_GITHUB_USERNAME>/node-s2i-openshift>, <strong>click on the site folder</strong>.</p>
</li>
<li>
<p><strong>Click on the app.js file</strong>.</p>
</li>
<li>
<p>With the app.js file open, <strong>click on the edit button</strong> pointed out in the picture below.</p>
<p><img alt="gh-edit-button" src="../images/gh-edit-button.png" /></p>
</li>
<li>
<p><strong>Scroll down to line 55</strong>, which displays the patient name.</p>
</li>
<li>
<p><strong>Edit lines 55-60 as you wish, modifying the text strings for Name, Age, Gender, etc</strong>.</p>
<p><img alt="edited-gh" src="../images/edited-gh.png" /></p>
</li>
<li>
<p><strong>Click Commit Changes</strong> at the bottom of the page.</p>
</li>
</ol>
<p>You just edited the source code, but you still need to push the update to the running application.</p>
<ol>
<li>
<p><strong>Back in the OpenShift console, navigate to the Topology page -&gt; Click the Node.js application icon -&gt; Click the Resources tab -&gt; Click the Start Build button</strong>.</p>
<p><img alt="start-build" src="../images/start-build.png" /></p>
<p>A new Build #2 will be created. As with the first build, you can view the build logs to watch everything it’s doing, or you can simply wait for the console to display <code>Build #2 is complete</code> and your Pod <code>Running</code>.</p>
</li>
<li>
<p>When the Pod is <code>running</code>, <strong>refresh the Example Health browser tab</strong>.</p>
<p><img alt="patient-info-edited" src="../images/patient-info-edited.png" /></p>
</li>
</ol>
<p>Your code changes have been pushed to the running Example Health application.</p></section><section class="print-page" id="lab004-lab004-5"><h1 id="lab004-lab004-5-cleaning-up">Cleaning Up<a class="headerlink" href="#lab004-lab004-5-cleaning-up" title="Permanent link">&para;</a></h1>
<p>There is no easy way to delete all of these objects from the OpenShift console. This is a much easier task in the OpenShift command line.</p>
<ol>
<li>
<p>In the OpenShift CLI, <strong>make sure you are in your own project</strong> (i.e. userNN-project) <strong>and run the following command</strong>:</p>
<div class="highlight"><pre><span></span><code>oc delete all --selector app=node-s-2-i-openshift -o name
</code></pre></div>
<details class="note" open="open"><summary>Note</summary><p>If you are not connected to the OpenShift command line, refer to <a href="#lab002-lab002-1">Using the OpenShift Command Line</a>.</p>
</details>
</li>
</ol>
<p>In this lab, you have exposed JavaScript source code in a GitHub repository to an OpenShift cluster, which containerized that JavaScript code into a container image, and then deployed it as a container running in a pod. You then made a code change to the JavaScript code and pushed an update to the application while it was running</p></section><h1 class='nav-section-title-end'>Ended: Deploying an Application from Source Code</h1>
                        <h2 class='nav-section-title' id='section-openshift-pipelines'>
                            OpenShift Pipelines <a class='headerlink' href='#section-openshift-pipelines' title='Permanent link'>↵</a>
                        </h2>
                        <section class="print-page" id="lab009-lab009-0"><h1 id="lab009-lab009-0-using-openshift-pipelines">Using OpenShift Pipelines<a class="headerlink" href="#lab009-lab009-0-using-openshift-pipelines" title="Permanent link">&para;</a></h1>
<p><img alt="openshift-pipelines-graphic.svg" src="../images/openshift-pipelines-graphic.svg" /></p>
<p><strong>Red Hat OpenShift Pipelines</strong> is a cloud-native, continuous integration and continuous delivery (CI/CD) solution based on Kubernetes resources. It uses Tekton building blocks to automate deployments across multiple platforms by abstracting away the underlying implementation details. Tekton introduces a number of standard custom resource definitions (CRDs) for defining CI/CD pipelines that are portable across Kubernetes distributions.</p>
<h2 id="lab009-lab009-0-key-features">Key features<a class="headerlink" href="#lab009-lab009-0-key-features" title="Permanent link">&para;</a></h2>
<ul>
<li>Red Hat OpenShift Pipelines is a <em>serverless</em> CI/CD system that runs pipelines with all the required dependencies in <em>isolated containers</em>.</li>
<li>Red Hat OpenShift Pipelines are designed for <em>decentralized</em> teams that work on microservice-based architecture.</li>
<li>Red Hat OpenShift Pipelines use <em>standard CI/CD pipeline definitions</em> that are easy to extend and integrate with the existing Kubernetes tools, enabling you to scale on-demand.</li>
<li>You can use Red Hat OpenShift Pipelines to build images with Kubernetes tools such as Source-to-Image (S2I), Buildah, Buildpacks, and Kaniko that are portable across any Kubernetes platform.</li>
<li>You can use the OpenShift Container Platform Developer console to create Tekton resources, view logs of pipeline runs, and manage pipelines in your OpenShift Container Platform namespaces.</li>
</ul>
<h2 id="lab009-lab009-0-what-is-tekton">What is Tekton?<a class="headerlink" href="#lab009-lab009-0-what-is-tekton" title="Permanent link">&para;</a></h2>
<p><img alt="Logo-tekton.svg" src="../images/Logo-tekton.svg" /></p>
<p><strong>Tekton</strong> is an <em>open source</em> project that provides a framework to create <em>cloud-native CI/CD pipelines</em> quickly. As a <em>Kubernetes-native</em> framework, Tekton makes it easier to deploy across multiple cloud providers or hybrid environments. By leveraging the Custom Resource Definitions (CRDs) in Kubernetes, Tekton uses the Kubernetes control plane to run pipeline tasks. By using standard industry specifications, Tekton will work well with existing CI/CD tools such as Jenkins, Jenkins X, Skaffold, Knative, and now OpenShift.</p>
<p>Source of images and information on this page: <a href="https://cloud.redhat.com/learn/topics/ci-cd">https://cloud.redhat.com/learn/topics/ci-cd</a></p></section><section class="print-page" id="lab009-lab009-1"><h1 id="lab009-lab009-1-using-openshift-pipelines">Using OpenShift Pipelines<a class="headerlink" href="#lab009-lab009-1-using-openshift-pipelines" title="Permanent link">&para;</a></h1>
<p>In this section, you will be connecting to a “Linux Guest” server which has a few things set up to make your life a little easier. Most notably, it has the OpenShift command line <code>oc</code> installed, so you don’t have to install it on your RHEL VM terminal.</p>
<ol>
<li>
<p><strong>Open a Terminal session</strong>.</p>
</li>
<li>
<p><strong>ssh into the Linux Guest server</strong>:</p>
<div class="highlight"><pre><span></span><code>ssh userNN@192.168.176.61
</code></pre></div>
<p>Where <code>NN</code> is your user number.</p>
</li>
<li>
<p>When prompted, <strong>enter your password:</strong> <code>p@ssw0rd</code> <strong>and hit enter</strong>.</p>
<details class="example" open="open"><summary>Example Output</summary><p><img alt="ascii-wsc.png" src="../images/ascii-wsc.png" /></p>
</details>
</li>
<li>
<p>In Firefox, <strong>navigate to the following URL</strong> to request an API token:</p>
<p><a href="https://oauth-openshift.apps.atsocppa.dmz/oauth/token/request">https://oauth-openshift.apps.atsocppa.dmz/oauth/token/request</a></p>
</li>
<li>
<p><strong>Enter your OpenShift credentials when prompted</strong>.</p>
<ul>
<li>
<p>Username: <code>userNN</code></p>
</li>
<li>
<p>Password: <code>p@ssw0rd</code></p>
</li>
</ul>
</li>
<li>
<p><strong>Click the “Display Token” hyperlink</strong>.</p>
<p><img alt="display-token.png" src="../images/display-token.png" /></p>
</li>
<li>
<p><strong>Copy the contents of the first text box</strong> beginning with “oc login” and ending with “6443”.</p>
<p><img alt="oc-login-token.png" src="../images/oc-login-token.png" /></p>
</li>
<li>
<p><strong>Paste this command back in your terminal session and press enter</strong>.</p>
<div class="highlight"><pre><span></span><code>oc login --token=&lt;YOUR_TOKEN_HERE&gt; --server=https://api.atsocppa.dmz:6443
</code></pre></div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>If you’re prompted to use an insecure connection, type Y and hit enter.</p>
</div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ oc login --token=uL3fHEPSGH3io0htdGRfAMAPIIY44BhwnGxCMA3dei4 --server=https://api.atsocppa.dmz:6443
Logged into &quot;https://api.atsocppa.dmz:6443&quot; as &quot;user01&quot; using the token provided.

You have access to 161 projects, the list has been suppressed. You can list all projects with &#39;oc projects&#39;

Using project &quot;user01-project&quot;.
</code></pre></div>
</details>
<p>You are now logged into the cluster via the command line, and you are told which project you are using.</p>
<p>If you’re in a project other than userNN-project, use the following command to move into it: <code>oc project userNN-project</code>, where NN is your user number.</p>
</li>
</ol></section><section class="print-page" id="lab009-lab009-2"><h1 id="lab009-lab009-2-cloning-the-github-repository-and-viewing-its-contents">Cloning the GitHub Repository and Viewing its Contents<a class="headerlink" href="#lab009-lab009-2-cloning-the-github-repository-and-viewing-its-contents" title="Permanent link">&para;</a></h1>
<p>In the terminal session, you should have been automatically placed in your home directory <code>/home/userNN</code> (where NN is your user number).</p>
<ol>
<li>
<p><strong>Run the command</strong> <code>pwd</code> <strong>to check your current working directory</strong>.</p>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ pwd
/home/user01
</code></pre></div>
</details>
</li>
<li>
<p>If you are in any other directory, <strong>change into the correct home directory using the command</strong>:</p>
<div class="highlight"><pre><span></span><code>cd /home/userNN
</code></pre></div>
<p>(Where <code>NN</code> is your user number).</p>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ cd /home/user01
user01@lab061:~$ pwd
/home/user01
</code></pre></div>
</details>
<ol>
<li>In your home directory, <strong>clone the OpenShift Pipelines repository using the command</strong>:</li>
</ol>
<div class="highlight"><pre><span></span><code>git clone https://github.com/mmondics/openshift-pipelines-s390x 
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ git clone https://github.com/mmondics/openshift-pipelines-s390x
Cloning into &#39;openshift-pipelines-s390x&#39;...
remote: Enumerating objects: 25, done.
remote: Counting objects: 100% (25/25), done.
remote: Compressing objects: 100% (21/21), done.
remote: Total 25 (delta 5), reused 0 (delta 0), pack-reused 0
Unpacking objects: 100% (25/25), done.
Checking connectivity... done
</code></pre></div>
</details>
</li>
<li>
<p>This will create a new directory called <code>openliberty-pipelines-s390x</code>. <strong>Change into this directory using the command</strong>:</p>
<div class="highlight"><pre><span></span><code>cd openshift-pipelines-s390x
</code></pre></div>
</li>
<li>
<p><strong>List its contents using the command</strong>:</p>
<div class="highlight"><pre><span></span><code>ls -l
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ cd openliberty-operator-ocpz
user01@lab061:~/openliberty-operator-ocpz$ ls -l
total 16
-rw-r--r-- 1 user00 users   48 Mar 16 14:20 README.md
drwxr-xr-x 2 user00 users 4096 Mar 16 14:20 pipeline
-rw-r--r-- 1 user00 users  251 Mar 22 13:23 pipeline-cleanup.sh
drwxr-xr-x 2 user00 users 4096 Mar 16 14:20 resources
drwxr-xr-x 2 user00 users 4096 Mar 16 14:20 tasks
</code></pre></div>
</details>
<p>If you navigate to the GitHub repository in a web browser <a href="https://github.com/mmondics/openshift-pipelines-s390x">https://github.com/mmondics/openshift-pipelines-s390x</a>, you will notice that the sub-directories in your Linux session reflect the folders contained in the repository.</p>
<table>
<thead>
<tr>
<th>File</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>README.MD</strong></td>
<td>Contains   the content displayed on the GitHub page for this repository. You can read through   this README file if you want to get more information about this lab.</td>
</tr>
<tr>
<td><strong>pipeline</strong></td>
<td>Directory   containing the YAML file that will be used to create a Pipeline.</td>
</tr>
<tr>
<td><strong>pipeline-cleanup.sh</strong></td>
<td>Shell   script that will delete all objects created in this lab.</td>
</tr>
<tr>
<td><strong>resources</strong></td>
<td>Directory   containing the YAML file that will create a PersistentVolumeClaim in   the cluster.</td>
</tr>
<tr>
<td><strong>tasks</strong></td>
<td>Directory   containing YAML files to create various Tasks that make up a pipeline.</td>
</tr>
</tbody>
</table>
</li>
</ol></section><section class="print-page" id="lab009-lab009-3"><h1 id="lab009-lab009-3-understanding-and-deploying-tasks">Understanding and Deploying Tasks<a class="headerlink" href="#lab009-lab009-3-understanding-and-deploying-tasks" title="Permanent link">&para;</a></h1>
<p>A <em>Task</em> defines a series of steps that run in a desired order and complete a set amount of build work. Every Task runs as a Pod on your OpenShift cluster with each step as its own container. Tasks have one single responsibility so they can be reused across different Pipelines or in multiple places within a single Pipeline.</p>
<p>The repository you pulled includes the YAML files needed to create three Tasks. Let’s take a look at one of them.</p>
<ol>
<li>
<p><strong>From the openshift-pipelines-s390x directory, run the command</strong>:</p>
<div class="highlight"><pre><span></span><code>cat tasks/hello.yaml
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~/openshift-pipelines-s390x$ cat tasks/hello.yaml
apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
name: hello
spec:
steps:
    - name: say-hello
    image: registry.access.redhat.com/ubi8/ubi
    command:
        - /bin/text
    args: [&#39;-c&#39;, &#39;echo Hello World&#39;]
</code></pre></div>
</details>
<p>This file will create a Kubernetes Task object called hello that is made up of one step. That step has its own name, image, command, and args associated with it. As explained above, once created, this Task will create one Pod that includes one Container.</p>
</li>
<li>
<p><strong>Create the Task using the command</strong>:</p>
<div class="highlight"><pre><span></span><code>oc create -f tasks/hello.yaml
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~/openshift-pipelines-s390x$ oc create -f tasks/hello.yaml
task.tekton.dev/hello created
</code></pre></div>
</details>
<p>The Task is now created in your project and can be run using Tekton, the CI/CD tool that OpenShift Pipelines are based on.</p>
</li>
<li>
<p><strong>Run the</strong> <code>hello</code> <strong>task using the command</strong>:</p>
<div class="highlight"><pre><span></span><code>tkn task start --showlog hello
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~/openshift-pipelines-s390x$ tkn task start --showlog hello
TaskRun started: hello-run-xvr92
Waiting for logs to be available...
[say-hello] Hello World
</code></pre></div>
</details>
<p>Running the <code>tkn task start</code> command created a new Kubernetes resource called a TaskRun. TaskRuns are automatically created for each Task that is run in a Pipeline, but as you can see, they can also be manually created by running a Task. This can be useful for debugging a single Task in a Pipeline.</p>
</li>
<li>
<p>Your Pipeline will consist of three Tasks total. <strong>Create the remaining Tasks using the commands</strong>:</p>
<div class="highlight"><pre><span></span><code>oc create -f tasks/apply_manifest_task.yaml
</code></pre></div>
<p>and</p>
<div class="highlight"><pre><span></span><code>oc create -f tasks/update_deployment_task.yaml
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~/openshift-pipelines-s390x$ oc create -f tasks/apply_manifest_task.yaml
task.tekton.dev/apply-manifests created
user01@lab061:~/openshift-pipelines-s390x$ oc create -f tasks/update_deployment_task.yaml
task.tekton.dev/update-deployment created
</code></pre></div>
</details>
</li>
<li>
<p><strong>You have now created three Tasks that will be plumbed together to create a Pipeline. To see them, run the command</strong>:</p>
<div class="highlight"><pre><span></span><code>tkn task ls
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~/openshift-pipelines-s390x$ tkn task ls
NAME                DESCRIPTION   AGE
apply-manifests                   7 minutes ago
hello                             8 minutes ago
update-deployment                 7 minutes ago
</code></pre></div>
</details>
<p>You will also need a <em>Workspace</em> in which your will run all of the Tasks associated with your Pipeline. This will be a shared space across each Task, TaskRun, Pipeline, and PipelineRun that you associate with the Workspace. With a Workspace, you can store Task inputs and outputs, share data among Tasks, use it as a mount point for credentials held in Secrets, create a cache of build artifacts that speed up jobs, and more.</p>
</li>
<li>
<p><strong>In our case, we will be using a PersistentVolumeClaim as our Workspace. Create the PVC using the command</strong>:</p>
<div class="highlight"><pre><span></span><code>oc create -f resources/persistent_volume_claim.yaml
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~/openshift-pipelines-s390x$ oc create -f resources/persistent_volume_claim.yaml
persistentvolumeclaim/source-pvc created
</code></pre></div>
</details>
</li>
</ol>
<p>In the next section, you will create a Pipeline that uses the Tasks and Workspace you just created to pull the source code of an application from GitHub and then builds and deploys it in a container on OpenShift.</p></section><section class="print-page" id="lab009-lab009-4"><h1 id="lab009-lab009-4-understanding-and-deploying-pipelines">Understanding and Deploying Pipelines<a class="headerlink" href="#lab009-lab009-4-understanding-and-deploying-pipelines" title="Permanent link">&para;</a></h1>
<p>A <em>Pipeline</em> consists of a series of Tasks that are executed to construct complex workflows that automate the build, deployment, and delivery of applications. It is a collection of PipelineResources, parameters, and one or more Tasks.</p>
<p>Below is a diagram of the Pipeline you will be creating.</p>
<p><img alt="pipeline-diagram" src="../images/pipeline-diagram.png" /></p>
<p>The repository you pulled provides the YAML file necessary to generate this Pipeline.</p>
<ol>
<li>
<p><strong>Take a look at the YAML by using the command</strong>:</p>
<div class="highlight"><pre><span></span><code>cat pipeline/pipeline.yaml
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~/openshift-pipelines-s390x$ cat tasks/hello.yaml
apiVersion: tekton.dev/v1beta1
kind: Pipeline
metadata:
name: build-and-deploy
spec:
workspaces:
- name: shared-workspace
params:
- name: deployment-name
    type: string
    description: name of the deployment to be patched
- name: git-url
    type: string
    description: url of the git repo for the code of deployment
- name: git-revision
    type: string
    description: revision to be used from repo of the code for deployment
    default: &quot;master&quot;
- name: IMAGE
    type: string
    description: image to be build from the code
tasks:
- name: fetch-repository
    taskRef:
    name: git-clone
    kind: ClusterTask
    workspaces:
    - name: output
    workspace: shared-workspace
    params:
    - name: url
    value: $(params.git-url)
    - name: subdirectory
    value: &quot;&quot;
    - name: deleteExisting
    value: &quot;true&quot;
    - name: revision
    value: $(params.git-revision)
- name: build-image
    taskRef:
    name: buildah
    kind: ClusterTask
    params:
    - name: TLSVERIFY
    value: &quot;false&quot;
    - name: IMAGE
    value: $(params.IMAGE)
    workspaces:
    - name: source
    workspace: shared-workspace
    runAfter:
    - fetch-repository
- name: apply-manifests
    taskRef:
    name: apply-manifests
    workspaces:
    - name: source
    workspace: shared-workspace
    runAfter:
    - build-image
- name: update-deployment
    taskRef:
    name: update-deployment
    params:
    - name: deployment
    value: $(params.deployment-name)
    - name: IMAGE
    value: $(params.IMAGE)
    runAfter:
    - apply-manifests
</code></pre></div>
</details>
<p>The Tasks included in this pipeline and their responsibilities are as follows:</p>
<ul>
<li>
<p><em>fetch-repository</em> clones the source code of the application from a GitHub repository based on the git-url and git-revision parameters.</p>
</li>
<li>
<p><em>build-image</em> builds the container image of the application using Buildah.</p>
</li>
<li>
<p><em>apply-manifests</em> deploys the application to OpenShift by running the oc apply command on the new container image with the provided parameters.</p>
</li>
<li>
<p><em>update-deployment</em> will update the application in OpenShift with the oc patch command when changes are needed.</p>
</li>
</ul>
<p>You will notice that there are no references to the GitHub repository or the image registry that will be pushed to in the pipeline. This is because Pipelines are designed to be generic and re-used in different situations or to deploy different applications. Pipelines abstract away the specific parameters that can be passed into the Pipeline. When triggering the Pipeline, you will provide different GitHub repositories and images to be used when executed.</p>
<p>Also notice that the execution order of Tasks can be determined by dependencies defined between Tasks via inputs and outputs, or explicitly ordered via runAfter.</p>
</li>
<li>
<p><strong>Create the Pipeline with the command</strong>:</p>
<div class="highlight"><pre><span></span><code>oc create -f pipeline/pipeline.yaml
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~/openshift-pipelines-s390x$ oc create -f pipeline/pipeline.yaml
pipeline.tekton.dev/build-and-deploy created
</code></pre></div>
</details>
<p>Although we are using pre-built YAML files to simplify the creation of these resources, everything in this lab could also be done in the OpenShift console in a browser.</p>
</li>
<li>
<p><strong>Take a look at the graphical representation of your Pipeline by accessing the cluster at the URL: <a href="https://console-openshift-console.apps.atsocppa.dmz/">https://console-openshift-console.apps.atsocppa.dmz/</a></strong></p>
<p>Username: <code>userNN</code> (where NN is your user number)</p>
<p>Password: <code>p@ssw0rd</code></p>
</li>
<li>
<p><strong>Navigate to the Developer Perspective -&gt; Pipelines -&gt; select your userNN Project</strong>.</p>
<p><img alt="dev-pipeline" src="../images/dev-pipeline.png" /></p>
</li>
<li>
<p><strong>Click your new Pipeline</strong> called <code>build-and-deploy</code>.</p>
<p><img alt="build-and-deploy" src="../images/build-and-deploy.png" /></p>
<p>The framework of your Pipeline has been created, and you can see the four Tasks that make up your Pipeline.</p>
<div class="admonition information">
<p class="admonition-title">Information</p>
<p>If you remember making the apply-manifests and update-deployment Tasks, but not the “fetch-repository” and “build-image” Tasks -- you aren’t wrong. These are ClusterTasks that come pre-built into OpenShift.</p>
</div>
</li>
</ol>
<p>In the next section you will trigger a PipelineRun to execute your Pipeline and the Tasks it contains.</p></section><section class="print-page" id="lab009-lab009-5"><h1 id="lab009-lab009-5-running-the-pipeline">Running the Pipeline<a class="headerlink" href="#lab009-lab009-5-running-the-pipeline" title="Permanent link">&para;</a></h1>
<p>Let’s use this Pipeline to create an application. To demonstrate the re-usability of OpenShift Pipelines, we will be creating both a frontend and a backend with the same Pipeline you created in the previous step.</p>
<p>We’ll also demonstrate the flexibility provided by OpenShift Pipelines that lets you use them from either the web console or the command line.</p>
<p>Let’s create the backend application with the Tekton CLI in your terminal.</p>
<p>Now that you have all of the building blocks in place, you can start the Pipeline with the following command. The command will run the Pipeline and pass in parameters to:</p>
<ul>
<li>
<p>Use the shared workspace and the PersistentVolumeClaim you created</p>
</li>
<li>
<p>Create the deployment named vote-api</p>
</li>
<li>
<p>Build a container image from the source code at the given GitHub repository</p>
</li>
<li>
<p>Push that container image into the OpenShift internal registry and tag it for your project</p>
</li>
<li>
<p>Show the log so you can follow its progress
Note that the forward slash  simply breaks the command into multiple lines for readability.</p>
</li>
</ul>
<h2 id="lab009-lab009-5-creating-the-backend-application-through-the-cli">Creating the Backend Application through the CLI<a class="headerlink" href="#lab009-lab009-5-creating-the-backend-application-through-the-cli" title="Permanent link">&para;</a></h2>
<ol>
<li>
<p><strong>Run the following command</strong>:</p>
<div class="highlight"><pre><span></span><code>tkn pipeline start build-and-deploy \
 -w name=shared-workspace,claimName=source-pvc \
 -p deployment-name=vote-api \
 -p git-url=https://github.com/mmondics/pipelines-vote-api.git \
 -p IMAGE=image-registry.openshift-image-registry.svc:5000/userNN-project/pipelines-vote-api --showlog 
</code></pre></div>
<div class="admonition important">
<p class="admonition-title"><img alt="⚠" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/26a0.svg" title=":warning:" /> Important <img alt="⚠" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/26a0.svg" title=":warning:" /></p>
<p>Make sure you change the one instance of <code>NN</code> to your team number in the command above.</p>
</div>
<details class="example"><summary>Expand for Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~/openshift-pipelines-s390x$ tkn pipeline start build-and-deploy \
&gt; -w name=shared-workspace,claimName=source-pvc \
&gt; -p deployment-name=vote-api \
&gt; -p git-url=https://github.com/mmondics/vote-api.git \
&gt; -p IMAGE=image-registry.openshift-image-registry.svc:5000/userNN-project/vote-api \
&gt; --showlog
PipelineRun started: build-and-deploy-run-75zqv
Waiting for logs to be available...
[fetch-respository : clone] + CHECKOUT_DIR=/workspace/output/
[fetch-respository : clone] + [[ true == \t\r\u\e ]]
[fetch-respository : clone] + cleandir
[fetch-respository : clone] + [[ -d /workspace/output/ ]]
[fetch-respository : clone] + rm -rf /workspace/output//Dockerfile /workspace/output//LICENSE /workspace/output//README.md /workspace/output//go.mod /workspace/output//go.sum /workspace/output//k8s /workspace/output//main.go /workspace/output//vendor
[fetch-respository : clone] + rm -rf /workspace/output//.git /workspace/output//.gitignore
[fetch-respository : clone] + rm -rf &#39;/workspace/output//..?*&#39;
[fetch-respository : clone] + test -z &#39;&#39;
[fetch-respository : clone] + test -z &#39;&#39;
[fetch-respository : clone] + test -z &#39;&#39;
[fetch-respository : clone] + /ko-app/git-init -url https://github.com/mmondics/vote-api.git -revision master -refspec &#39;&#39; -path /workspace/output/ -sslVerify=true -submodules=true -depth 1
[fetch-respository : clone] {&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:1616101272.5251348,&quot;caller&quot;:&quot;git/git.go:165&quot;,&quot;msg&quot;:&quot;Successfully cloned https://github.com/mmondics/vote-api.git @ a08f579f6135293358b9423a3370e725ae1380cc (grafted, HEAD, origin/master) in path /workspace/output/&quot;}
[fetch-respository : clone] {&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:1616101272.6701891,&quot;caller&quot;:&quot;git/git.go:203&quot;,&quot;msg&quot;:&quot;Successfully initialized and updated submodules in path /workspace/output/&quot;}
[fetch-respository : clone] + cd /workspace/output/
[fetch-respository : clone] ++ git rev-parse HEAD
[fetch-respository : clone] + RESULT_SHA=a08f579f6135293358b9423a3370e725ae1380cc
[fetch-respository : clone] + EXIT_CODE=0
[fetch-respository : clone] + &#39;[&#39; 0 &#39;!=&#39; 0 &#39;]&#39;
[fetch-respository : clone] + echo -n a08f579f6135293358b9423a3370e725ae1380cc
[fetch-respository : clone] + echo -n https://github.com/mmondics/vote-api.git

[build-image : build] + buildah --storage-driver=vfs bud --format=oci --tls-verify=false --no-cache -f ./Dockerfile -t image-registry.openshift-image-registry.svc:5000/user00-project/vote-api .
[build-image : build] STEP 1: FROM image-registry.openshift-image-registry.svc:5000/openshift/golang:latest AS builder
[build-image : build] Getting image source signatures
[build-image : build] Copying blob sha256:ff637d5a66cba4903fc7d9343b0f9dbb4e1bf8ada19bd3934ea0edfb85dc4
[build-image : build] Copying blob sha256:f7fb0662b957bcb1b5007f9b5502af4da4c13e17b7bc2eff4f02c3e5ec08e
[build-image : build] Copying blob sha256:35aab756d1a095511ab75eeca5aa77a37fa62a258f3fa5bcfb37ad604e369
[build-image : build] Copying blob sha256:7cc70ce0e0ee7fe5f8ea22894ad8c2f962f1dfdd00d05de91a32181c89179
[build-image : build] Copying blob sha256:73986f838dc404255946f6aa282b0aeabc420faa4f21b572e1de735498edf
[build-image : build] Copying config sha256:9e8f033b036bdb224dc931cfcaaf532da6a6ae7d779e8a09c52eed12305
[build-image : build] Writing manifest to image destination
[build-image : build] Storing signatures
[build-image : build] STEP 2: WORKDIR /build
[build-image : build] STEP 3: ADD . /build/
[build-image : build] STEP 4: RUN export GARCH=&quot;$(uname -m)&quot; &amp;&amp; if [[ ${GARCH} == &quot;s390x&quot; ]]; then export GARCH=&quot;s390x&quot;; fi &amp;&amp; GOOS=linux GOARCH=${GARCH} CGO_ENABLED=0 go build -mod=vendor -o api-server 
[build-image : build] STEP 5: FROM scratch
[build-image : build] STEP 6: WORKDIR /app
[build-image : build] STEP 7: COPY --from=builder /build/api-server /app/api-server
[build-image : build] STEP 8: CMD [ &quot;/app/api-server&quot; ]
[build-image : build] STEP 9: COMMIT image-registry.openshift-image-registry.svc:5000/user00-project/vote-api
[build-image : build] --&gt; 36faca61f94
[build-image : build] 36faca61f941af886128abd8792753095eaac7c1041084e222f426243ed50ecc

[build-image : push] + buildah --storage-driver=vfs push --tls-verify=false --digestfile /workspace/source/image-digest image-registry.openshift-image-registry.svc:5000/user00-project/vote-api docker://image-registry.openshift-image-registry.svc:5000/user00-project/vote-api
[build-image : push] + buildah --storage-driver=vfs push --tls-verify=false --digestfile /workspace/source/image-digest image-registry.openshift-image-registry.svc:5000/user00-project/vote-api docker://image-registry.openshift-image-registry.svc:5000/user00-project/vote-api
[build-image : push] Getting image source signatures
[build-image : push] Copying blob sha256:9eda1116f7414b98e397f94cc650fd50890c2d97fa47925e02b83df7726119
[build-image : push] Copying config sha256:36faca61f941af886128abd8792753095eaac7c1041084e222f426243ed5
[build-image : push] Writing manifest to image destination
[build-image : push] Storing signatures

[build-image : digest-to-results] + cat /workspace/source/image-digest
[build-image : digest-to-results] + tee /tekton/results/IMAGE_DIGEST
[build-image : digest-to-results] sha256:a7d730f92530c2f10891c55ba86a44e4fcc907436831c99733779ffb0d0fe8

[apply-manifests : apply] Applying manifests in k8s directory
[apply-manifests : apply] deployment.apps &quot;vote-api&quot; created
[apply-manifests : apply] service &quot;vote-api&quot; created
[apply-manifests : apply] -----------------------------------

[update-deployment : patch] deployment.apps &quot;vote-api&quot; patched
</code></pre></div>
</details>
<p>If you see the final <code>deployment.apps “vote-api” patched</code> line, your PipelineRun was successful and your backend application is now deployed in OpenShift.</p>
</li>
<li>
<p><strong>Look at your running application Pod by issuing the command</strong>:</p>
<div class="highlight"><pre><span></span><code>oc get pod
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~/openshift-pipelines-s390x$ oc get pod
NAME                                                           READY   STATUS      RESTARTS   AGE
build-and-deploy-run-sgtc7-apply-manifests-9p6mv-pod-95jhw     0/1     Completed   0          9m52s
build-and-deploy-run-sgtc7-build-image-6kh6n-pod-pkvgx         0/3     Completed   0          12m
build-and-deploy-run-sgtc7-fetch-repository-flxfx-pod-p6nzh    0/1     Completed   0          13m
build-and-deploy-run-sgtc7-update-deployment-hgxrz-pod-htqpf   0/1     Completed   0          9m33s
vote-api-6765569bfb-v4jlh                                      1/1     Running     0          9m20s
</code></pre></div>
</details>
<p>You should see one <em>running</em> Pod and four <em>completed</em> Pods. The running Pod is your application that the Pipeline pulled from GitHub, containerized, pushed into the internal OpenShift repository, and started. The completed Pods were created to complete the Tasks defined in the Pipeline, and each is made up of one container per step in the Task.</p>
<p>Looking at the READY column, you can see that most of the Pods have one container, with the exception of the build-image Pod that has three.</p>
</li>
<li>
<p><strong>The Tekton CLI also provides a way to check your Pipelines and PipelineRuns by running</strong>:</p>
<div class="highlight"><pre><span></span><code>tkn pipeline ls
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~/openshift-pipelines-s390x$ tkn pipeline ls
NAME               AGE             LAST RUN                     STARTED         DURATION    STATUS
build-and-deploy   4 minutes ago   build-and-deploy-run-2q5fp   4 minutes ago   3 minutes   Succeeded
</code></pre></div>
</details>
</li>
</ol>
<p>Since we have successfully run the Pipeline in the CLI, let’s trigger a run from the console in the next section.</p>
<h2 id="lab009-lab009-5-creating-the-frontend-application-through-the-console">Creating the Frontend Application through the Console<a class="headerlink" href="#lab009-lab009-5-creating-the-frontend-application-through-the-console" title="Permanent link">&para;</a></h2>
<p>Let’s create the frontend portion of our application by running the Pipeline from the OpenShift console.</p>
<ol>
<li>
<p><strong>If you’ve closed out of the OpenShift console in your web browser, go back to <a href="https://console-openshift-console.apps.atsocppa.dmz/">https://console-openshift-console.apps.atsocppa.dmz/</a></strong></p>
</li>
<li>
<p><strong>Navigate to the Developer Perspective -&gt; Pipelines -&gt; and select your userNN Project</strong>.</p>
<p><img alt="build-and-deploy-2" src="../images/build-and-deploy-2.png" /></p>
<p>The main Pipelines page displays the same information returned from the <code>tkn pipeline ls</code> command.</p>
</li>
<li>
<p><strong>Click your build-and-deploy Pipeline and then click the Actions -&gt; Start button</strong>.</p>
<p><img alt="start-pipeline" src="../images/start-pipeline.png" /></p>
<p>This will open a new window that prompts you for the parameters with which to start your second PipelineRun. This window is the GUI equivalent to the multi-line <code>tkn pipeline start</code> command that we entered in the CLI PipelineRun.</p>
</li>
<li>
<p><strong>Enter the following parameters</strong>:</p>
<ul>
<li>
<p>deployment name: <code>vote-ui</code></p>
</li>
<li>
<p>git-url: <code>https://github.com/mmondics/pipelines-vote-ui.git</code></p>
</li>
<li>
<p>git-revision: <code>master</code></p>
</li>
<li>
<p>IMAGE: <code>image-registry.openshift-image-registry.svc:5000/userNN-project/vote-ui</code></p>
</li>
<li>
<p>shared-workspace: <code>PersistentVolumeClaim</code> -&gt; <code>source-pvc</code></p>
</li>
</ul>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Make sure you change the one instance of <code>NN</code> in the IMAGE field to your user number.</p>
</div>
</li>
<li>
<p><strong>Then click start</strong>.</p>
<p><img alt="start-pipeline-ui" src="../images/start-pipeline-ui.png" /></p>
<p>You will be taken to the page for your PipelineRun and shown the graphical representation of the running Pipeline.</p>
<p><img alt="pipeline-running" src="../images/pipeline-running.png" /></p>
</li>
<li>
<p><strong>Click the logs tab</strong> to follow what’s happening in more detail like you saw in the CLI.</p>
<p><img alt="pipeline-logs" src="../images/pipeline-running.png" /></p>
</li>
</ol>
<p>When you see the PipelineRun has Succeeded and the <code>deployment.apps “vote-ui” has been patched</code>, your frontend application is also up and running.</p>
<p>With both your backend and frontend applications are running, in the next section we’ll access it in a browser.</p></section><section class="print-page" id="lab009-lab009-6"><h1 id="lab009-lab009-6-accessing-the-pipeline-in-a-browser">Accessing the Pipeline in a Browser<a class="headerlink" href="#lab009-lab009-6-accessing-the-pipeline-in-a-browser" title="Permanent link">&para;</a></h1>
<p>Your application is accessible via its route.</p>
<ol>
<li>
<p>In the OpenShift console, <strong>navigate to the Topology page in the Developer Perspective and make sure you’re in your userNN-project</strong>.</p>
<p><img alt="pipeline-app-topology" src="../images/pipeline-app-topology.png" /></p>
<p>You should see two Icons with solid blue bars indicating your application pods are running without error.</p>
</li>
<li>
<p>On the vote-ui icon, <strong>click the button in the top right corner to navigate to the application’s exposed route</strong>.</p>
<p><img alt="pipeline-app-topology-2" src="../images/pipeline-app-topology-2.png" /></p>
<p>This will open a new browser tab for your frontend application UI.</p>
<p><img alt="cat-dog" src="../images/cat-dog.png" /></p>
</li>
<li>
<p><strong>Click the box for your desired option</strong>.</p>
<p>By casting your vote with the vote-ui frontend, you are invoking a REST API call and sending a POST request that is stored in the vote-api backend application.</p>
<p>You can see this POST request reflected in the vote-api Pod logs.</p>
</li>
<li>
<p><strong>In your terminal session find the name of your vote-api Pod using the command</strong>:</p>
<div class="highlight"><pre><span></span><code>oc get pods | grep Running
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~/openshift-pipelines-s390x$ oc get pods | grep Running
vote-api-6765569bfb-p2bhh                                      1/1     Running     0          65m
vote-ui-6846f88f6f-rzzgt                                       1/1     Running     0          18m
</code></pre></div>
</details>
</li>
<li>
<p><strong>Copy the full name for your vote-api Pod and view its logs with the command</strong>:</p>
<div class="highlight"><pre><span></span><code>oc logs pod/vote-api-XXXXXXXXXX-YYYYY 
</code></pre></div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Your randomly-generated Pod names will differ.</p>
</div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~/openshift-pipelines-s390x$ oc logs pod/vote-api-6765569bfb-p2bhh
[GIN-debug] [WARNING] Creating an Engine instance with the Logger and Recovery middleware already attached.

[GIN-debug] [WARNING] Running in &quot;debug&quot; mode. Switch to &quot;release&quot; mode in production.
- using env:    export GIN_MODE=release
- using code:   gin.SetMode(gin.ReleaseMode)

[GIN-debug] GET    /vote                     --&gt; main.setupRouter.func1 (3 handlers)
[GIN-debug] POST   /vote                     --&gt; main.setupRouter.func2 (3 handlers)
[GIN-debug] Listening and serving HTTP on :9000
[GIN] 2021/03/22 - 16:18:18 | 200 |     179.658µs |    10.131.1.157 | POST     /vote
[GIN] 2021/03/22 - 16:18:48 | 200 |     107.379µs |    10.131.1.157 | POST     /vote
</code></pre></div>
</details>
<p>You can see your POST requests at the <code>/vote</code> endpoint at the bottom, and more detail is stored in NFS by the PersistentVolumeClaim you created earlier.</p>
</li>
</ol>
<p>In this lab, you have:</p>
<ul>
<li>Created Tasks that have specific responsibilities in the building and deploying of a containerized application onto an OpenShift on IBM Z cluster</li>
<li>Created a Pipeline that combines these Tasks to one end-to-end process</li>
<li>Ran the Pipeline twice -- once from the command line, and once from the OpenShift console -- to create a backend and a frontend application.</li>
<li>Used the created applications to invoke a REST API call that is stored persistently in NFS storage.</li>
</ul></section><section class="print-page" id="lab009-lab009-7"><h1 id="lab009-lab009-7-cleaning-up">Cleaning Up<a class="headerlink" href="#lab009-lab009-7-cleaning-up" title="Permanent link">&para;</a></h1>
<ol>
<li>
<p>When you’re ready to finish the lab and delete the objects you created, <strong>return to your terminal and double check that you’re in your own userNN-project with</strong>:</p>
<div class="highlight"><pre><span></span><code>oc project
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~/openshift-pipelines-s390x$ oc project
Using project &quot;user00-project&quot; on server &quot;https://api.atsocpd2.dmz:6443&quot;.
</code></pre></div>
</details>
</li>
<li>
<p><strong>Run the uninstall script</strong>:</p>
<div class="highlight"><pre><span></span><code>./pipeline-cleanup.sh
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~/openshift-pipelines-s390x$ ./pipeline-cleanup.sh
Running oc delete all --all
pod &quot;build-and-deploy-run-6hgg7-apply-manifests-ksns5-pod-zvnq8&quot; deleted
pod &quot;build-and-deploy-run-6hgg7-build-image-4bstq-pod-sd2xv&quot; deleted
pod &quot;build-and-deploy-run-6hgg7-fetch-repository-jgqml-pod-ld4nj&quot; deleted
pod &quot;build-and-deploy-run-6hgg7-update-deployment-qhmxh-pod-c56gj&quot; deleted
pod &quot;build-and-deploy-run-fnx5s-apply-manifests-k8v7f-pod-88fpm&quot; deleted
pod &quot;build-and-deploy-run-fnx5s-build-image-4xknh-pod-kq4zk&quot; deleted
pod &quot;build-and-deploy-run-fnx5s-fetch-repository-m5pmr-pod-8m5gt&quot; deleted
pod &quot;build-and-deploy-run-fnx5s-update-deployment-fgq9s-pod-2s4vw&quot; deleted
pod &quot;hello-run-l2skb-pod-vzvrj&quot; deleted
pod &quot;vote-api-6765569bfb-p59vj&quot; deleted
pod &quot;vote-ui-6846f88f6f-z7zp9&quot; deleted
service &quot;vote-api&quot; deleted
service &quot;vote-ui&quot; deleted
deployment.apps &quot;vote-api&quot; deleted
deployment.apps &quot;vote-ui&quot; deleted
replicaset.apps &quot;vote-ui-566848fff4&quot; deleted
replicaset.apps &quot;vote-ui-6846f88f6f&quot; deleted
imagestream.image.openshift.io &quot;vote-api&quot; deleted
imagestream.image.openshift.io &quot;vote-ui&quot; deleted
route.route.openshift.io &quot;vote-ui&quot; deleted
Deleting Pipeline &amp; resources
pipeline.tekton.dev &quot;build-and-deploy&quot; deleted
pipelinerun.tekton.dev &quot;build-and-deploy-run-6hgg7&quot; deleted
pipelinerun.tekton.dev &quot;build-and-deploy-run-fnx5s&quot; deleted
task.tekton.dev &quot;apply-manifests&quot; deleted
task.tekton.dev &quot;hello&quot; deleted
task.tekton.dev &quot;update-deployment&quot; deleted
taskrun.tekton.dev &quot;hello-run-l2skb&quot; deleted
Deleting PVC
persistentvolumeclaim &quot;source-pvc&quot; deleted
Removing Images
</code></pre></div>
</details>
</li>
</ol></section><h1 class='nav-section-title-end'>Ended: OpenShift Pipelines</h1>
                        <h2 class='nav-section-title' id='section-monitoring-metering-and-metrics'>
                            Monitoring, Metering, and Metrics <a class='headerlink' href='#section-monitoring-metering-and-metrics' title='Permanent link'>↵</a>
                        </h2>
                        <section class="print-page" id="lab005-lab005-1"><h1 id="lab005-lab005-1-monitoring-metering-and-metrics">Monitoring, Metering, and Metrics<a class="headerlink" href="#lab005-lab005-1-monitoring-metering-and-metrics" title="Permanent link">&para;</a></h1>
<p>A significant architectural shift toward containers is underway and, as with any architectural shift, this brings new operational challenges. It can be challenging for many of the legacy monitoring tools to monitor container platforms in fast moving, often ephemeral environments. The good news is newer cloud-based offerings can ensure monitoring solutions are as scalable as the services being built and monitored. These new solutions have evolved to address the growing need to monitor your stack from the bottom to the top.</p>
<p>From an operations point of view, infrastructure monitoring tools collect metrics about the host or container, such as CPU load, available memory and network I/O.</p>
<p>The default monitoring stack is the 3-pronged open source approach of, Grafana, Alertmanager, and Prometheus.</p>
<p><strong><em>Prometheus</em></strong> gives you finely grained metrics at a huge scale. With the right configuration, Prometheus can handle millions of time series.</p>
<p><strong><em>Grafana</em></strong> can visualize the data being scraped by Prometheus. Grafana comes with pre-built dashboards for typical use cases, or you can create your own custom ones.</p>
<p><strong><em>Alertmanager</em></strong> forwards alerts to a service such as Slack or another webhook . Alertmanager can use metadata to classify alerts into groups such as errors, notifications, etc.</p>
<p>The Grafana-Alertmanager-Prometheus monitoring stack provides a highly configurable, open source option to monitor Kubernetes workloads.</p>
<p><img alt="monitoring-arch" src="../images/monitoring-arch.png" /></p></section><section class="print-page" id="lab005-lab005-2"><h1 id="lab005-lab005-2-connect-to-ocp-and-authenticate">Connect to OCP and Authenticate<a class="headerlink" href="#lab005-lab005-2-connect-to-ocp-and-authenticate" title="Permanent link">&para;</a></h1>
<ol>
<li>
<p>In your virtual machine desktop, <strong>open a Firefox web browser</strong>.</p>
</li>
<li>
<p>In the browser, <strong>navigate to the OpenShift on IBM Z console</strong> at the following address: <a href="https://console-openshift-console.apps.atsocppa.dmz/">https://console-openshift-console.apps.atsocppa.dmz/</a>.</p>
<details class="note" open="open"><summary>Note</summary><p>You will receive a security challenge if the cluster has not yet been accessed from your browser. This is due to the default SSL certificate being “self-signed” and not yet recognized.</p>
<p>Accept the challenge to continue by <strong>clicking Advanced</strong> and then <strong>clicking Proceed to console-openshift-console.apps.atsocppa.dmz (unsafe)</strong>.</p>
<p>You will likely need to do this twice due to how OpenShift reroutes Oauth requests. </p>
</details>
<details><summary>Expand for screenshot</summary><p><img alt="security-accept.png" src="../images/security-accept.png" />
<img alt="security-accept-2.png" src="../images/security-accept-2.png" /></p>
</details>
<p>You will now see the OpenShift console login page.</p>
<p><img alt="openshift-console-login" src="../images/openshift-console-login.png" /></p>
</li>
<li>
<p><strong>Log in with the OpenShift credentials</strong> provided to you on the <a href="#lab-assignments">Lab Assignments</a> page.</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>Your OpenShift credentials will be something like the following:</p>
<ul>
<li>
<p>Username: userNN (where NN is your user number)</p>
</li>
<li>
<p>Password: p@ssw0rd</p>
</li>
</ul>
</div>
</li>
</ol></section><section class="print-page" id="lab005-lab005-3"><h1 id="lab005-lab005-3-using-openshifft-metrics-prometheus">Using OpenShifft Metrics (Prometheus)<a class="headerlink" href="#lab005-lab005-3-using-openshifft-metrics-prometheus" title="Permanent link">&para;</a></h1>
<p>OpenShift provides a web interface to <em>Prometheus</em>, which enables you to run Prometheus Query Language (PromQL) queries and visualize the metrics on a plot. This functionality provides an extensive overview of the cluster state and helps to troubleshoot problems.</p>
<ol>
<li>
<p>In the OpenShift console, <strong>switch to the Administrator perspective</strong> if you are not already on it.</p>
<p><img alt="administrator-perspective" src="../images/administrator-perspective.png" /></p>
</li>
<li>
<p>In the menu bar on the left side of the page, <strong>click Monitoring and then Metrics</strong>.</p>
<p><img alt="menu-metrics" src="../images/menu-metrics.png" /></p>
<p>You will be taken to a Prometheus interface within the OpenShift console.</p>
<p><img alt="empty-metrics" src="../images/empty-metrics.png" /></p>
<p>Once you enter a query, the graph will populate.</p>
</li>
<li>
<p><strong>Click the Insert Metric at Cursor dropdown and enter the following string in the new query bar</strong>:</p>
<div class="highlight"><pre><span></span><code>namespace:container_memory_usage_bytes:sum
</code></pre></div>
<p><img alt="insert-metric-1" src="../images/insert-metric-1.png" /></p>
</li>
<li>
<p><strong>Click the associated query result that is returned</strong>.</p>
<p><img alt="insert-metric-2" src="../images/insert-metric-2.png" /></p>
<p>The string will populate the query text box.</p>
</li>
<li>
<p><strong>Click the blue "Run Queries" button</strong>.</p>
<p><img alt="memory-usage" src="../images/memory-usage.png" /></p>
<p>The graph should now display the memory usage over time for each namespace.</p>
</li>
<li>
<p><strong>Scroll down the page</strong> to the table displaying each namespace and its memory usage in bytes.</p>
<p><img alt="memory-table" src="../images/memory-table.png" /></p>
<details class="note" open="open"><summary>Note</summary><p>You table will look different depending on what work is being done in the OpenShift cluster at the time.</p>
</details>
<p>OpenShift passes around a massive amount of data to run itself and the applications running on top of it. Prometheus is an extremely powerful data source that can return results for millions of time strings with extremely granular precision.</p>
<p>Because of OpenShift’s vast data production and Prometheus’ ability to process it, certain queries can produce simply too much data to be useful. Because Prometheus makes use of labels, we can use these labels to filter data to make better sense of it.</p>
</li>
<li>
<p><strong>Modify your query to the following</strong>:</p>
<div class="highlight"><pre><span></span><code>namespace:container_memory_usage_bytes:sum{namespace=&quot;userNN-project&quot;}
</code></pre></div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Make sure you change the one instance of <code>NN</code> to your user number.</p>
<p>Also, notice that they are squiggly brackets <code>{}</code> in the query, not regular parentheses.</p>
</div>
</li>
<li>
<p><strong>Click Run Queries</strong></p>
<p><img alt="memory-namespaced" src="../images/memory-namespaced.png" /></p>
<p>Your graph is now displaying the memory usage over time for your own project. If you see a “No datapoints found” message, select a longer timeframe using the dropdown menu in the top left of the graph.</p>
<details class="note" open="open"><summary>Note</summary><p>If you skipped ahead to this lab without completing the others, it’s possible that your project has not had workload deployed in it for more than the maximum time frame. If this is the case, run a simple application in your project, and you will see the data start to populate (refer to <a href="#lab001-lab001-1">Exploring the OpenShift Console</a> for help with this.)</p>
</details>
</li>
</ol>
<p>As you might have noticed, working directly with Prometheus can be tedious and requires specific PromQL queries that aren’t the easiest to work with. That’s why people typically use Prometheus for its <em>data source</em> functionality, and then move to Grafana for the <em>data visualization</em>.</p></section><section class="print-page" id="lab005-lab005-4"><h1 id="lab005-lab005-4-using-the-in-browser-grafana-dashboards">Using the In-Browser Grafana Dashboards<a class="headerlink" href="#lab005-lab005-4-using-the-in-browser-grafana-dashboards" title="Permanent link">&para;</a></h1>
<ol>
<li>
<p><strong>From the OpenShift menu, navigate to Monitoring -&gt; Dashboards</strong>.</p>
<p><img alt="menu-dashboards" src="../images/menu-dashboards.png" /></p>
<p>This takes you to an in-browser user interface for the Grafana monitoring solution. By default, there are various preconfigured dashboards for common use cases.</p>
<p><img alt="default-in-browser" src="../images/default-in-browser.png" /></p>
</li>
<li>
<p><strong>Click the "Dashboard" dropdown in the top-left of the page, and select another that is of interest to you</strong>.</p>
</li>
</ol></section><section class="print-page" id="lab005-lab005-5"><h1 id="lab005-lab005-5-connect-to-grafana">Connect to Grafana<a class="headerlink" href="#lab005-lab005-5-connect-to-grafana" title="Permanent link">&para;</a></h1>
<ol>
<li>
<p>To utilize further Grafana functions, <strong>navigate to the Grafana UI at the following address</strong>.</p>
<p><a href="https://grafana-openshift-monitoring.apps.atsocppa.dmz/">https://grafana-openshift-monitoring.apps.atsocppa.dmz/</a></p>
<details class="information"><summary>Expand for More Information</summary><p>Where is this URL coming from? It is exposed service (or route) for the Grafana service. You could open a terminal and run the following command to find the URLs to Prometheus, Grafana, and Alertmanager:</p>
<div class="highlight"><pre><span></span><code>root # ===&gt; oc -n openshift-monitoring get routes
NAME                HOST/PORT                              
alertmanager-main   alertmanager-main-openshift-monitoring.apps.atsocppa.dmz
grafana             grafana-openshift-monitoring.apps.atsocppa.dmz
prometheus-k8s      prometheus-k8s-openshift-monitoring.apps.atsocppa.dmz
</code></pre></div>
</details>
<details class="information" open="open"><summary>Information</summary><p>You might see a security challenge if the cluster has not yet been accessed from your workstation. Accept the challenge to continue.</p>
</details>
<p>You should now see login page prompting your OpenShift credentials.</p>
</li>
<li>
<p><strong>Log into Grafana using the your OpenShift credentials</strong>.</p>
<ul>
<li>Username: userNN</li>
<li>Password: p@ssw0rd</li>
</ul>
<p>Notice that the credentials you use to log into Grafana are the same as those you use to log into OpenShift itself. OpenShift’s role-bases access control (RBAC) functionality extends to the monitoring stack, so administrators can control who can see this part of the environment.</p>
</li>
</ol></section><section class="print-page" id="lab005-lab005-6"><h1 id="lab005-lab005-6-using-grafana-dashboards">Using Grafana Dashboards<a class="headerlink" href="#lab005-lab005-6-using-grafana-dashboards" title="Permanent link">&para;</a></h1>
<p>Once logged into Grafana, you’ll be taken to the Home Dashboard from which you can navigate to your starred or recently viewed dashboards. You can also install various types of plugins from the official Grafana list and also from third-party sources from this page.</p>
<p><img alt="grafana-home" src="../images/grafana-home.png" /></p>
<ol>
<li>
<p><strong>Click the Home dropdown in the top-left corner, and expand the Default dashboards if they aren’t already visible</strong>.</p>
<p><img alt="dashboard-dropdown" src="../images/dashboard-dropdown.png" /></p>
<p>A list of the recent and pre-installed dashboards will pop up. You may or may not see any recent dashboards, depending on previous usage of your userNN credentials. Notice that you can search dashboards by keyword in the search bar up top, or filter by labels on the right side.</p>
</li>
<li>
<p><strong>Click the Kubernetes / Compute Resources / Cluster link</strong> in the General tab.</p>
<p><img alt="kubernetes-graph" src="../images/kubernetes-graph.png" /></p>
<p>You will see a dashboard populated with information related to the cluster’s compute resources such as CPU and memory utilization. This dashboard displays CPU usage and CPU quota/memory requests by namespace.</p>
<p><img alt="grafana-options" src="../images/grafana-options.png" /></p>
</li>
<li>
<p><strong>Click the CPU Usage dropdown above the first graph in this dashboard and click View</strong>.</p>
<details class="information" open="open"><summary>Information</summary><p>Alternatively, you can click on the CPU Usage graph to activate it, and hit the <code>V</code> key on your keyboard.</p>
</details>
<p>This will bring up a full screen view of the graph to more easily see details.</p>
<p><img alt="graph-details-1" src="../images/graph-details-1.png" /></p>
</li>
<li>
<p><strong>Hover your cursor over the graph various points to see details for a certain namespace at a specific point in time</strong>.</p>
<p><img alt="graph-details-2" src="../images/graph-details-2.png" /></p>
<p>This still might be difficult to target a specific namespace, especially for the namespaces that aren’t using much CPU.</p>
</li>
<li>
<p><strong>Click a namespaces in the chart’s legend</strong>, such as <code>atg-zoscb</code> or <code>openshift-apiserver</code>.</p>
<p><img alt="legend" src="../images/legend.png" /></p>
</li>
<li>
<p><strong>Hold the Shift key and click a few more namespaces</strong>.</p>
<p><img alt="legend-2" src="../images/legend-2.png" /></p>
<p>This will display only the CPU usage for the few namespaces you selected.</p>
</li>
<li>
<p><strong>Click the Share dashboard button in the top right of the page</strong>.</p>
<p><img alt="share-link" src="../images/share-link.png" /></p>
<p>From here, you can share a snapshot of the graph either internally or externally. When creating a snapshot to share externally, sensitive data will be stripped.</p>
<details class="note" open="open"><summary>Note</summary><p>If you try to share or export a graph here, you will find that it’s unsuccessful.</p>
</details>
<p>The userNN profiles have administrator-viewer credentials, so you are limited to the features you can actually change. A profile with full cluster administrator authority would have more access to Grafana functions such as sharing graphs and snapshots, creating their own custom dashboards, editing and saving pre-built dashboards, and installing various plugins and other tools that extend Grafana’s built-in features.</p>
</li>
<li>
<p><strong>Close this browser window when you are ready to move on</strong>.</p>
</li>
</ol></section><section class="print-page" id="lab005-lab005-7"><h1 id="lab005-lab005-7-using-openshift-alerts-with-alertmanager">Using OpenShift Alerts with Alertmanager<a class="headerlink" href="#lab005-lab005-7-using-openshift-alerts-with-alertmanager" title="Permanent link">&para;</a></h1>
<p>Alerting with Prometheus is separated into two parts. Alerting rules in <em>Prometheus</em> send alerts to <em>Alertmanager</em>. Alertmanager then manages those alerts, including silencing, inhibition, aggregation and sending out notifications via methods such as email or chat platforms like Slack.</p>
<p><img alt="alert-stack" src="../images/alert-stack.png" /></p>
<p>An example rules file with an alert would be:</p>
<div class="highlight"><pre><span></span><code><span class="nt">groups</span><span class="p">:</span>
<span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">example</span>
  <span class="nt">rules</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">alert</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">HighRequestLatency</span>
    <span class="nt">expr</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">job:request_latency_seconds:mean5m{job=&quot;myjob&quot;} &gt; 0.5</span>
    <span class="nt">for</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10m</span>
    <span class="nt">labels</span><span class="p">:</span>
      <span class="nt">severity</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">page</span>
    <span class="nt">annotations</span><span class="p">:</span>
      <span class="nt">summary</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">High request latency</span>
</code></pre></div>
<p>The optional <code>for</code> clause causes Prometheus to wait for a certain duration between first encountering a new expression output vector element and counting an alert as firing for this element. In this case, Prometheus will check that the alert continues to be active during each evaluation for 10 minutes before firing the alert. Elements that are active, but not firing yet, are in the pending state.</p>
<p>The <code>labels</code> clause allows specifying a set of additional labels to be attached to the alert. Any existing conflicting labels will be overwritten.</p>
<p>The <code>annotations</code> clause specifies a set of informational labels that can be used to store longer additional information such as alert descriptions or runbook links.</p>
<ol>
<li>
<p>In the menu bar on the left side of the OpenShift console, <strong>click Monitoring and then Alerting</strong>.</p>
<p>You will be taken to an Alertmanager interface within the OpenShift console.</p>
<p><img alt="alertmanager" src="../images/alertmanager.png" /></p>
</li>
<li>
<p><strong>Click the Alerting Rules tab</strong> to see the 100+ alerts that are not currently firing (hopefully!)</p>
<p><img alt="alerting-rules" src="../images/alerting-rules.png" /></p>
<p>These alerts come pre-built with the monitoring stack, and they will start firing if triggered. This list includes alerts for critical operators going down, pods crash-looping, nodes being unreachable, and many more. Feel free to look through them.</p>
</li>
</ol></section><h1 class='nav-section-title-end'>Ended: Monitoring, Metering, and Metrics</h1>
                        <h2 class='nav-section-title' id='section-using-persistent-storage-with-mongodb-and-nodejs'>
                            Using Persistent Storage with MongoDB and NodeJS <a class='headerlink' href='#section-using-persistent-storage-with-mongodb-and-nodejs' title='Permanent link'>↵</a>
                        </h2>
                        <section class="print-page" id="lab006-lab006-1"><h1 id="lab006-lab006-1-using-persistent-storage-mongodb-and-nodejs">Using Persistent Storage - MongoDB and NodeJS<a class="headerlink" href="#lab006-lab006-1-using-persistent-storage-mongodb-and-nodejs" title="Permanent link">&para;</a></h1>
<p>In production Kubernetes clusters, applications need to write data to storage where it will persist even if the application pods go down. In this lab, we’ll see how that’s done using Persistent Volumes and Persistent Volume Claims.</p>
<p>OpenShift on IBM Z supports various types of persistent storage, including Spectrum Scale, OpenShift Container Storage, and NFS, which is what this cluster uses. Before the start of the workshop, persistent volumes were defined in OpenShift, more than enough for one per user. Each persistent volume definition maps to the NFS server.</p>
<p><img alt="nfs-arch" src="../images/nfs-arch.png" /></p>
<p>In this lab, you will deploy an application consisting of two components, a containerized <em>Node.js web application</em> and a containerized <em>MongoDB</em> instance, which you will back with persistent storage. Using the Node.js web application, you will be able to query the database, as well as insert new data into it.</p>
<p><img alt="app-arch" src="../images/app-arch.png" /></p>
<p>To deploy the <em>Node.js application</em>, you will build and run the container from a Dockerfile residing in a GitHub repository.</p>
<p>To deploy <em>MongoDB</em>, you will pull a MongoDB image from <quay.io> and run it. The image in quay.io is the official MongoDB container image pulled from Docker Hub and moved to the Quay registry. This was done simply because Dockerhub has rate limits on pull requests from their public repository.</p></section><section class="print-page" id="lab006-lab006-2"><h1 id="lab006-lab006-2-connect-to-ocp-and-authenticate">Connect to OCP and Authenticate<a class="headerlink" href="#lab006-lab006-2-connect-to-ocp-and-authenticate" title="Permanent link">&para;</a></h1>
<ol>
<li>
<p>In your virtual machine desktop, <strong>open a Firefox web browser</strong>.</p>
</li>
<li>
<p>In the browser, <strong>navigate to the OpenShift on IBM Z console</strong> at the following address: <a href="https://console-openshift-console.apps.atsocppa.dmz/">https://console-openshift-console.apps.atsocppa.dmz/</a>.</p>
<details class="note" open="open"><summary>Note</summary><p>You will receive a security challenge if the cluster has not yet been accessed from your browser. This is due to the default SSL certificate being “self-signed” and not yet recognized.</p>
<p>Accept the challenge to continue by <strong>clicking Advanced</strong> and then <strong>clicking Proceed to console-openshift-console.apps.atsocppa.dmz (unsafe)</strong>.</p>
<p>You will likely need to do this twice due to how OpenShift reroutes Oauth requests. </p>
</details>
<details><summary>Expand for screenshot</summary><p><img alt="security-accept.png" src="../images/security-accept.png" />
<img alt="security-accept-2.png" src="../images/security-accept-2.png" /></p>
</details>
<p>You will now see the OpenShift console login page.</p>
<p><img alt="openshift-console-login" src="../images/openshift-console-login.png" /></p>
</li>
<li>
<p>Log in with the OpenShift credentials provided to you on the <a href="#lab-assignments">Lab Assignments</a> page.</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>Your OpenShift credentials will be something like the following:</p>
<ul>
<li>
<p>Username: userNN (where NN is your user number)</p>
</li>
<li>
<p>Password: p@ssw0rd</p>
</li>
</ul>
</div>
</li>
</ol></section><section class="print-page" id="lab006-lab006-3"><h1 id="lab006-lab006-3-create-a-persistentvolumeclaim">Create a PersistentVolumeClaim<a class="headerlink" href="#lab006-lab006-3-create-a-persistentvolumeclaim" title="Permanent link">&para;</a></h1>
<p>As described in a previous section, a PersistentVolume has been already been predefined for each lab user. Next you will create a PersistentVolumeClaim that will bind to one of the available PersistentVolumes.</p>
<ol>
<li>
<p><strong>Change to the Administrator perspective</strong>, if not already there.</p>
</li>
<li>
<p><strong>Navigate to the Projects page</strong>. You can find it in the Menu, under Home -&gt; Projects.</p>
<p><img alt="home-projects" src="../images/home-projects.png" /></p>
</li>
<li>
<p><strong>Find and click on your userNN-project</strong>.</p>
</li>
<li>
<p>Under the menu button, <strong>click Storage -&gt; Persistent Volume Claims</strong>.</p>
</li>
<li>
<p><strong>Click “Create Persistent Volume Claim”</strong>.</p>
<p><img alt="create-pvc" src="../images/create-pvc.png" /></p>
<p>The Create Persistent Volume Claim form has four fields, and you’ll need to manually change each.</p>
<ul>
<li>
<p><strong>For Storage Class, select rootsquash-nfs</strong></p>
</li>
<li>
<p><strong>For Persistent Volume Claim Name, change the value to pvc-userNN</strong> (Replacing NN with your user #).</p>
</li>
<li>
<p><strong>For Access Mode, select Shared Access (RWX</strong>).</p>
</li>
<li>
<p><strong>For Size, change the value to 2 Gi</strong>.</p>
</li>
</ul>
<p>Your form should look like the following:</p>
<p><img alt="create-pvc-2" src="../images/create-pvc-2.png" /></p>
</li>
<li>
<p><strong>Click the create button</strong>.</p>
<p>You’ll be brought to the Overview for your newly created Persistent Volume Claim. The status of your claim should be <em>Bound</em>.</p>
<p><img alt="bound-pvc" src="../images/bound-pvc.png" /></p>
<details class="note" open="open"><summary>Note</summary><p>If your PersistentVolumeClaim does not bind almost immediately to a PersistentVolume, you likely did not fill out the fields as described above. You can delete your persistent volume claim and try again by clicking on the Actions dropdown and selecting Delete Persistent Volume Claim.</p>
</details>
</li>
</ol></section><section class="print-page" id="lab006-lab006-4"><h1 id="lab006-lab006-4-deploy-mongodb-from-a-container-image">Deploy MongoDB from a Container Image<a class="headerlink" href="#lab006-lab006-4-deploy-mongodb-from-a-container-image" title="Permanent link">&para;</a></h1>
<p>In this section, you will be deploying a container using a MongoDB container image from quay.io. A container image holds a set of software that is ready to run, while a container is a running instance of a container image. Images can be hosted in registries, such as the quay.io registry, Docker Hub, or a private registry of your own.</p>
<ol>
<li>
<p><strong>Toggle to the Developer Perspective and ensure you are in the correct userNN-project</strong>.</p>
<p><img alt="developer-userNN" src="../images/developer-userNN.png" /></p>
</li>
<li>
<p><strong>Click Add+ from the left-hand menu</strong>.</p>
</li>
<li>
<p><strong>Click the Container Images option</strong>.</p>
<p>This brings up a new page which prompts you for an image name and further configurable parameters further down the page. Only the image name is required, and the rest will automatically populate for you.</p>
</li>
<li>
<p><strong>In the search bar for Image Name from external registry, type</strong> <code>quay.io/mmondics/mongo</code>.</p>
<p><img alt="mongo-search" src="../images/mongo-search.png" /></p>
<p>A green check mark and a “validated” message will appear in the search bar, indicating that the MongoDB image has been found and validated in Quay.</p>
<details class="important" open="open"><summary><img alt="⚠" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/26a0.svg" title=":warning:" /> Important <img alt="⚠" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/26a0.svg" title=":warning:" /></summary><p>The fields below will automatically populate, but <strong><em>it is imperative that you change the Name field for your MongoDB service</em></strong>, or else the Node.js app will not be able to find and connect to the database.</p>
</details>
</li>
<li>
<p><strong>For Application Name, leave the default value</strong>.</p>
</li>
<li>
<p><strong><em>Replace the value of the Name field with mongodb</em></strong></p>
</li>
<li>
<p><strong>Leave Deployment and Create a Route to the Application checked</strong>.</p>
<p><img alt="mongo-fields" src="../images/mongo-fields.png" /></p>
</li>
<li>
<p><strong>Click the Create Button</strong>.</p>
<p>You will now be taken to the Topology view, where you will see an icon for your new MongoDB deployment.</p>
</li>
<li>
<p><strong>Click the icon for the mongodb deployment</strong>.</p>
<p>This will bring up a window on the right-hand side of the screen with information about your deployment.</p>
</li>
<li>
<p><strong>Select the Details tab</strong>, if not already selected.</p>
<p><img alt="mongo-details" src="../images/mongo-details.png" /></p>
<p>Depending on how quickly you clicked the icon, it will display either 1 pod, or 0 scaling to 1. If it has not scaled up to 1 pod yet, it will after a few seconds. However, we’re going to be adding and removing storage, so we will kill the pod once it comes up.</p>
</li>
<li>
<p><strong>Click the Down Arrow</strong> to reduce the pod count to zero.</p>
<p><img alt="mongo-down" src="../images/mongo-down.png" /></p>
<p>When a MongoDB pod is created, two storage volumes are attached to it. Let’s examine those.</p>
</li>
<li>
<p><strong>Click the mongodb deployment in the right-side window</strong>.</p>
<p><img alt="mongodb-deployment" src="../images/mongodb-deployment.png" /></p>
</li>
<li>
<p><strong>Once on the Deployment Details page, scroll down Volumes section</strong>.</p>
<p>Upon its creation, the pod created two volumes, mongodb-1 and mongodb-2. By default, MongoDB stores data in the <code>/data/db</code> directory, which is where the mongodb-2 volume has been mounted. This volume is not persistent. If the pod gets deleted, all of the stored data will be lost.</p>
<p>To make your MongoDB data persistent, you are going to delete mongodb-2 and instead mount your persistent volume claim at /data/db.</p>
</li>
<li>
<p><strong>Click the three dots for the mongodb-2 volume</strong>.</p>
</li>
<li>
<p><strong>Click Remove Volume</strong>.</p>
<p><img alt="remove-volume" src="../images/remove-volume.png" /></p>
<p>Now, you’ll add persistent storage, mounting the volume at /data/db.</p>
</li>
<li>
<p>Still on the Deployment Details page, <strong>scroll back up to the top and click the Actions dropdown</strong>.</p>
</li>
<li>
<p><strong>Click Add Storage</strong>.</p>
<p><img alt="add-storage" src="../images/add-storage.png" /></p>
<p>To add storage to your MongoDB deployment, you will need to fill out a couple of fields.</p>
</li>
<li>
<p><em>Use Existing Claim should already be selected</em>.</p>
</li>
<li>
<p><strong>From the Select Claim dropdown menu, select pvc-userNN</strong>.</p>
</li>
<li>
<p><strong>For Mount Path, enter</strong> <code>/data/db</code>.</p>
</li>
<li>
<p><strong>For Subpath, enter your userNN</strong>, where NN is your user number.</p>
<p><img alt="add-storage-1" src="../images/add-storage-1.png" /></p>
<p><img alt="add-storage-2" src="../images/add-storage-2.png" /></p>
</li>
<li>
<p><strong>Click the Save button</strong>.</p>
<p>You will now be returned to the Deployment Details page. In the same way that you reduced the pod count to zero, you will now bring it back up to one.</p>
</li>
<li>
<p><strong>Click the Up Arrow to increase the pod count to one</strong>.</p>
<p><img alt="scale-mongo-up" src="../images/scale-mongo-up.png" /></p>
</li>
<li>
<p><strong>Scroll Down to the section labeled Volumes</strong>, and you’ll see the persistent volume now mounted at /data/db</p>
<p><img alt="mounted-pvc1" src="../images/mounted-pvc.png" /></p>
<p>Now you’re ready to deploy the Node.js web application.</p>
</li>
</ol></section><section class="print-page" id="lab006-lab006-5"><h1 id="lab006-lab006-5-deploy-nodejs-application-from-a-dockerfile">Deploy Node.js Application from a Dockerfile<a class="headerlink" href="#lab006-lab006-5-deploy-nodejs-application-from-a-dockerfile" title="Permanent link">&para;</a></h1>
<p>In this portion of the lab, you will deploy a Node.js web application created by the ATG. You will be building your deployment from a Dockerfile residing in a GitHub repository. Through the web application, you will be able to insert data into and query the MongoDB database you just created. For this lab the database will store sample name and email pairs displayed as a list of user information in the web UI.</p>
<p>First, you need to deploy the application.</p>
<ol>
<li>
<p>Staying in the Developer Perspective, <strong>click +Add from the left-side menu</strong>.</p>
</li>
<li>
<p><strong>Click the From Dockerfile tile</strong>.</p>
<p>Fill out the form as follows:</p>
</li>
<li>
<p><strong>In the Git Repo URL Field, enter</strong>:</p>
<div class="highlight"><pre><span></span><code>https://github.com/mmondics/mongodb-app
</code></pre></div>
<p>You should see a “Validated” message below the URL field.</p>
</li>
<li>
<p><strong>Ensure that the value in the Application field is mongo-app</strong>.</p>
</li>
<li>
<p><strong>Replace the value in the Name field with nodejs-app</strong>.</p>
</li>
<li>
<p><strong>Leave Deployment checked</strong>.</p>
<p><img alt="import-dockerfile" src="../images/import-dockerfile.png" /></p>
<p><img alt="import-dockerfile-2" src="../images/import-dockerfile-2.png" /></p>
</li>
<li>
<p><strong>Click the Create button</strong>.  </p>
<p>Your Node.js application will now pull the Dockerfile from GitHub and begin its build. You will be returned to the Topology view. You should see mongodb and nodejs-app grouped together in mongo-app. When the build is complete, you will see a blue ring form around nodejs-app. You can also check its status by clicking on the nodejs-app icon and examining the Details panel.</p>
</li>
<li>
<p>Once the build is complete, <strong>click the Open URL button at the top right of the nodejs-app icon</strong>.</p>
<p><img alt="open-url" src="../images/open-url.png" /></p>
<p>This button is simply a shortcut to the route that was created as part of the deployment.</p>
<p>You are brought to the following landing page for your Node.js application:</p>
<p><img alt="node-landing" src="../images/node-landing.png" /></p>
</li>
</ol>
<p>In the next section, you will insert data into and query your MongoDB database.</p></section><section class="print-page" id="lab006-lab006-6"><h1 id="lab006-lab006-6-interacting-with-mongodb-from-nodejs-web-application">Interacting with MongoDB from Node.js Web Application<a class="headerlink" href="#lab006-lab006-6-interacting-with-mongodb-from-nodejs-web-application" title="Permanent link">&para;</a></h1>
<p>You should be on the “Hello World” landing page of your Node.js web application. If you have moved off of this screen, refer to the previous section for instructions on how to access the application.</p>
<p>Since your application has not yet been used, the MongoDB database of user data will be empty. We can use the Node.js frontend application to insert data into the linked MongoDB pod and the persistent storage backing it.</p>
<ol>
<li>
<p><strong>Click the Add a New User button</strong>.</p>
<p><img alt="node-landing-2" src="../images/node-landing-2.png" /></p>
<p>You will be brought to a new page titled Add New User.</p>
</li>
<li>
<p><strong>Enter a sample username and email and click Submit</strong>.</p>
<p><img alt="add-new-user" src="../images/add-new-user.png" /></p>
<p>You will be brought to a page titled User List which displays the entire contents of your database. Feel free to add additional users.</p>
<p><img alt="user-list" src="../images/user-list.png" /></p>
<p>The data you just entered through the NodeJS web application is now stored in a MongoDB database backed by persistent storage on our NFS server. Now, let’s test that our data will persist if we simulate a database crash by deleting our MongoDB pod.</p>
</li>
<li>
<p><strong>Return to the OpenShift Console Developer Perspective and navigate to the Topology View</strong>.</p>
</li>
<li>
<p><strong>Click the mongodb deployment</strong>.</p>
</li>
<li>
<p><strong>Click the down arrow to reduce the pod count to zero, terminating the MongoDB pod</strong>.</p>
<p><img alt="mongo-down" src="../images/mongo-down.png" /></p>
</li>
<li>
<p><strong>Return to the web application and refresh the page</strong>.</p>
<p>The page will not connect, and if you wait long enough you will get a 504 Gateway Time-out error as the database no longer exists and no connection can be made.</p>
</li>
<li>
<p><strong>Back in OpenShift, click the up arrow to increase the pod count back to 1</strong>.</p>
</li>
<li>
<p><strong>Return to the web application and refresh the page again</strong>.</p>
<p>Your data still exists, even though the MongoDB pod was terminated and replaced by a completely new one.</p>
<p>In this section, a new MongoDB pod was created. Since you mounted NFS persistent storage at /data/db in the original MongoDB pod, your data persisted even when the original MongoDB pod was deleted and replaced with a new one. Without persistent storage, the new MongoDB pod would have contained an empty database.</p>
</li>
</ol></section><section class="print-page" id="lab006-lab006-7"><h1 id="lab006-lab006-7-cleaning-up">Cleaning Up<a class="headerlink" href="#lab006-lab006-7-cleaning-up" title="Permanent link">&para;</a></h1>
<p>There is no easy way to delete all of these objects from the OpenShift console. This is a much easier task in the OpenShift command line.</p>
<ol>
<li>
<p>In the OpenShift CLI, <strong>make sure you are in your own project</strong> (i.e. userNN-project) <strong>and run the following command</strong>:</p>
<div class="highlight"><pre><span></span><code>oc delete all --all
</code></pre></div>
<details class="note" open="open"><summary>Note</summary><p>If you are not connected to the OpenShift command line, refer to <a href="#lab002-lab002-1">Using the OpenShift Command Line</a>.</p>
</details>
</li>
</ol>
<p>This will delete most of the objects in your project, but not the Persistent Volume Claim you created.</p>
<ol>
<li>
<p><strong>To delete the PVC, run the command</strong>:</p>
<div class="highlight"><pre><span></span><code>oc delete pvc/pvc-userNN
</code></pre></div>
<p>Where <code>NN</code> is your user number.</p>
</li>
</ol></section><h1 class='nav-section-title-end'>Ended: Using Persistent Storage with MongoDB and NodeJS</h1>
                        <h2 class='nav-section-title' id='section-deploying-an-application-with-the-open-liberty-operator'>
                            Deploying an Application with the Open Liberty Operator <a class='headerlink' href='#section-deploying-an-application-with-the-open-liberty-operator' title='Permanent link'>↵</a>
                        </h2>
                        <section class="print-page" id="lab007-lab007-1"><h1 id="lab007-lab007-1-deploying-an-application-with-the-open-liberty-operator">Deploying an Application with the Open Liberty Operator<a class="headerlink" href="#lab007-lab007-1-deploying-an-application-with-the-open-liberty-operator" title="Permanent link">&para;</a></h1>
<p><img alt="open-liberty-logo" src="../images/open-liberty-logo.png" /></p>
<p>Note: this lab is a modified version of the GitHub repository here:</p>
<p><a href="https://github.com/OpenShift-Z/openliberty-operator-ocpz">https://github.com/OpenShift-Z/openliberty-operator-ocpz</a></p>
<p>Open Liberty:</p>
<ul>
<li>is a lightweight, open framework for building fast and efficient cloud-native Java microservices</li>
<li>is fast to start up with low memory footprint and live reload for quick iteration.</li>
<li>is simple to add and remove features from the latest versions of MicroProfile and Java EE.</li>
<li>requires zero migration lets you focus on what's important, not the APIs changing under you.</li>
</ul>
<p>The <a href="https://github.com/OpenLiberty/open-liberty-operator">Open Liberty Operator</a> can be used to deploy and manage <a href="https://github.com/OpenLiberty">Open Liberty</a> applications into OpenShift clusters. You can also perform Day-2 operations such as gathering traces and dumps using the operator.</p>
<p>Because the Open Liberty Operator watches all namespaces in the OpenShift cluster, workshop users are not required to deploy the Operator itself. It has already been deployed in the openshift-operators project.</p></section><section class="print-page" id="lab007-lab007-2"><h1 id="lab007-lab007-2-log-into-openshift-using-the-cli">Log into OpenShift Using the CLI<a class="headerlink" href="#lab007-lab007-2-log-into-openshift-using-the-cli" title="Permanent link">&para;</a></h1>
<p>In this section, you will be connecting to a “Linux Guest” server which has a few things set up to make your life a little easier. Most notably, it has the OpenShift command line <code>oc</code> installed, so you don’t have to install it on your RHEL VM terminal.</p>
<ol>
<li>
<p><strong>Open a Terminal session</strong></p>
</li>
<li>
<p><strong>ssh into the Linux Guest server</strong>:</p>
<div class="highlight"><pre><span></span><code>ssh userNN@192.168.176.61
</code></pre></div>
<p>Where <code>NN</code> is your user number.</p>
</li>
<li>
<p>When prompted, <strong>enter your password:</strong> <code>p@ssw0rd</code> <strong>and hit enter</strong>.</p>
<details class="example" open="open"><summary>Example Output</summary><p><img alt="ascii-wsc.png" src="../images/ascii-wsc.png" /></p>
</details>
</li>
<li>
<p>In Firefox, <strong>navigate to the following URL</strong> to request an API token:</p>
<p><a href="https://oauth-openshift.apps.atsocppa.dmz/oauth/token/request">https://oauth-openshift.apps.atsocppa.dmz/oauth/token/request</a></p>
</li>
<li>
<p><strong>Enter your OpenShift credentials when prompted</strong>.</p>
<ul>
<li>
<p>Username: <code>userNN</code></p>
</li>
<li>
<p>Password: <code>p@ssw0rd</code></p>
</li>
</ul>
</li>
<li>
<p><strong>Click the “Display Token” hyperlink</strong>.</p>
<p><img alt="display-token.png" src="../images/display-token.png" /></p>
</li>
<li>
<p><strong>Copy the contents of the first text box</strong> beginning with <code>oc login</code> and ending with <code>6443</code>.</p>
<p><img alt="oc-login-token.png" src="../images/oc-login-token.png" /></p>
</li>
<li>
<p><strong>Paste this command back in your terminal session and press enter</strong>.</p>
<div class="highlight"><pre><span></span><code>oc login --token=&lt;YOUR_TOKEN_HERE&gt; --server=https://api.atsocppa.dmz:6443
</code></pre></div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>If you’re prompted to use an insecure connection, type Y and hit enter.</p>
</div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ oc login --token=uL3fHEPSGH3io0htdGRfAMAPIIY44BhwnGxCMA3dei4 --server=https://api.atsocppa.dmz:6443
Logged into &quot;https://api.atsocppa.dmz:6443&quot; as &quot;user01&quot; using the token provided.

You have access to 161 projects, the list has been suppressed. You can list all projects with &#39;oc projects&#39;

Using project &quot;user01-project&quot;.
</code></pre></div>
</details>
<p>You are now logged into the cluster via the command line, and you are told which project you are using.</p>
<p>If you’re in a project other than userNN-project, use the following command to move into it: <code>oc project userNN-project</code>, where NN is your user number.</p>
</li>
</ol></section><section class="print-page" id="lab007-lab007-3"><h1 id="lab007-lab007-3-cloning-the-github-repository-and-reviewing-its-contents">Cloning the GitHub Repository and Reviewing its Contents<a class="headerlink" href="#lab007-lab007-3-cloning-the-github-repository-and-reviewing-its-contents" title="Permanent link">&para;</a></h1>
<p>In the terminal session, you should have been automatically placed in your home directory <code>/home/userNN</code> (where NN is your user number).</p>
<ol>
<li>
<p><strong>Run the command</strong> <code>pwd</code> <strong>to check your current working directory</strong>.</p>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ pwd
/home/user01
</code></pre></div>
</details>
</li>
<li>
<p>If you are in any other directory, <strong>change into the correct home directory using the command</strong>:</p>
<div class="highlight"><pre><span></span><code>cd /home/userNN
</code></pre></div>
<p>Where <code>NN</code> is your user number.</p>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ cd /home/user01
user01@lab061:~$ pwd
/home/user01
</code></pre></div>
</details>
</li>
<li>
<p>In your home directory, <strong>clone the Open Liberty Operator repository using the command</strong>:</p>
<div class="highlight"><pre><span></span><code>git clone https://github.com/mmondics/openliberty-operator-ocpz
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ git clone https://github.com/mmondics/openliberty-operator-ocpz
Cloning into &#39;openliberty-operator-ocpz&#39;...
remote: Enumerating objects: 70, done.
remote: Counting objects: 100% (70/70), done.
remote: Compressing objects: 100% (68/68), done.
remote: Total 70 (delta 30), reused 2 (delta 1), pack-reused 0
Unpacking objects: 100% (70/70), done.
Checking connectivity... done.
</code></pre></div>
</details>
</li>
<li>
<p>This will create a new directory called <code>openliberty-operator-ocpz</code>. <strong>Change into this directory using the command</strong>:</p>
<div class="highlight"><pre><span></span><code>cd openliberty-operator-ocpz
</code></pre></div>
</li>
<li>
<p><strong>Then list its contents using the command</strong>:</p>
<div class="highlight"><pre><span></span><code>ls -l
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ cd openliberty-operator-ocpz
user01@lab061:~/openliberty-operator-ocpz$ ls -l
total 24
-rw-r--r-- 6 user01 users 4096 Sep  8 14:33 README.md
drwxr-xr-x 6 user01 users 4096 Sep  8 14:33 admin-ol-operator-install
drwxr-xr-x 6 user01 users 4096 Sep  8 14:33 images
drwxr-xr-x 6 user01 users 4096 Sep  8 14:33 ol-app-install
</code></pre></div>
</details>
<details class="information"><summary>Expand for More Information</summary><p>If you navigate to the GitHub in a web browser (<a href="https://github.com/mmondics/openliberty-operator-ocpz">https://github.com/mmondics/openliberty-operator-ocpz</a>), you will notice that the sub-directories in your Linux session reflect the folders contained in the repository.</p>
<table>
<thead>
<tr>
<th>File</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>README.md</td>
<td>Contains the content displayed on the GitHub page for this   repository. You can read through this README file if you want to get more   information about this lab.</td>
</tr>
<tr>
<td>admin-ol-operator-install</td>
<td>Directory used to install the Open Liberty Operator onto   the OpenShift cluster. Since this has been done ahead of time, you won’t be   using this directory.</td>
</tr>
<tr>
<td>images</td>
<td>Contains the images referenced in the README.md file and   displayed on the GitHub page for this repository.</td>
</tr>
<tr>
<td>ol-app-install</td>
<td>Contains all of the files needed to build, push, and   deploy the Mod Resorts sample application. This is where we will be doing our   work for this lab.</td>
</tr>
</tbody>
</table>
</details>
</li>
<li>
<p><strong>Change into the</strong> <code>ol-app-install</code> <strong>directory using the command</strong>:</p>
<div class="highlight"><pre><span></span><code>cd ol-app-install
</code></pre></div>
</li>
<li>
<p><strong>List its contents using the command</strong>:</p>
<div class="highlight"><pre><span></span><code>ls -l
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ cd ol-app-install
user01@lab061:~/openliberty-operator-ocpz/ol-app-install$ ls -l
total 8416
-rwxr--r—1 user01 users      845 Sep  8 14:33 1-build.sh
-rwxr--r—1 user01 users      367 Sep  8 14:33 2-deploy.sh
-rwxr--r—1 user01 users      612 Sep  8 14:33 3-cleanup.sh
-rwxr--r—1 user01 users      142 Sep  8 14:33 Dockerfile
-rwxr--r—1 user01 users      291 Sep  8 14:33 app-mod-withroute_cr.yaml
-rwxr--r—1 user01 users      636 Sep  8 14:33 env
-rwxr--r—1 user01 users   858364 Sep  8 14:33 modresorts-1.0.war
-rwxr--r—1 user01 users      687 Sep  8 14:33 server.xml
</code></pre></div>
</details>
<p>This directory contains 8 files that you will use to install the Mod Resorts sample application.</p>
<details class="information"><summary>Expand for More Information</summary><table>
<thead>
<tr>
<th>File</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>1-build.sh</code></td>
<td>shell script that contains commands to log into the   OpenShift Cluster and the internal registry, create a new project, build the   container image and then push it into the registry.</td>
</tr>
<tr>
<td><code>2-deploy.sh</code></td>
<td>shell script that contains commands to create the   OpenLibertyApplication custom resource based off of the image build and   pushed by 1-build.sh.</td>
</tr>
<tr>
<td><code>3-cleanup.sh</code></td>
<td>shell script that will clean up the OpenLibertyApplication   created by the previous scripts and delete the new project created by 1-build.sh.</td>
</tr>
<tr>
<td><code>Dockerfile</code></td>
<td>referenced by 1-build.sh to build the container image.</td>
</tr>
<tr>
<td><code>app-mod-withroute_cr.yaml</code></td>
<td>referenced by 2-deploy.sh to create the   OpenLibertyApplication custom resource.</td>
</tr>
<tr>
<td><code>env</code></td>
<td>environment variables sourced by the shell scripts for   various commands.</td>
</tr>
<tr>
<td><code>modresorts-1.0.war</code></td>
<td>a collection of JAR-files, JavaServer Pages, Java   Servlets, Java classes, etc… that together constitute the sample Mod Resorts   application.</td>
</tr>
<tr>
<td><code>server.xml</code></td>
<td>used in conjunction with the .war file to create the web   application.</td>
</tr>
</tbody>
</table>
</details>
</li>
</ol></section><section class="print-page" id="lab007-lab007-4"><h1 id="lab007-lab007-4-using-the-open-liberty-operator-to-install-an-application">Using the Open Liberty Operator to Install an Application<a class="headerlink" href="#lab007-lab007-4-using-the-open-liberty-operator-to-install-an-application" title="Permanent link">&para;</a></h1>
<ol>
<li>
<p><strong>Edit the environment variables file to match your user number (NN)</strong>.</p>
<div class="highlight"><pre><span></span><code>sed -i &#39;s/NN/YOUR_USER_NUMBER/g&#39; env
</code></pre></div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Make sure that you replace YOUR_USER_NUMBER in the command above.</p>
</div>
</li>
<li>
<p><strong>Run the command</strong> <code>cat env</code> <strong>to check that the two instances of</strong> <code>NN</code> <strong>were properly replaced with your user number</strong>.</p>
<p>With your modified environment variables file env, you’re ready to run the shell script <code>1-build.sh</code> that will use <em>Buildah</em> to build a container image from the Dockerfile, and <em>Podman</em> to push the image into OpenShift’s internal registry.</p>
<p>Before running this script, take a look at the steps it will go through.</p>
</li>
<li>
<p><strong>View the script contents using the command</strong>:</p>
<div class="highlight"><pre><span></span><code>cat 1-build.sh
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>#!/bin/text

unset KUBECONFIG

. ./env

echo &quot;Logging into OpenShift&quot;
oc login $OPENSHIFT_API_URL \
    --username=$OPENSHIFT_USERNAME \
    --password=$OPENSHIFT_PASSWORD \
    --insecure-skip-tls-verify=true

echo &quot;Logging into OpenShift image registry&quot;
podman login \
    --username $OPENSHIFT_USERNAME \
    --password $(oc whoami -t) \
    --tls-verify=false \
    $OPENSHIFT_REGISTRY_URL

echo &quot;Switch to $OPENSHIFT_PROJECT&quot;
oc project $OPENSHIFT_PROJECT

echo &quot;Building the container image&quot;
buildah build-using-dockerfile \
-t ${OPENSHIFT_REGISTRY_URL}/$OPENSHIFT_PROJECT/app-modernization:v1.0.0 \
    .

echo &quot;Pushing the container image to the OpenShift image registry&quot;
podman push --tls-verify=false \
${OPENSHIFT_REGISTRY_URL}/${OPENSHIFT_PROJECT}/app-modernization:v1.0.0
</code></pre></div>
</details>
<p>This shell script:</p>
<ul>
<li>Logs you into the OpenShift cluster.</li>
<li>Logs you into the OpenShift cluster’s internal image registry.</li>
<li>Switches to your project, if not currently working in it.</li>
<li>Builds the container image using the Dockerfile contained in your working directory.</li>
<li>Pushes the new container image from step 4 to the cluster’s internal image registry.</li>
</ul>
<details class="note" open="open"><summary>Note</summary><p>Note that you are welcome to enter each command manually and individually, but the scripting is there to minimize the opportunity for typos and other errors. If you do enter each command manually, make sure to replace each variable in BLUE with the actual value itself. Also, notice that the forward slash  simply breaks a single command into multiple lines.</p>
</details>
</li>
<li>
<p>You might notice that the <code>Dockerfile</code> is doing the brunt of the work in this script to build the container image itself. <strong>Take a look at this too, using the command</strong>:</p>
<div class="highlight"><pre><span></span><code>cat Dockerfile
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code><span class="k">FROM</span> <span class="s">quay.io/mmondics/open-liberty:latest</span>
<span class="k">COPY</span> --chown<span class="o">=</span><span class="m">1001</span>:0 modresorts-1.0.war /config/dropins
<span class="k">COPY</span> --chown<span class="o">=</span><span class="m">1001</span>:0 server.xml /config/
</code></pre></div>
</details>
<p>This <code>Dockerfile</code> pulls the Open Liberty Java EE 8 image from Quay.io then adds the <code>modresorts-1.0.war</code> binary and <code>server.xml</code> configuration file to the base image.</p>
<p>Back in the <code>ol-app-install</code> working directory, you can now run the script that brings all of these pieces together.</p>
</li>
<li>
<p><strong>Run the script using the command</strong>:</p>
<div class="highlight"><pre><span></span><code>./1-build.sh
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~/openliberty-operator-ocpz/ol-app-install$ ./1-build.sh
Logging into Openshift
Login successful.

You have access to 170 projects, the list has been suppressed. You can list all projects with &#39;oc projects&#39;

Using project &quot;user01-project&quot;.
Logging into Openshift image registry
Login Succeeded!
Switch to user01-project
Already on project &quot;user01-project&quot; on server &quot;https://api.atsocppa.dmz:6443&quot;.
Building the container image
STEP 1: FROM quay.io/mmondics/open-liberty:javaee8-ubi-min
STEP 2: COPY --chown=1001:0 modresorts-1.0.war /config/dropins
STEP 3: COPY --chown=1001:0 server.xml /config/
STEP 4: COMMIT default-route-openshift-image-registry.apps.atsocppa.dmz/user01-project/app-modernization:v1.0.0
Getting image source signatures
Copying blob d20db2e30c33 skipped: already exists
Copying blob 4ec5f0a55d74 skipped: already exists

... cut from screenshot ...

Copying config c6e6f3bf6b done
Writing manifest to image destination
Copying config c6e6f3bf6b done
Writing manifest to image destination
Storing signatures
user01@lab061:~/openliberty-operator-ocpz/ol-app-install$
</code></pre></div>
</details>
<p>Your container image is now built and pushed into OpenShift’s internal registry.</p>
</li>
<li>
<p><strong>View your new image in the registry using the command</strong>:</p>
<div class="highlight"><pre><span></span><code>podman images
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~/openliberty-operator-ocpz/ol-app-install$ podman images
REPOSITORY                                                                                 TAG     IMAGE ID       CREATED          SIZE
default-route-openshift-image-registry.apps.atsocppa.dmz/user01-project/app-modernization  v1.0.0  5970fc63cb46   16 seconds ago   472 MB
</code></pre></div>
</details>
<p>With the app-modernization image in the OpenShift internal registry, it can now be used to deploy an application into the cluster.</p>
<p>You have one more file to edit before deploying the Mod Resorts sample application.</p>
</li>
<li>
<p><strong>Edit the custom resource file using the command</strong>:</p>
<div class="highlight"><pre><span></span><code>sed -i &#39;s/NN/YOUR_USER_NUMBER/g&#39; app-mod-withroute_cr.yaml
</code></pre></div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Make sure that you replace YOUR_USER_NUMBER in the command above.</p>
</div>
</li>
<li>
<p><strong>Run the command</strong>:</p>
<div class="highlight"><pre><span></span><code>cat app-mod-withroute_cr.yaml
</code></pre></div>
<p>And make sure that the two instances of <code>NN</code> were properly replaced with your user number.</p>
<details class="information"><summary>Expand for More Information</summary><p>What exactly is this YAML file?</p>
<p>A <em>Custom Resource Definition (CRD)</em> object defines a new, unique object in the cluster and lets the Kubernetes API server handle its entire lifecycle. <em>Custom Resource (CR)</em> objects are created from CRDs that have been added to the cluster by a cluster administrator, allowing all cluster users to add the new resource type into projects.</p>
<p>So in this case, a CRD was created ahead of time of the kind: OpenLibertyApplication, and you are creating a CR from that CRD. </p>
</details>
<p>With the modified app-mod-withroute_cr.yaml file, you’re ready to run the second script, <code>2-deploy.sh</code>. Before running it, take a look at what all it will do.</p>
</li>
<li>
<p><strong>Run the command</strong>:</p>
<div class="highlight"><pre><span></span><code>cat 2-deploy.sh
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>#!/bin/text

unset KUBECONFIG

. ./env

echo &quot;Logging into OpenShift&quot;
oc login $OPENSHIFT_API_URL \
    --username=$OPENSHIFT_USERNAME \
    --password=$OPENSHIFT_PASSWORD \
    --insecure-skip-tls-verify=true

echo &quot;Creating OpenLiberty Custom Resource&quot;
oc -n $OPENSHIFT_PROJECT create -f app-mod-withroute_cr.yaml
</code></pre></div>
</details>
<p>This shell script:</p>
<ul>
<li>Logs you into the OpenShift cluster.</li>
<li>Creates an object from the Custom Resource (CR) YAML file you just edited.</li>
</ul>
</li>
<li>
<p><strong>Run this shell script with the command</strong>:</p>
<div class="highlight"><pre><span></span><code>./2-deploy.sh
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~/openliberty-operator-ocpz/ol-app-install$ ./2-deploy.sh
Logging into Openshift
Login successful.

You have access to 170 projects, the list has been suppressed. You can list all projects with &#39;oc projects&#39;

Using project &quot;user01-project&quot;.
Creating Openliberty Custom Resource Definition
openlibertyapplication.openliberty.io/appmod created
</code></pre></div>
</details>
<p>Your Custom Resource named <code>appmod</code> of kind <code>OpenLibertyApplication</code> has been <code>created</code> in your project, <code>userNN-project</code>.  The creation of this CR resulted in the Open Liberty Operator deploying a pod, deployment, replicaset, and a service that is exposed as a route.</p>
</li>
<li>
<p><strong>View all of the created objects using the command</strong>:</p>
<div class="highlight"><pre><span></span><code>oc get all
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~/openliberty-operator-ocpz/ol-app-install$ oc get all
NAME                          READY   STATUS    RESTARTS   AGE
pod/appmod-5959fb64b5-fqkvg   1/1     Running   0          16s

NAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE
service/appmod   ClusterIP   172.30.26.44   &lt;none&gt;        9080/TCP   17s

NAME                     READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/appmod   1/1     1            1           16s

NAME                                DESIRED   CURRENT   READY   AGE
replicaset.apps/appmod-5959fb64b5   1         1         1       16s

NAME                                           IMAGE REPOSITORY                    TAGS     UPDATED
imagestream.image.openshift.io/app-modernization   default-route-openshift-image-registry.apps.atsocppa.dmz/user01-project/app-modernization   v1.0.0   29 seconds ago

NAME                              HOST/PORT                 PATH  SERVICES   PORT  TERMINATION WILDCARD
route.route.openshift.io/appmod   modresort-user01.apps.atsocppa.dmz   /resorts   appmod     9080-tcp     None
</code></pre></div>
</details>
</li>
</ol></section><section class="print-page" id="lab007-lab007-5"><h1 id="lab007-lab007-5-access-the-application-in-a-browser">Access the Application in a Browser<a class="headerlink" href="#lab007-lab007-5-access-the-application-in-a-browser" title="Permanent link">&para;</a></h1>
<p>Your application is running and accessible via the exposed route.</p>
<ol>
<li>
<p><strong>In a web browser, navigate to the route</strong>:</p>
<p><a href="http://modresort-userNN.apps.atsocppa.dmz/resorts/">http://modresort-userNN.apps.atsocppa.dmz/resorts/</a></p>
<p>Where NN is your user number.</p>
<p><img alt="mod-resorts" src="../images/mod-resorts.png" /></p>
</li>
</ol>
<p>The demo application used (mod resorts) is admittedly a simple use-case with no dependencies on external resources, so you will notice that most of the links do not function. In real-world applications, there will be dependencies on external resources which can be integrated using various OpenShift and Kubernetes objects such as ConfigMaps, Volume mounts, secrets, etc.</p></section><section class="print-page" id="lab007-lab007-6"><h1 id="lab007-lab007-6-cleaning-up">Cleaning Up<a class="headerlink" href="#lab007-lab007-6-cleaning-up" title="Permanent link">&para;</a></h1>
<p>When you’re ready to wrap up this lab, return to your terminal to run the last shell script.</p>
<ol>
<li>
<p><strong>Run the cleanup script with the command</strong>:</p>
<div class="highlight"><pre><span></span><code>./3-cleanup.sh
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~/openliberty-operator-ocpz/ol-app-install$ ./3-cleanup.sh
Logging into OpenShift
Login successful.

You have access to 169 projects, the list has been suppressed. You can list all projects with &#39;oc projects&#39;

Using project &quot;user01-project&quot;.
Logging into OpenShift image registry
Login Succeeded!
Deleting Openliberty app
openlibertyapplication.openliberty.io &quot;appmod&quot; deleted
Deleting imagestream
imagestream.image.openshift.io &quot;app-modernization&quot; deleted
</code></pre></div>
</details>
</li>
</ol>
<p>Your OpenLiberty app consisting of a pod, deployment, service, route, and the imagestream used to create the pod have all been deleted.</p></section><h1 class='nav-section-title-end'>Ended: Deploying an Application with the Open Liberty Operator</h1>
                        <h2 class='nav-section-title' id='section-deploying-an-application-with-quarkus-red-hat-runtime'>
                            Deploying an Application with Quarkus Red Hat Runtime <a class='headerlink' href='#section-deploying-an-application-with-quarkus-red-hat-runtime' title='Permanent link'>↵</a>
                        </h2>
                        <section class="print-page" id="lab008-lab008-1"><h1 id="lab008-lab008-1-deploying-an-application-with-quarkus-red-hat-runtime">Deploying an Application with Quarkus Red Hat Runtime<a class="headerlink" href="#lab008-lab008-1-deploying-an-application-with-quarkus-red-hat-runtime" title="Permanent link">&para;</a></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For more Quarkus guides, see the official site here: <a href="https://quarkus.io/guides/">https://quarkus.io/guides/</a></p>
</div>
<p><img alt="quarkus-logo" src="../images/quarkus-logo.png" /></p>
<p><strong><em>Quarkus</em></strong> is a full-stack, Kubernetes-native Java framework optimized specifically for containers and Kubernetes environments. It is designed to work with popular Java standards, frameworks, and libraries like Eclipse MicroProfile, Spring Apache Kafka, RESTEasy, and many more.</p>
<p>Quarkus was designed for developers with the intent to be <em>easy to use</em> with features that work well with <em>little to no configuration</em>. It includes many features for developers, such as live coding so you can immediately check the effect of code changes and quickly troubleshoot them.</p>
<p>Quarkus was built around a <em>container-first</em> philosophy, meaning it’s optimized for lower memory usage and faster startup times. Quarkus builds applications to consume 1/10<sup>th</sup> the memory when compared to traditional Java, and has a much faster startup time (as much as 300 times faster), both of which greatly reduce the cost of cloud resources.</p>
<p>In this lab, you will explore these features by:</p>
<ul>
<li>Creating a new Quarkus project</li>
<li>Configuring the Quarkus application for OpenShift</li>
<li>Deploying the Quarkus application to OpenShift</li>
</ul></section><section class="print-page" id="lab008-lab008-2"><h1 id="lab008-lab008-2-log-into-openshift-using-the-cli">Log into OpenShift Using the ClI<a class="headerlink" href="#lab008-lab008-2-log-into-openshift-using-the-cli" title="Permanent link">&para;</a></h1>
<p>In this section, you will be connecting to a “Linux Guest” server which has a few things set up to make your life a little easier. Most notably, it has the OpenShift command line <code>oc</code> installed, so you don’t have to install it on your RHEL VM terminal.</p>
<ol>
<li>
<p><strong>Open a Terminal session</strong></p>
</li>
<li>
<p><strong>ssh into the Linux Guest server</strong>:</p>
<div class="highlight"><pre><span></span><code>ssh userNN@192.168.176.61
</code></pre></div>
<p>Where <code>NN</code> is your user number.</p>
</li>
<li>
<p>When prompted, <strong>enter your password:</strong> <code>p@ssw0rd</code> <strong>and hit enter</strong>.</p>
<details class="example" open="open"><summary>Example Output</summary><p><img alt="ascii-wsc.png" src="../images/ascii-wsc.png" /></p>
</details>
</li>
<li>
<p>In Firefox, <strong>navigate to the following URL</strong> to request an API token:</p>
<p><a href="https://oauth-openshift.apps.atsocppa.dmz/oauth/token/request">https://oauth-openshift.apps.atsocppa.dmz/oauth/token/request</a></p>
</li>
<li>
<p><strong>Enter your OpenShift credentials when prompted</strong>.</p>
<ul>
<li>
<p>Username: <code>userNN</code></p>
</li>
<li>
<p>Password: <code>p@ssw0rd</code></p>
</li>
</ul>
</li>
<li>
<p><strong>Click the “Display Token” hyperlink</strong>.</p>
<p><img alt="display-token.png" src="../images/display-token.png" /></p>
</li>
<li>
<p><strong>Copy the contents of the first text box</strong> beginning with “oc login” and ending with “6443”.</p>
<p><img alt="oc-login-token.png" src="../images/oc-login-token.png" /></p>
</li>
<li>
<p><strong>Paste this command back in your terminal session and press enter</strong>.</p>
<div class="highlight"><pre><span></span><code>oc login --token=&lt;YOUR_TOKEN_HERE&gt; --server=https://api.atsocppa.dmz:6443
</code></pre></div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>If you’re prompted to use an insecure connection, type Y and hit enter.</p>
</div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ oc login --token=uL3fHEPSGH3io0htdGRfAMAPIIY44BhwnGxCMA3dei4 --server=https://api.atsocppa.dmz:6443
Logged into &quot;https://api.atsocppa.dmz:6443&quot; as &quot;user01&quot; using the token provided.

You have access to 161 projects, the list has been suppressed. You can list all projects with &#39;oc projects&#39;

Using project &quot;user01-project&quot;.
</code></pre></div>
</details>
<p>You are now logged into the cluster via the command line, and you are told which project you are using.</p>
<p>If you’re in a project other than userNN-project, use the following command to move into it: <code>oc project userNN-project</code>, where NN is your user number.</p>
</li>
</ol></section><section class="print-page" id="lab008-lab008-3"><h1 id="lab008-lab008-3-creating-and-reviewing-the-quarkus-project">Creating and Reviewing the Quarkus Project<a class="headerlink" href="#lab008-lab008-3-creating-and-reviewing-the-quarkus-project" title="Permanent link">&para;</a></h1>
<p>In the terminal session, you should have been automatically placed in your home directory <code>/home/userNN</code> (where <code>NN</code> is your user number).</p>
<ol>
<li>
<p><strong>Run the command</strong> <code>pwd</code> <strong>to check your current working directory</strong>.</p>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ pwd
/home/user01
</code></pre></div>
</details>
</li>
<li>
<p>If you are in any other directory, <strong>change into the correct home directory using the command</strong>:</p>
<div class="highlight"><pre><span></span><code>cd /home/userNN
</code></pre></div>
<p>Where NN is your user number.</p>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ cd /home/user01
user01@lab061:~$ pwd
/home/user01
</code></pre></div>
</details>
<p>We will start off by creating a Maven Project. <em>Maven</em> is a powerful project management tool based on POM (Project Object Model). It is a tool used by Java developers to simplify and add structure to their day-to-day work by implementing dependency and documentation into their Java applications.</p>
<p>You can read more about Maven on their official site here: <a href="https://maven.apache.org/index.html">https://maven.apache.org/index.html</a>.</p>
<p>The following command uses the <em>Maven Quarkus Plugin</em> to create a basic Maven project for you in the <code>openshift-quickstart</code> subdirectory. It generates:</p>
<ul>
<li>
<p>The Maven structure including the <code>pom.xml</code></p>
</li>
<li>
<p>An org.acme.rest.GreetingResource resource exposed on <code>/greeting</code></p>
</li>
<li>
<p>An associated unit test</p>
</li>
<li>
<p>A landing page that is accessible on <a href="http://localhost:8080">http://localhost:8080</a> after starting the application</p>
</li>
<li>
<p>Example Dockerfiles for both native and jvm modes</p>
</li>
<li>
<p>The application configuration file</p>
</li>
</ul>
<p>Note that the forward slash  simply breaks the command into multiple lines for readability. Also note that if you do not specify the variables for projectGroupId, projectArtifactId, etc., the Maven installer will prompt you for them.</p>
</li>
<li>
<p><strong>In your home directory, run the following command</strong>:</p>
<div class="highlight"><pre><span></span><code>mvn io.quarkus:quarkus-maven-plugin:1.8.3.Final:create \
-DprojectGroupId=org.acme \
-DprojectArtifactId=openshift-quickstart \
-DclassName=&quot;org.acme.rest.GreetingResource&quot; \
-Dpath=&quot;/greeting&quot; \
-Dextensions=&quot;resteasy&quot;
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~$ user01@lab061:~$ mvn io.quarkus:quarkus-maven-plugin:1.8.3.Final:create \
&gt;     -DprojectGroupId=org.acme \
&gt;     -DprojectArtifactId=openshift-quickstart \
&gt;     -DclassName=&quot;org.acme.rest.GreetingResource&quot; \
&gt;     -Dpath=&quot;/greeting&quot; \
&gt;     -Dextensions=”resteasy”

[INFO] Scanning for projects...
[INFO] 
[INFO] ------------------&lt; org.apache.maven:standalone-pom &gt;-------------------
[INFO] Building Maven Stub Project (No POM) 1
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- quarkus-maven-plugin:1.8.3.Final:create (default-cli) @ standalone-pom ---
[INFO] 
[INFO] Maven Wrapper version 0.5.6 has been successfully set up for your project.
[INFO] Using Apache Maven: 3.6.3
[INFO] Repo URL in properties file: https://repo.maven.apache.org/maven2
[INFO] 
[INFO] ========================================================================================
[INFO] Your new application has been created in /home/user01/openshift-quickstart
[INFO] Navigate into this directory and launch your application with mvn quarkus:dev
[INFO] Your application will be accessible on http://localhost:8080
[INFO] ========================================================================================
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  12.644 s
[INFO] Finished at: 2020-10-19T11:35:57-04:00
[INFO] ------------------------------------------------------------------------
</code></pre></div>
</details>
</li>
<li>
<p>As the installation says, an application has been created under the <code>openshift-quickstart</code> sub-directory. <strong>Change into this directory using the command</strong>:</p>
<div class="highlight"><pre><span></span><code>cd openshift-quickstart
</code></pre></div>
</li>
<li>
<p><strong>Then view its structure using the command</strong>:</p>
<div class="highlight"><pre><span></span><code>tree
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>    user01@lab061:~$ cd openshift-quickstart
    user01@lab061:~/openshift-quickstart$ tree
    total 24
    .
    |-- README.md
    |-- mvnw
    |-- mvnw.cmd
    |-- pom.xml
    `-- src
        |-- main
        |   |-- docker
        |   |   |-- Dockerfile.fast-jar
        |   |   |-- Dockerfile.jvm
        |   |   `-- Dockerfile.native
        |   |-- java
        |   |   `-- org
        |   |       `-- acme
        |   |           `-- rest
        |   |               `-- GreetingResource.java
        |   `-- resources
        |       |-- META-INF
        |       |   `-- resources
        |       |       `-- index.html
        |       `-- application.properties
        `-- test
            `-- java
                `-- org
                    `-- acme
                        `-- rest
                            |-- GreetingResourceTest.java
                            `-- NativeGreetingResourceIT.java

    15 directories, 12 files
</code></pre></div>
</details>
<p>You can see that the command created the <code>pom.xml</code> file, Dockerfiles for both JVM and native modes, your GreetingResource.java file exposed at <code>/greeting</code>, and the associated test resources.</p>
</li>
<li>
<p>Let’s take a look at the <code>pom.xml</code> file that was created as a part of the installation. <strong>View the file using the command</strong>:</p>
<div class="highlight"><pre><span></span><code>cat pom.xml
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~/openshift-quickstart$ cat pom.xml

...omitted...
<span class="nt">&lt;dependencyManagement&gt;</span>
    <span class="nt">&lt;dependencies&gt;</span>
    <span class="nt">&lt;dependency&gt;</span>
        <span class="nt">&lt;groupId&gt;</span>${quarkus.platform.group-id}<span class="nt">&lt;/groupId&gt;</span>
        <span class="nt">&lt;artifactId&gt;</span>${quarkus.platform.artifact-id}<span class="nt">&lt;/artifactId&gt;</span>
        <span class="nt">&lt;version&gt;</span>${quarkus.platform.version}<span class="nt">&lt;/version&gt;</span>
        <span class="nt">&lt;type&gt;</span>pom<span class="nt">&lt;/type&gt;</span>
        <span class="nt">&lt;scope&gt;</span>import<span class="nt">&lt;/scope&gt;</span>
    <span class="nt">&lt;/dependency&gt;</span>
    <span class="nt">&lt;/dependencies&gt;</span>
<span class="nt">&lt;/dependencyManagement&gt;</span>
...omitted...

<span class="nt">&lt;build&gt;</span>
    <span class="nt">&lt;plugins&gt;</span>
    <span class="nt">&lt;plugin&gt;</span>
        <span class="nt">&lt;groupId&gt;</span>io.quarkus<span class="nt">&lt;/groupId&gt;</span>
        <span class="nt">&lt;artifactId&gt;</span>quarkus-maven-plugin<span class="nt">&lt;/artifactId&gt;</span>
        <span class="nt">&lt;version&gt;</span>${quarkus-plugin.version}<span class="nt">&lt;/version&gt;</span>
        <span class="nt">&lt;executions&gt;</span>
        <span class="nt">&lt;execution&gt;</span>
            <span class="nt">&lt;goals&gt;</span>
            <span class="nt">&lt;goal&gt;</span>generate-code<span class="nt">&lt;/goal&gt;</span>
            <span class="nt">&lt;goal&gt;</span>generate-code-tests<span class="nt">&lt;/goal&gt;</span>
            <span class="nt">&lt;goal&gt;</span>build<span class="nt">&lt;/goal&gt;</span>
            <span class="nt">&lt;/goals&gt;</span>
        <span class="nt">&lt;/execution&gt;</span>
        <span class="nt">&lt;/executions&gt;</span>
    <span class="nt">&lt;/plugin&gt;</span>
    <span class="nt">&lt;plugin&gt;</span>
        <span class="nt">&lt;artifactId&gt;</span>maven-compiler-plugin<span class="nt">&lt;/artifactId&gt;</span>
        <span class="nt">&lt;version&gt;</span>${compiler-plugin.version}<span class="nt">&lt;/version&gt;</span>
    <span class="nt">&lt;/plugin&gt;</span>
    <span class="nt">&lt;plugin&gt;</span>
        <span class="nt">&lt;artifactId&gt;</span>maven-surefire-plugin<span class="nt">&lt;/artifactId&gt;</span>
        <span class="nt">&lt;version&gt;</span>${surefire-plugin.version}<span class="nt">&lt;/version&gt;</span>
        <span class="nt">&lt;configuration&gt;</span>
        <span class="nt">&lt;systemPropertyVariables&gt;</span>
            <span class="nt">&lt;java.util.logging.manager&gt;</span>org.jboss.logmanager.LogManager<span class="nt">&lt;/java.util.logging.manager&gt;</span>
            <span class="nt">&lt;maven.home&gt;</span>${maven.home}<span class="nt">&lt;/maven.home&gt;</span>
        <span class="nt">&lt;/systemPropertyVariables&gt;</span>
        <span class="nt">&lt;/configuration&gt;</span>
    <span class="nt">&lt;/plugin&gt;</span>
    <span class="nt">&lt;/plugins&gt;</span>
<span class="nt">&lt;/build&gt;</span>
</code></pre></div>
</details>
<p>The snippets above show the import of the Quarkus BOM, which allows you to omit the version on the different Quarkus dependencies. In addition, you can see the quarkus-maven-plugin responsible for the packaging of the application and providing the development mode.</p>
<p>Next look at the dependencies section.</p>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code><span class="nt">&lt;dependencies&gt;</span>
    <span class="nt">&lt;dependency&gt;</span>
    <span class="nt">&lt;groupId&gt;</span>io.quarkus<span class="nt">&lt;/groupId&gt;</span>
    <span class="nt">&lt;artifactId&gt;</span>quarkus-resteasy<span class="nt">&lt;/artifactId&gt;</span>
    <span class="nt">&lt;/dependency&gt;</span>
    <span class="nt">&lt;dependency&gt;</span>
    <span class="nt">&lt;groupId&gt;</span>io.quarkus<span class="nt">&lt;/groupId&gt;</span>
    <span class="nt">&lt;artifactId&gt;</span>quarkus-junit5<span class="nt">&lt;/artifactId&gt;</span>
    <span class="nt">&lt;scope&gt;</span>test<span class="nt">&lt;/scope&gt;</span>
    <span class="nt">&lt;/dependency&gt;</span>
    <span class="nt">&lt;dependency&gt;</span>
    <span class="nt">&lt;groupId&gt;</span>io.rest-assured<span class="nt">&lt;/groupId&gt;</span>
    <span class="nt">&lt;artifactId&gt;</span>rest-assured<span class="nt">&lt;/artifactId&gt;</span>
    <span class="nt">&lt;scope&gt;</span>test<span class="nt">&lt;/scope&gt;</span>
    <span class="nt">&lt;/dependency&gt;</span>
</code></pre></div>
</details>
<p>You can see we are using <a href="https://code.quarkus.io/">Quarkus extensions</a> which allow the development and testing of REST applications:</p>
<p>During the installation, the <code>openshift-quickstart/src/main/java/org/acme/rest/GreetingResource.java</code>
file was created. This is a simple REST endpoint, returning “hello” to requests at <code>/greeting</code>.</p>
</li>
<li>
<p><strong>From the</strong> <code>openshift-quickstart</code> <strong>directory, view this file with the command</strong>:</p>
<div class="highlight"><pre><span></span><code>cat src/main/java/org/acme/rest/GreetingResource.java
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code><span class="kn">package</span> <span class="nn">org.acme.rest</span><span class="p">;</span>

<span class="kn">import</span> <span class="nn">javax.ws.rs.GET</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">javax.ws.rs.Path</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">javax.ws.rs.Produces</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">javax.ws.rs.core.MediaType</span><span class="p">;</span>

<span class="nd">@Path</span><span class="p">(</span><span class="s">&quot;/greeting&quot;</span><span class="p">)</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">GreetingResource</span> <span class="p">{</span>

    <span class="nd">@GET</span>
    <span class="nd">@Produces</span><span class="p">(</span><span class="n">MediaType</span><span class="p">.</span><span class="na">TEXT_PLAIN</span><span class="p">)</span>
    <span class="kd">public</span> <span class="n">String</span> <span class="nf">hello</span><span class="p">()</span> <span class="p">{</span>
        <span class="k">return</span> <span class="s">&quot;hello&quot;</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
</details>
<p>You can see that this file is simply telling the application to return “hello” at the <code>/greeting</code> path.</p>
</li>
</ol></section><section class="print-page" id="lab008-lab008-4"><h1 id="lab008-lab008-4-configure-the-application-for-openshift">Configure the Application for OpenShift<a class="headerlink" href="#lab008-lab008-4-configure-the-application-for-openshift" title="Permanent link">&para;</a></h1>
<p>One of the great things about Quarkus is the plethora of <em>extensions</em> it provides out of the box. Quarkus extensions are comparable to Maven dependencies that allow for much easier use and integration into 3<sup>rd</sup> party projects.</p>
<p>We will be using the <em>Quarkus OpenShift extension</em>. The OpenShift extension is actually a wrapper that brings together the <a href="https://quarkus.io/guides/deploying-to-kubernetes">kubernetes</a> and <a href="https://quarkus.io/guides/container-image#s2i">container-image-s2i</a> extensions with defaults specific to OpenShift.</p>
<ol>
<li>
<p><strong>In your terminal session, add the OpenShift extension to you application with the command</strong>:</p>
<div class="highlight"><pre><span></span><code>./mvnw quarkus:add-extension -Dextensions=&quot;openshift&quot;
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~/openshift-quickstart$ ./mvnw quarkus:add-extension -Dextensions=&quot;openshift&quot;
[INFO] Scanning for projects...
[INFO] 
[INFO] -------------------&lt; org.acme:openshift-quickstart &gt;--------------------
[INFO] Building openshift-quickstart 1.0-SNAPSHOT
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- quarkus-maven-plugin:1.9.0.CR1:add-extension (default-cli) @ openshift-quickstart ---
? Extension io.quarkus:quarkus-openshift has been installed
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  11.356 s
[INFO] Finished at: 2020-10-23T15:42:02-04:00
[INFO] ------------------------------------------------------------------------
</code></pre></div>
</details>
<p>This command added the following dependency to your <code>pom.xml</code> file:</p>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>    <span class="nt">&lt;dependency&gt;</span>
    <span class="nt">&lt;groupId&gt;</span>io.quarkus<span class="nt">&lt;/groupId&gt;</span>
    <span class="nt">&lt;artifactId&gt;</span>quarkus-openshift<span class="nt">&lt;/artifactId&gt;</span>
    <span class="nt">&lt;/dependency&gt;</span>
</code></pre></div>
</details>
<p>This dependency is the generic quarkus.openshift extension, but it can be further customized with essentially any further nested dependency for OpenShift or Kubernetes objects you need. Some examples are in the table below, and the full list is here: <a href="https://quarkus.io/guides/kubernetes#openshift">https://quarkus.io/guides/kubernetes#openshift</a>.</p>
<details class="information"><summary>Expand for more Information</summary><table>
<thead>
<tr>
<th>Property</th>
<th>Type</th>
</tr>
</thead>
<tbody>
<tr>
<td>quarkus.openshift.version</td>
<td>String</td>
</tr>
<tr>
<td>quarkus.openshift.env-vars</td>
<td>Map<String, Env></td>
</tr>
<tr>
<td>quarkus.openshift.replicas</td>
<td>int</td>
</tr>
<tr>
<td>quarkus.openshift.service-account</td>
<td>String</td>
</tr>
<tr>
<td>quarkus.openshift.host</td>
<td>String</td>
</tr>
<tr>
<td>quarkus.openshift.ports</td>
<td>Map<String, Port></td>
</tr>
<tr>
<td>quarkus.openshift.pvc-volumes</td>
<td>Map<String, PersistentVolumeClaimVolume></td>
</tr>
<tr>
<td>quarkus.openshift.image-pull-policy</td>
<td>ImagePullPolicy</td>
</tr>
<tr>
<td>quarkus.openshift.image-pull-secrets</td>
<td>String[]</td>
</tr>
<tr>
<td>quarkus.openshift.liveness-probe</td>
<td>Probe</td>
</tr>
<tr>
<td>quarkus.openshift.readiness-probe</td>
<td>Probe</td>
</tr>
<tr>
<td>quarkus.openshift.expose</td>
<td>boolean</td>
</tr>
</tbody>
</table>
</details>
<p>You will be using a few of these customizations when you deploy the application to OpenShift in the next step.</p>
</li>
</ol></section><section class="print-page" id="lab008-lab008-5"><h1 id="lab008-lab008-5-deploy-the-application-onto-openshift">Deploy the Application onto OpenShift<a class="headerlink" href="#lab008-lab008-5-deploy-the-application-onto-openshift" title="Permanent link">&para;</a></h1>
<p>Let’s now take our local application and use the Quarkus extension we just added to build and deploy a containerized application onto OpenShift.</p>
<ol>
<li>
<p><strong>In the openshift-quickstart directory, run the command</strong>:</p>
<div class="highlight"><pre><span></span><code>./mvnw clean package \
-Dquarkus.kubernetes.deploy=true \
-Dquarkus.kubernetes-client.trust-certs=true \
-Dquarkus.openshift.expose=true
</code></pre></div>
<p>The <code>-Dquarkus</code> flags in this command are telling Maven to deploy the application into the Kubernetes (OpenShift) cluster, trust the certificates, and expose the application service as a route, eliminating the need to run an <code>oc expose svc</code> to make the service endpoint accessible outside of the cluster.</p>
<div class="admonition information">
<p class="admonition-title">Information</p>
<p>This command may take a few minutes to complete.</p>
</div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~/openshift-quickstart$ ./mvnw clean package \
    -Dquarkus.kubernetes.deploy=true \
    -Dquarkus.kubernetes-client.trust-certs=true \
    -Dquarkus.openshift.expose=true
[INFO] Scanning for projects...
[INFO] 
[INFO] -------------------&lt; org.acme:openshift-quickstart &gt;--------------------
[INFO] Building openshift-quickstart 1.0.0-SNAPSHOT
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
...omitted...

[INFO] [io.quarkus.kubernetes.deployment.KubernetesDeployer] The deployed application can be accessed at: http://openshift-quickstart-user01-project.apps.atsocppa.dmz
[INFO] [io.quarkus.deployment.QuarkusAugmentor] Quarkus augmentation completed in 94655ms
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  03:19 min
[INFO] Finished at: 2021-03-09T12:12:14-05:00
[INFO] ------------------------------------------------------------------------
</code></pre></div>
</details>
<p>The previous command builds a jar file locally, connects to the OpenShift cluster you previously logged into, triggers a container image build, pushes that container image into the OpenShift internal registry, generates OpenShift/Kubernetes resources including a Service, Route, DeploymentConfig, and your running application pod.</p>
</li>
<li>
<p><strong>View all of the created objects with the following command</strong>:</p>
<div class="highlight"><pre><span></span><code>oc get all
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061: ~/openshift-quickstart$ oc get all
NAME                                READY   STATUS      RESTARTS   AGE
pod/openshift-quickstart-1-build    0/1     Completed   0          9m10s
pod/openshift-quickstart-1-deploy   0/1     Completed   0          8m13s
pod/openshift-quickstart-1-ndp8h    1/1     Running     0          8m10s

NAME                                           DESIRED   CURRENT   READY   AGE
replicationcontroller/openshift-quickstart-1   1         1         1       8m13s

NAME                           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
service/openshift-quickstart   ClusterIP   172.30.28.241   &lt;none&gt;        8080/TCP   8m14s

NAME                                                  REVISION   DESIRED   CURRENT   TRIGGERED BY
deploymentconfig.apps.openshift.io/openshift-quickstart   1          1         1         image(openshift-quickstart:1.0-SNAPSHOT)

NAME                                                  TYPE     FROM     LATEST
buildconfig.build.openshift.io/openshift-quickstart   Source   Binary   1

NAME                                              TYPE     FROM     STATUS     STARTED         DURATION
build.build.openshift.io/openshift-quickstart-1   Source   Binary   Complete   9 minutes ago   55s

NAME                    IMAGE REPOSITORY                                 TAGS                                      UPDATED
imagestream.image.openshift.io/openjdk-11             default-route-openshift-image-registry.apps.atsocppa.dmz/user01-project/openjdk-11             1.3,1.3-3,1.3-3.1591609340 + 18 more...   9 minutes ago
imagestream.image.openshift.io/openshift-quickstart   default-route-openshift-image-registry.apps.atsocppa.dmz/user01-project/openshift-quickstart   1.0-SNAPSHOT                              8 minutes ago

NAME           HOST/PORT                        PATH      SERVICES               PORT   TERMINATION  
route.route.openshift.io/openshift-quickstart  openshift-quickstart-user01-project.apps.atsocppa.dmz   /      openshift-quickstart   8080
</code></pre></div>
</details>
<p>Each of these objects were created because of the <code>-Dquarkus.kubernetes.deploy=true</code> and <code>-Dquarkus.openshift.expose=true</code> flags provided in the previous command. There are many more OpenShift objects and object properties that can be created by passing different flags, such as liveliness probes, environment variables, secrets, persistent storage, and more.</p>
<p>If you have one running pod, your application has successfully deployed and is accessible at the route.</p>
</li>
<li>
<p><strong>In a web browser, navigate to your route</strong>:</p>
<details class="hint"><summary>Hint</summary><p>It will be <a href="http://openshift-quickstart-userNN-project.apps.atsocppa.dmz/">http://openshift-quickstart-userNN-project.apps.atsocppa.dmz/</a> where NN is your user number.</p>
</details>
<p><img alt="quarkus-main" src="../images/quarkus-main.png" /></p>
<p>Your Quarkus application is now deployed as a container in OpenShift.</p>
<p>Earlier we looked at the GreetingResource.java REST endpoint and its return of “hello” in the command line. We can do the same thing in the web browser.</p>
</li>
<li>
<p><strong>Add</strong> <code>/greeting</code> <strong>to the end of your route</strong>.</p>
<details class="hint"><summary>Hint</summary><p><a href="http://openshift-quickstart-userNN-project.apps.atsocppa.dmz/greeting">http://openshift-quickstart-userNN-project.apps.atsocppa.dmz/greeting</a> where NN is your user number.</p>
</details>
<p><img alt="hello" src="../images/hello.png" /></p>
<p>In this lab, you have created a Quarkus application locally, containerized the application and deployed it onto an OpenShift cluster running on IBM Z, and accessed it from a public route.</p>
<p>The speed, agility, and ease with which we’re able to edit and redeploy applications using the Quarkus runtime creates tremendous value in time savings, allowing developers and operations staff to minimize downtime and keep applications up to date. Further, the simplicity of integration using Quarkus extensions creates great opportunity for customization and implementations tailored to fit a variety of needs.</p>
</li>
</ol></section><section class="print-page" id="lab008-lab008-6"><h1 id="lab008-lab008-6-cleaning-up">Cleaning Up<a class="headerlink" href="#lab008-lab008-6-cleaning-up" title="Permanent link">&para;</a></h1>
<ol>
<li>
<p><strong>Double check that you are in your own userNN-project by issuing the command</strong>:</p>
<div class="highlight"><pre><span></span><code>oc project
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061 ~/openshift-quickstart $ oc project
Using project &quot;user01-project&quot; on server &quot;https://api.atsocppa.dmz:6443&quot;.
</code></pre></div>
</details>
</li>
<li>
<p><strong>Once you’re sure you’re in your own project, issue the following command to delete all objects</strong> associated with your application labeled app.kubernetes.io/name=openshift-quickstart.  </p>
<div class="highlight"><pre><span></span><code>oc delete all --selector app.kubernetes.io/name=openshift-quickstart
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~/openshift-quickstart $ oc delete all --selector app.kubernetes.io/name=openshift-quickstart
pod &quot;openshift-quickstart-1-ztfq9&quot; deleted
replicationcontroller &quot;openshift-quickstart-1&quot; deleted
service &quot;openshift-quickstart&quot; deleted
deploymentconfig.apps.openshift.io &quot;openshift-quickstart&quot; deleted
buildconfig.build.openshift.io &quot;openshift-quickstart&quot; deleted
build.build.openshift.io &quot;openshift-quickstart-1&quot; deleted
imagestream.image.openshift.io &quot;openjdk-11&quot; deleted
imagestream.image.openshift.io &quot;openshift-quickstart&quot; deleted
route.route.openshift.io &quot;openshift-quickstart&quot; deleted
</code></pre></div>
</details>
</li>
<li>
<p><strong>To check that all of your mongo application resources were deleted, run the command</strong>:</p>
<div class="highlight"><pre><span></span><code>oc get all
</code></pre></div>
<details class="example" open="open"><summary>Example Output</summary><div class="highlight"><pre><span></span><code>user01@lab061:~/openshift-quickstart $ oc get all
No resources found.
user00@lab061:~$
</code></pre></div>
</details>
</li>
</ol>
<details class="note"><summary>Note</summary><p>If there are leftover resources from other labs that you would like to delete, run the command:</p>
<div class="highlight"><pre><span></span><code>oc delete all --all 
</code></pre></div>
</details></section><h1 class='nav-section-title-end'>Ended: Deploying an Application with Quarkus Red Hat Runtime</h1><h1 class='nav-section-title-end'>Ended: Labs</h1></div>
                
              
              
                


              
            </article>
          </div>
        </div>
        
      </main>
      
        
<footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright © 2021 IBM Z Washington Systems Center
          </div>
        
        
          Made with
          <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
            Material for MkDocs
          </a>
        
        
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../..", "features": [], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../assets/javascripts/workers/search.f8263e09.min.js", "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.4fc53ad4.min.js"></script>
      
        <script src="../js/print-site.js"></script>
      
    
  </body>
</html>